# ğŸ“… 2025.02.11 ë¦¬ë·° & íšŒê³ 

---

# ğŸ“ ë¦¬ë·°

## ì•„ì´ë””ì–´ ê´€ë ¨

ì£¼ì œ ì„ ì •ì´ ì•„ì§ë„ ë‚œí•­ì„ ê²ªê³  ìˆë‹¤. ê·¸ë˜ì„œ ê¸°ë³¸ìœ¼ë¡œ ëŒì•„ê°€ì„œ ìµœì¢… í”„ë¡œì íŠ¸ì˜ ì£¼ì œë¥¼ í•˜ë‚˜í•˜ë‚˜ ëœ¯ì–´ë³´ì•˜ë‹¤.

### ì‹ ê·œ ëª¨ë¸ì´ ì¶œì‹œë˜ì—ˆì„ ë•Œ

- ì™œ ì‹ ê·œ ëª¨ë¸ì´ ì¶œì‹œ ë˜ì—ˆì„ ë•Œì¼ê¹Œ?
    - ì‹ ê·œ ëª¨ë¸ì˜ ì´ˆê¸° íŒë§¤ëŸ‰ì€ ë§¤ìš° ì¤‘ìš”í•˜ë‹¤
    - ì´ˆê¸° íŒë§¤ëŸ‰ì€ ìš°ìƒí–¥ ê·¸ë˜í”„ë¥¼ ê·¸ë¦¬ê¸° ì‰½ì§€ ì•Šìœ¼ë¯€ë¡œ, ì´ˆê¸° íŒë§¤ëŸ‰ì„ ìœ ì§€í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë¯€ë¡œ
    - ì†Œë¹„ì ê´€ì‹¬ì´ ê°€ì¥ ì§‘ì¤‘ë˜ëŠ” ì‹œê¸°ì´ë‹¤.
    - ì‹ ì°¨ ì¶œì‹œ ì§í›„ì—ëŠ” ìë™ì°¨ íŒ¬, ì†Œë¹„ì, ìë™ì°¨ ë¦¬ë·°ì–´, ì—…ê³„ ì „ë¬¸ê°€ë“¤ì´ ê°€ì¥ í™œë°œí•˜ê²Œ ë°˜ì‘í•˜ëŠ” ì‹œê¸°
    - ì´ìŠˆ ë°œìƒ ê°€ëŠ¥ì„±ì´ ê°€ì¥ ë†’ì€ ì‹œì ì´ê¸° ë•Œë¬¸ì´ë‹¤.
    - ìƒˆë¡œìš´ ëª¨ë¸ì´ ì‹œì¥ì— ë‚˜ì™”ì„ ë•Œ ì˜ˆìƒì¹˜ ëª»í•œ ë¬¸ì œ(ì˜ˆ: í’ˆì§ˆ, ê¸°ëŠ¥, ê°€ê²© ë“±)ì— ëŒ€í•œ ë…¼ë€ì´ ë°œìƒí•  ê°€ëŠ¥ì„±ì´ í¬ë‹¤.
    - ì´ëŸ° ì´ìŠˆê°€ í™•ì‚°ë˜ê¸° ì „ì— ì¡°ê¸° íƒì§€í•˜ì—¬ ëŒ€ì‘í•˜ë©´ ë¸Œëœë“œ ì‹ ë¢°ë„ ìœ ì§€ì— ìœ ë¦¬

### SNS (ìœ íŠœë¸Œ, ì¸ìŠ¤íƒ€ê·¸ë¨, ì»¤ë®¤ë‹ˆí‹° ë“±)ì—ì„œ

- ì™œ SNS ë°˜ì‘ì„ ë´ì•¼í•˜ëŠ”ê°€??
    - ì‹ ì°¨ ì¶œì‹œ ì§í›„ì—ëŠ” ìë™ì°¨ íŒ¬, ì†Œë¹„ì, ìë™ì°¨ ë¦¬ë·°ì–´, ì—…ê³„ ì „ë¬¸ê°€ë“¤ì´ ê°€ì¥ í™œë°œí•˜ê²Œ ë°˜ì‘í•˜ëŠ” ì‹œê¸°ì¸ë°, ê´€ì‹¬ë„ê°€ ë†’ì•„ì§ì— ë”°ë¼ SNS, ì»¤ë®¤ë‹ˆí‹°, ìœ íŠœë¸Œ ë“±ì—ì„œ ë‹¤ì–‘í•œ ì˜ê²¬ì´ ë¹ ë¥´ê²Œ í˜•ì„±ëœë‹¤.
        - ì¶œì‹œ ì‹œì ì—ëŠ” ì½˜í…ì¸ (ë¦¬ë·°, ëŒ“ê¸€, ê²Œì‹œê¸€, ì˜ìƒ ë“±)ê°€ í­ë°œì ìœ¼ë¡œ ì¦ê°€í•˜ê¸° ë•Œë¬¸ì— ë¶„ì„ì— í•„ìš”í•œ ë°ì´í„° í™•ë³´ê°€ ì‰½ë‹¤.
    - SNSëŠ” ì†Œë¹„ìì˜ ì˜ê²¬ì´ ê°€ì¥ ì¦‰ê°ì ìœ¼ë¡œ ë°˜ì˜ë˜ëŠ” ê³µê°„ì´ë‹¤
        - SNSëŠ” ì‚¬ëŒë“¤ì´ ì œí’ˆì´ë‚˜ ë¸Œëœë“œì— ëŒ€í•´ ê°€ì¥ ë¹ ë¥´ê³  ì§ì ‘ì ìœ¼ë¡œ ì˜ê²¬ì„ ê³µìœ í•˜ëŠ” í”Œë«í¼ì´ë‹¤.
    - ì‹ ì°¨ ì¶œì‹œ ì§í›„, ìœ íŠœë¸Œ ë¦¬ë·°, ì¸ìŠ¤íƒ€ê·¸ë¨ ê²Œì‹œë¬¼, ì»¤ë®¤ë‹ˆí‹° ê²Œì‹œê¸€ ë° ëŒ“ê¸€ ë“±ì„ í†µí•´ ì†Œë¹„ì ë°˜ì‘ì´ ì‹¤ì‹œê°„ìœ¼ë¡œ ë‚˜íƒ€ë‚œë‹¤.
    - **ìš”ì¦˜ì€ ê´‘ê³  ë³´ë‹¤ëŠ” SNSë¥¼ ë¯¿ëŠ” ë¶„ìœ„ê¸°ê°€ í˜•ì„±ë¨**
        - ìë™ì°¨ êµ¬ë§¤ìë“¤ì€ ì´ì œ ì „í†µì ì¸ ê´‘ê³ ë³´ë‹¤ ì‹¤ì œ ì‚¬ìš©ì ë¦¬ë·°, SNS ì¸í”Œë£¨ì–¸ì„œ ì˜ê²¬, ì˜¨ë¼ì¸ ì»¤ë®¤ë‹ˆí‹° í† ë¡ ì„ ë” ì‹ ë¢°í•˜ëŠ” ê²½í–¥ì´ ìˆë‹¤.
    - ì „í†µì ì¸ ë°©ë²•ë³´ë‹¤ ì €ë ´í•œ ë°©ì‹ì´ë‹¤.
        - ì „í†µì ì¸ ì†Œë¹„ì ì¡°ì‚¬(ì„¤ë¬¸ì¡°ì‚¬, FGI ë“±)ëŠ” ì‹œê°„ê³¼ ë¹„ìš©ì´ ë§ì´ ë“¤ì§€ë§Œ, SNS ë¶„ì„ì€ ì‹¤ì‹œê°„ìœ¼ë¡œ ë°©ëŒ€í•œ ë°ì´í„°ë¥¼ ìë™ ìˆ˜ì§‘Â·ë¶„ì„í•  ìˆ˜ ìˆì–´ ë¹„êµì  íš¨ìœ¨ì ì´ë‹¤.

### ì†Œë¹„ìë“¤ì˜ ë°˜ì‘ì„ ëª¨ë‹ˆí„°ë§

- ì™œ ì†Œë¹„ì ë°˜ì‘ì´ ì¤‘ìš”í•œê°€?
    - ì‹ ì°¨ ì¶œì‹œ ì§í›„ ì†Œë¹„ìë“¤ì˜ ë°˜ì‘ì€ ì œí’ˆ ì„±ê³µ ì—¬ë¶€ë¥¼ ê²°ì •ì§“ëŠ” ì¤‘ìš”í•œ ìš”ì†Œì´ë‹¤.
    - ì˜ˆìƒì¹˜ ëª»í•œ ë¬¸ì œ(ì˜ˆ: ê²°í•¨, ë¶ˆí¸í•œ ê¸°ëŠ¥, ë””ìì¸ ë…¼ë€)ê°€ ë°œìƒí•  ê²½ìš°, ì´ë¥¼ ì¡°ê¸°ì— ê°ì§€í•˜ê³  ì‹ ì†í•˜ê²Œ ëŒ€ì‘í•´ì•¼ ë¸Œëœë“œ ì‹ ë¢°ë„ë¥¼ ìœ ì§€í•  ìˆ˜ ìˆë‹¤.
    - í˜„ëŒ€ ìë™ì°¨ì™€ ê°™ì€ ê¸€ë¡œë²Œ ë¸Œëœë“œëŠ” ì†Œë¹„ìë“¤ì˜ ì¸ì‹ì´ ê¸°ì—…ì˜ ì¥ê¸°ì ì¸ ì„±ê³µì— ì¤‘ìš”í•œ ì˜í–¥ì„ ë¯¸ì¹¨
    - ì‹¤ì œ ì†Œë¹„ìë“¤ì˜ ì§„ì§œ ë‹ˆì¦ˆë¥¼ íŒŒì•…í•  ìˆ˜ ìˆë‹¤.
        - ìë™ì°¨ ì—…ê³„ì—ì„œëŠ” ì¢…ì¢… ë‚´ë¶€ì ì¸ ê°€ì„¤ì— ê¸°ë°˜í•œ ì œí’ˆ ê¸°íšì´ ì´ë£¨ì–´ì§€ì§€ë§Œ, ì‹¤ì œ ì†Œë¹„ìë“¤ì´ ì›í•˜ëŠ” ê¸°ëŠ¥ê³¼ ê¸°ëŒ€í•˜ëŠ” ì ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ
        - SNS ë° ì»¤ë®¤ë‹ˆí‹°ì—ì„œ ì†Œë¹„ìë“¤ì´ ì§ì ‘ ì–¸ê¸‰í•˜ëŠ” ë¶ˆë§Œ ì‚¬í•­ê³¼ ê°œì„  ìš”ì²­ì„ ë¶„ì„í•˜ë©´, ì´í›„ ëª¨ë¸ ê°œë°œ ë° ë§ˆì¼€íŒ… ì „ëµì„ ë³´ë‹¤ ì†Œë¹„ì ì¤‘ì‹¬ìœ¼ë¡œ ì¡°ì •í•  ìˆ˜ ìˆìŒ
    - ë§ˆì¼€íŒ… ì „ëµì— ëŒ€í•œ ë°©í–¥ì„± ì„¤ì •
        - ì†Œë¹„ìë“¤ì˜ ë°˜ì‘ì„ ë¶„ì„í•˜ì—¬ ì–´ë–¤ ì ì„ ê°•ì¡°í• ì§€, ì–´ë–¤ ë©”ì‹œì§€ë¥¼ ì „ë‹¬í• ì§€ ìµœì í™” ê°€ëŠ¥
    - ìœ„ê¸° ëŒ€ì‘
        - ì œí’ˆ ì¶œì‹œ í›„ ê°€ì¥ ìš°ë ¤ë˜ëŠ” ê²ƒì€ ì˜ˆìƒì¹˜ ëª»í•œ ë¬¸ì œ(ë¦¬ì½œ, í’ˆì§ˆ ê²°í•¨ ë“±)ê°€ ë°œìƒí–ˆì„ ë•Œ ê¸°ì—…ì´ ëŠ¦ê²Œ ëŒ€ì‘í•˜ëŠ” ê²ƒ
        - ì‹¤ì‹œê°„ìœ¼ë¡œ ì†Œë¹„ìë“¤ì˜ ë¶ˆë§Œ ì‚¬í•­ì„ ì¶”ì í•˜ë©´, ë¬¸ì œê°€ ì»¤ì§€ê¸° ì „ì— ë¹ ë¥´ê²Œ ëŒ€ì‘í•  ìˆ˜ ìˆìŒ

### íŠ¹ì • ì´ìŠˆì— ëŒ€í•œ ëŒ€í™”ê°€ ì–¼ë§ˆë‚˜ ì´ë£¨ì–´ì§€ê³  ìˆëŠ”ì§€ë¥¼ ëª¨ë‹ˆí„°ë§

- ì´ìŠˆì˜ ì¤‘ìš”ë„ ë¥¼ íŒŒì•…í•˜ê¸° ìœ„í•¨ì´ë‹¤.
    - ë‹¨ìˆœíˆ ì˜ê²¬ì„ ìˆ˜ì§‘í•˜ëŠ” ê²ƒë³´ë‹¤ëŠ” íŠ¹ì • ì´ìŠˆê°€ ì–¼ë§ˆë‚˜ ë§ì€ ì‚¬ëŒë“¤ì—ê²Œ íšŒìë˜ê³  ìˆëŠ”ì§€ë¥¼ ë¶„ì„í•´ì•¼í•œë‹¤.
    - ë¬¸ì œì˜ ì‹¬ê°ì„±ê³¼ ê¸°ì—…ì´ ëŒ€ì‘í•  ìš°ì„ ìˆœìœ„ë¥¼ ë§¤ê¸¸ ìˆ˜ ìˆë‹¤.
- ì´ìŠˆì˜ ì–‘? ì´ ì•„ë‹Œ ë§¥ë½ì´ ì¤‘ìš”í•˜ê¸° ë•Œë¬¸ì´ë‹¤.
    - ë‹¨ìˆœíˆ ì˜ê²¬ì´ ì–¼ë§ˆë‚˜ ì´ë£¨ì–´ì¡Œëƒë„ ì¤‘ìš”í•˜ì§€ë§Œ, íŠ¹ì • ì´ìŠˆê°€ ì™œ ì´ë£¨ì–´ì¡ŒëŠ”ì§€ë„ ì•Œ ìˆ˜ ìˆê¸° ë•Œë¬¸
- í˜„ì¬ ì‹œì¥ì˜ íŠ¸ë Œë“œì™€ íŒ¨í„´ ë¶„ì„ì´ ê°€ëŠ¥í•˜ë¯€ë¡œ

### ì•Œë¦¼ì„ ì œê³µ

- ì™œ ì•Œë¦¼ì„ ì¤˜ì•¼í•˜ëŠ”ê°€?
    - ì¦‰ê°ì ì¸ ë°˜ì‘ì€ ë¬¸ì œ í•´ê²°ì— ë§¤ìš° ì¤‘ìš”í•¨
    - ì˜ˆë¥¼ ë“¤ì–´, íŠ¹ì • ë¶€í’ˆì˜ ê²°í•¨ì´ë‚˜ ì‹ ì°¨ ë””ìì¸ì— ëŒ€í•œ ë¶€ì •ì ì¸ ë°˜ì‘ì´ ê¸‰ê²©íˆ í™•ì‚°ë  ê²½ìš°, ë¹ ë¥¸ ì‹œê°„ ë‚´ì— **ì•Œë¦¼ì„ í†µí•´ í•´ë‹¹ ì´ìŠˆë¥¼ ë‹´ë‹¹ìì—ê²Œ ì „ë‹¬**í•¨ìœ¼ë¡œì¨ ì¦‰ì‹œ ëŒ€ì‘í•  ìˆ˜ ìˆìŒ
    - ë¹„ì¦ˆë‹ˆìŠ¤ ë¦¬ìŠ¤í¬ë¥¼ ìµœì†Œí™” ê°€ëŠ¥
    - ì¦‰ì‹œ ì†Œë¹„ìì—ê²Œ ê´€ë ¨ ì‚¬í•­ì„ ì•ˆë‚´í•˜ê±°ë‚˜, í•´ê²° ë°©ì•ˆì„ ì œê³µí•  ìˆ˜ ìˆìŒ

## ì»¤ë®¤ë‹ˆí‹°ë¥¼ í¬ë¡¤ë§í•´ë³´ê¸°

- ë””ì‹œì¸ì‚¬ì´ë“œì™€ í´ë¦¬ì•™ì´ë¼ëŠ” ì»¤ë®¤ë‹ˆí‹°ë¥¼ â€˜ì•„ë°˜ë–¼â€™ë¼ëŠ” í‚¤ì›Œë“œë¥¼ ê°€ì§€ê³  í¬ë¡¤ë§ì„ í•´ë³´ì•˜ë‹¤.

```python
# í´ë¦¬ì•™

# ì—¬ëŸ¬ í˜ì´ì§€ í¬ë¡¤ë§
for page in range(0, max_pages):
    print(f"ğŸ“Œ í˜„ì¬ {page + 1} í˜ì´ì§€ í¬ë¡¤ë§ ì¤‘...")

    # ê²€ìƒ‰ ê²°ê³¼ í˜ì´ì§€ URL ìƒì„±
    search_url = base_url.format(search_keyword, page)

    # í˜ì´ì§€ ìš”ì²­
    response = requests.get(search_url, headers=headers)
    
    if response.status_code != 200:
        print(f"âŒ í˜ì´ì§€ {page} ìš”ì²­ ì‹¤íŒ¨ (ìƒíƒœ ì½”ë“œ: {response.status_code})")
        break

    # BeautifulSoup ê°ì²´ ìƒì„±
    soup = BeautifulSoup(response.text, 'html.parser')

    # ê²Œì‹œê¸€ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
    posts = soup.select("div.list_item")

    for post in posts:
        board_name = post.select_one("button.shortname.fixed")  # ê²Œì‹œíŒëª…
        title_tag = post.select_one("a.subject_fixed")  # ê²Œì‹œê¸€ ì œëª©
        author = post.select_one("span.nickname span")  # ì‘ì„±ì
        date = post.select_one("div.list_time span.timestamp")  # ì‘ì„± ë‚ ì§œ
        views = post.select_one("div.list_hit span.hit")  # ì¡°íšŒìˆ˜
        comments = post.select_one("a.list_reply span.rSymph05")  # ëŒ“ê¸€ ìˆ˜

        if title_tag and board_name:
            post_url = "https://www.clien.net" + title_tag['href']  # ê²Œì‹œê¸€ URL

            print(f"ğŸ”— ê²Œì‹œê¸€ ë°©ë¬¸: {title_tag.text.strip()}")
            print(f"   ğŸ‘‰ URL: {post_url}")

            # ê²Œì‹œê¸€ í˜ì´ì§€ ë°©ë¬¸í•˜ì—¬ ë³¸ë¬¸ê³¼ ì¢‹ì•„ìš” ìˆ˜ ê°€ì ¸ì˜¤ê¸°
            post_response = requests.get(post_url, headers=headers)
            if post_response.status_code != 200:
                print(f"âš ï¸ ê²Œì‹œê¸€ ìš”ì²­ ì‹¤íŒ¨: {post_url}")
                continue

            post_soup = BeautifulSoup(post_response.text, 'html.parser')

            # ë³¸ë¬¸ ì¶”ì¶œ
            content_tag = post_soup.select_one("div.post_article")
            content = "\n".join([p.text.strip() for p in content_tag.find_all("p")]) if content_tag else "ë³¸ë¬¸ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ"

            # ì¢‹ì•„ìš” ìˆ˜ ì¶”ì¶œ
            like_tag = post_soup.select_one("a.symph_count.disable strong")
            likes = like_tag.text.strip() if like_tag else "0"  # ì¢‹ì•„ìš” ìˆ˜ê°€ ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ì²˜ë¦¬

            # ë°ì´í„° ì €ì¥
            board_list.append({
                "ê²Œì‹œíŒ": board_name.text.strip(),
                "ì œëª©": title_tag.text.strip(),
                "URL": post_url,
                "ì‘ì„±ì": author.text.strip() if author else "N/A",
                "ì‘ì„±ì¼": date.text.strip() if date else "N/A",
                "ì¡°íšŒìˆ˜": views.text.strip() if views else "N/A",
                "ëŒ“ê¸€ ìˆ˜": comments.text.strip() if comments else "0",
                "ì¢‹ì•„ìš” ìˆ˜": likes,
                "ë³¸ë¬¸": content
            })

            time.sleep(2)  # ì°¨ë‹¨ ë°©ì§€ë¥¼ ìœ„í•´ ëŒ€ê¸°

```

```python
# ë””ì‹œ 
# ë©€í‹°í”„ë¡œì„¸ì‹± ì´ìš©

# ê²°ê³¼ ì €ì¥ ë¦¬ìŠ¤íŠ¸
results = []

# ê²Œì‹œê¸€ ìƒì„¸ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
def fetch_post_details(post_url):
    try:
        post_response = requests.get(post_url, headers=headers, timeout=5)
        if post_response.status_code != 200:
            return None

        post_soup = BeautifulSoup(post_response.text, 'html.parser')

        # ê²Œì‹œê¸€ ì œëª©
        title_tag = post_soup.find("span", class_="title_subject")
        title = title_tag.get_text(strip=True) if title_tag else "ì œëª© ì—†ìŒ"

        # ê²Œì‹œê¸€ ë‚´ìš©
        content_tag = post_soup.find("div", class_="write_div")
        content = content_tag.get_text(strip=True) if content_tag else "ë‚´ìš© ì—†ìŒ"

        # ê²Œì‹œê¸€ ë‚ ì§œ
        date_tag = post_soup.find("span", class_="gall_date")
        date_str = date_tag.get_text(strip=True) if date_tag else "ë‚ ì§œ ì—†ìŒ"
        try:
            post_date = datetime.strptime(date_str, "%Y.%m.%d %H:%M:%S")
            post_date = post_date.strftime("%Y-%m-%d %H:%M:%S")
        except ValueError:
            post_date = "ë‚ ì§œ ë³€í™˜ ì‹¤íŒ¨"

        # ì‘ì„±ì
        nickname_tag = post_soup.find("span", class_="nickname")
        nickname = nickname_tag.get_text(strip=True) if nickname_tag else "ìµëª…"

        # IP ì£¼ì†Œ
        ip_tag = post_soup.find("span", class_="ip")
        ip = ip_tag.get_text(strip=True).replace("(", "").replace(")", "") if ip_tag else "IP ì—†ìŒ"

        # ì¶”ì²œ ìˆ˜
        recommend_tag = post_soup.find("p", class_="up_num")
        recommend_count = recommend_tag.get_text(strip=True) if recommend_tag else "0"

        # ë¹„ì¶”ì²œ ìˆ˜
        dislike_tag = post_soup.find("p", class_="down_num")
        dislike_count = dislike_tag.get_text(strip=True) if dislike_tag else "0"

        # ëŒ“ê¸€ ìˆ˜
        comment_tag = post_soup.find("span", id=lambda x: x and x.startswith("comment_total"))
        comment_count = comment_tag.get_text(strip=True) if comment_tag else "0"

        # ì¡°íšŒìˆ˜
        view_count_tag = post_soup.find("span", class_="gall_count")
        view_count = view_count_tag.get_text(strip=True).replace("ì¡°íšŒ ", "") if view_count_tag else "0"

        return {
            "title": title,
            "url": post_url,
            "date": post_date,
            "author": f"{nickname} ({ip})",
            "content": content,
            "views": view_count,
            "recommend": recommend_count,
            "dislike": dislike_count,
            "comments": comment_count
        }
    except Exception as e:
        print(f"ê²Œì‹œê¸€ {post_url} í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
        return None

# ì—¬ëŸ¬ í˜ì´ì§€ì˜ ê²Œì‹œê¸€ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
def fetch_page_posts(page):
    search_url = base_url.format(page)
    response = requests.get(search_url, headers=headers, timeout=5)
    
    if response.status_code != 200:
        print(f"í˜ì´ì§€ {page} ìš”ì²­ ì‹¤íŒ¨ (ìƒíƒœ ì½”ë“œ: {response.status_code})")
        return []

    soup = BeautifulSoup(response.text, 'html.parser')
    posts = soup.select("ul.sch_result_list li")

    post_urls = []
    for post in posts:
        title_tag = post.find("a", class_="tit_txt")
        if title_tag:
            post_urls.append(title_tag["href"])

    return post_urls

# ë³‘ë ¬ í¬ë¡¤ë§ ì‹¤í–‰
with ThreadPoolExecutor(max_workers=10) as executor:  # 10ê°œì˜ ìŠ¤ë ˆë“œ ì‚¬ìš©
    # 1. ê²Œì‹œê¸€ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (ê° í˜ì´ì§€ í¬ë¡¤ë§)
    future_to_page = {executor.submit(fetch_page_posts, page): page for page in range(1, max_pages + 1)}

    all_post_urls = []
    for future in as_completed(future_to_page):
        post_urls = future.result()
        if post_urls:
            all_post_urls.extend(post_urls)

    print(f"ì´ {len(all_post_urls)} ê°œì˜ ê²Œì‹œê¸€ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")

    # 2. ê²Œì‹œê¸€ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ë³‘ë ¬ ì‹¤í–‰)
    future_to_post = {executor.submit(fetch_post_details, post_url): post_url for post_url in all_post_urls}

    for future in as_completed(future_to_post):
        post_data = future.result()
        if post_data:
            results.append(post_data)

# DataFrameìœ¼ë¡œ ë³€í™˜
df = pd.DataFrame(resul
```

```python
# ë””ì‹œ
# ë©€í‹° í”„ë¡œì„¸ì‹± ì´ìš© x

# ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
results = []

# ì—¬ëŸ¬ í˜ì´ì§€ ìˆœíšŒ
for page in range(1, max_pages + 1):
    print(f"í˜„ì¬ {page} í˜ì´ì§€ í¬ë¡¤ë§ ì¤‘...")

    # í˜ì´ì§€ë³„ ê²€ìƒ‰ URL ìƒì„±
    search_url = base_url.format(page)

    # í˜ì´ì§€ ìš”ì²­
    response = requests.get(search_url, headers=headers)
    if response.status_code != 200:
        print(f"í˜ì´ì§€ {page} ìš”ì²­ ì‹¤íŒ¨ (ìƒíƒœ ì½”ë“œ: {response.status_code})")
        break

    soup = BeautifulSoup(response.text, 'html.parser')

    # ê²Œì‹œê¸€ ëª©ë¡ ì¶”ì¶œ
    posts = soup.select("ul.sch_result_list li")

    # ê²Œì‹œê¸€ì´ ì—†ìœ¼ë©´ ì¢…ë£Œ
    if not posts:
        print("ë” ì´ìƒ ê²Œì‹œê¸€ì´ ì—†ìŠµë‹ˆë‹¤. í¬ë¡¤ë§ ì¢…ë£Œ.")
        break

    for post in posts:
        # ê²Œì‹œê¸€ ì œëª©ê³¼ URL
        title_tag = post.find("a", class_="tit_txt")
        if title_tag:
            title = title_tag.get_text(strip=True)
            post_url = title_tag["href"]
        else:
            continue

        # ê²Œì‹œê¸€ ìƒì„¸ í˜ì´ì§€ ìš”ì²­
        post_response = requests.get(post_url, headers=headers)
        if post_response.status_code != 200:
            print(f"ê²Œì‹œê¸€ {post_url} ìš”ì²­ ì‹¤íŒ¨, ê±´ë„ˆëœ€")
            continue

        post_soup = BeautifulSoup(post_response.text, 'html.parser')

        # ê²Œì‹œê¸€ ë‚´ìš©
        content_tag = post_soup.find("div", class_="write_div")
        content = content_tag.get_text(strip=True) if content_tag else "ë‚´ìš© ì—†ìŒ"

        # ê²Œì‹œê¸€ ë‚ ì§œ
        date_tag = post_soup.find("span", class_="gall_date")
        date_str = date_tag.get_text(strip=True) if date_tag else "ë‚ ì§œ ì—†ìŒ"
        try:
            post_date = datetime.strptime(date_str, "%Y.%m.%d %H:%M:%S")
            post_date = post_date.strftime("%Y-%m-%d %H:%M:%S")
        except ValueError:
            post_date = "ë‚ ì§œ ë³€í™˜ ì‹¤íŒ¨"

        # ì¶”ì²œ ìˆ˜
        recommend_tag = post_soup.find("p", class_="up_num")
        recommend_count = recommend_tag.get_text(strip=True) if recommend_tag else "0"

        # ë¹„ì¶”ì²œ ìˆ˜
        dislike_tag = post_soup.find("p", class_="down_num")
        dislike_count = dislike_tag.get_text(strip=True) if dislike_tag else "0"

        # ëŒ“ê¸€ ìˆ˜
        comment_tag = post_soup.find("span", id=lambda x: x and x.startswith("comment_total"))
        comment_count = comment_tag.get_text(strip=True) if comment_tag else "0"
        
        # ì¡°íšŒìˆ˜
        view_count_tag = post_soup.find("span", class_="gall_count")
        view_count = view_count = view_count_tag.get_text(strip=True).replace("ì¡°íšŒ ", "") if view_count_tag else "0"

        # ì‘ì„±ì ë‹‰ë„¤ì„
        nickname_tag = post_soup.find("span", class_="nickname")
        nickname = nickname_tag.get_text(strip=True) if nickname_tag else "ìµëª…"

        # ì‘ì„±ì IP
        ip_tag = post_soup.find("span", class_="ip")
        ip = ip_tag.get_text(strip=True).replace("(", "").replace(")", "") if ip_tag else "IP ì—†ìŒ"

        # ê²°ê³¼ ì €ì¥
        results.append({
            "title": title,
            "url": post_url,
            "date": post_date,
            "content": content,
            "author": f"{nickname} ({ip})",  # ì‘ì„±ì + IP ì¶”ê°€
            "views": view_count,
            "recommend": recommend_count,
            "dislike": dislike_count,
            "comments": comment_count
        })

        # ìš”ì²­ ì‚¬ì´ ë”œë ˆì´ ì¶”ê°€ (ê³¼ë¶€í•˜ ë°©ì§€)
        time.sleep(1)
```

í™•ì‹¤í•œ Use Caseê°€ ì—†ì–´ì„œ ê·¸ëŸ°ì§€ ì¡°ê¸ˆ ë§‰ë§‰í•˜ë‹¤.. ë˜í•œ ë©€í‹° í”„ë¡œì„¸ì‹±ì„ ì´ìš©í•´ì„œ í¬ë¡¤ë§ì„ í–ˆë”ë‹ˆ IPê°€ ë§‰í˜€ë²„ë ¸ë‹¤. ì´ëŸ´ ë• ì–´ë–»ê²Œ ëŒ€ì²˜í•´ì•¼í• ì§€ëŠ” ë” ê³µë¶€ì™€ ë°©ë²•ë¡ ì— ëŒ€í•œ ì—°êµ¬ê°€ í•„ìš”í•  ë“¯ í•˜ë‹¤..

---

# ğŸ” íšŒê³  (KPT)

## âœ… Keep

- ì˜¤ëŠ˜ì€ ì§„í–‰ ì‚¬í•­ì„ ëª¨ë‘ ê¸°ë¡í–ˆë‹¤. ë¬¼ë¡  í‰ì†Œì—ë„ ê¸°ë¡ì„ í–ˆì§€ë§Œ, ì˜¤ëŠ˜ì€ íŠ¹íˆ ëª¨ë“  ê³¼ì • (ìƒê° + ì‘ì—…)ê³¼ ê³ ë¯¼í–ˆë˜ ê²ƒ, ìŠ¤ì³ê°”ë˜ ê²ƒ ë“± ì •ë§ ëª¨ë“  ê²ƒì„ ì ì—ˆë‹¤. ê·¸ë¬ë”ë‹ˆ í‡´ê·¼ ì „ì— ë¦¬ë·°ë¥¼ ì§„í–‰í–ˆì„ ë•Œ ê¸€ë“¤ì„ ì­‰ ì½ì–´ë³´ë‹ˆ, í™•ì‹¤íˆ ìƒê°ì´ ë»—ì–´ê°ˆ ìˆ˜ ìˆëŠ” ê°€ì§€ê°€ ë§ì•„ì¡ŒìŒì„ ëŠê¼ˆë‹¤. ë‚´ì¼ ì•„ì¹¨ ìŠ¤í¬ëŸ¼ ë•Œ íŒ€ì›ë“¤ì—ê²Œ ì´ ìƒê°ì„ ì •ë¦¬í•´ì„œ ë³´ì—¬ì¤˜ì•¼ê² ë‹¤.

## ğŸ’¡ Try

- ê³¼ë„í•œ requestsë¡œ ì¸í•œ IPê°€ ë§‰í˜”ì„ ë•Œ ì–´ë–»ê²Œ ëŒ€ì²˜í•˜ê³  ë‹¤ë¥¸ ë°©ì‹ì€ ë¬´ì—‡ì´ ìˆì„ì§€ ê³ ë¯¼í•´ë³´ìâ€¦
---
