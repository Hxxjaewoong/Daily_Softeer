# 📅 2025.02.10 리뷰 & 회고

---

# 📝 리뷰

## Apache Spark Job 최적화  

### 1⃣ Spark 최적화 경우  
- **컴퓨팅 효율성(computation efficiency)과 노드 간 통신 최소화**  
- **RDD vs DataFrame**  
  - DataFrame이 성능 원천 (cd5c적화 적용 가능)  
  - RDD는 메모리 제어 및 컴저러운 연산에 유능  
  - 비정형 데이터(텍스트, 반이리 파일 등) 처리 시 RDD 활용  

---

### 2⃣ 데이터 저장 형식 및 압축 최적화  
- **Parquet, ORC(컬럼 저장 방식) + Snappy, LZ4 압축** → 성능 향상 및 저장 공간 절약  
- **컬럼 저장 방식(Columnar Storage)의 재상**  
  - ✅ **압축 효율** (유사한 데이터 타입께서 압축 최적화)  
  - ✅ **컬럼 단위 검색** (불필요한 컬럼 읽기 방지)  
  - ✅ **Aggregation 성능 향상** (단일 컬럼 연산 최적화)  
  - ✅ **Predicate Pushdown** → 불필요한 데이터 로딩 방지  

- **RDS vs Redshift 비교**  
  - **RDS**: 트랜저택션(OLTP), 함 기반 저장(row-based)  
  - **Redshift**: 분석(OLAP) 최적화, 컬럼 저장(columnar)  

---

### 3⃣ 메모리 관리 및 캐시밍 전략  
- **Spark 메모리 구조**
  - **Storage Memory**: RDD 캐시발  
  - **Execution Memory**: Shuffle, Join, Sort 등 입신 데이터 저장  
  - **User Memory**: RDD 변환 연산 저장  
  - **Reserved Memory**: Spark 내부 객체 저장  

- **Cache vs Persist vs Checkpoint 차이**  
  - `Cache`: 메모리에 저장, 재계산 가능 (라인리지 유지)  
  - `Persist`: 특정 저장 레벨 지정 가능 (`MEMORY_AND_DISK` 기본값)  
  - `Checkpoint`: HDFS/S3에 저장, 라인리지 제거 (장기 실행 Job에 유용)  

---

### 4⃣ Shuffle 최적화 및 데이터 스큐 해결  
- **Shuffle 원인**  
  - `groupByKey`, `reduceByKey`, `join` 등에서 발생  
  - 데이터 불교효(Data Skew)으로 특정 키에 데이터 집중  

- **최적화 방법**  
  - ✅ `sortWithinPartitions()` → 전체 Sort 대시 파티션 내 정렬  
  - ✅ `repartitionByRange()` → Range 기반 파티션  
  - ✅ `filter + agg` 활용 → `groupBy` 연산 최소화  

- **데이터 스큐 해결 방법**  
  - **Salting**: 키에 난수 추가해서 데이터 분산  
    ```python
    from pyspark.sql.functions import rand
    df = df.withColumn('salted_key', df['city'] + (rand()*10).cast("int"))
    ```
  - **Broadcast Join**: 작은 데이터셋을 브로더캐스트해서 Shuffle 최소화  
    ```python
    from pyspark.sql.functions import broadcast
    df1.join(broadcast(df2), 'id')
    ```

---

# 🔍 회고 (KPT)

## ✅ Keep

- 점심 시간, 퇴근 시간 이후에도 꾸준히 부족한 부분을 채워가려고 한 것..

## ⚠️ Problem

- 일정을 따라가지 못한 것..
    - 하나의 일에 꽂혀서 다른 일을 못했다. 일정을 정해놓고 작업을 하는 만큼, 시간 관리 및 작업 분배에 더 신경을 쓰자.

---