# 📅 2025.01.20

---

# 리뷰 & 회고

---

### 하둡 이해해보기
> Assumptions and Goals of HDFS
- Hardware Failure
    - 시스템 전체의 신뢰성을 보장하기 위해 데이터를 복제 하여 하드웨어 장애에도 데이터의 가용성을 유지하는 것
- Streaming Data Access
    - 스트리밍 방식의 데이터 처리에 최적화 ==> 데이터를 대규모로 분석하거나 처리하는 작업 지원
- Large Data Sets
    - 페타바이트 수준의 데이터를 처리해야함 ==> 처리 성능을 높이기 위하여 블록 단위로 나눔
- Simple Coherency Model
    - WORM(Write Once Read Many) ==> 데이터 수정보다는 데이터를 추가적으로 저장하는 경우에 최적화 
    - 파일 동시 수정 필요성을 제거함 ==> 데이터 일관성 문제 해결
    - **데이터 처리량 (Throughput)을 높이는데 기여함**
    - 그러나 스토리지를 많이 쓰는 단점이 있는 듯?
- “Moving Computation is Cheaper than Moving Data”
    - 대규모 데이터 전송은 네트워크 병목 가능성이 있음
    - 데이터를 처리하는 프로그램을 데이터가 저장된 노드로 이동시켜 데이터 로칼리티를 활용함. 
- Portability Across Heterogeneous Hardware and Software Platforms

> NameNode & DataNode
- NameNode
    - 파일 시스템 메타데이터를 관리 ==> 파일과 디렉토리가 저장된 위치와 구조를 추적 
    - 만약 NameNode가 고장나면..? ==> Standby NameNode가 존재하는 듯
- DataNode
    - 실제 저장소 역할
    - 안정적 저장을 위해 블록을 복제 해놓음
    - 주기적으로 NameNode에 작동 상태 알림
- 이 두 구성 요소가 협력하면서 HDFS는 대규모 분산 처리

> Data Locality
- 분산 처리에서 데이터를 처리하는 작업을 데이터가 저장된 노드로 이동시켜 네트워크 병목을 줄이고 성능을 최적화하는 것


> Yarn
- Resource Manager + Job scheduler의 역할을 함
- Resource Manager: 각 노드의 Node Manager와 통신하며 하드웨어 자원 모니터링과 관리하며, 요청을 받으면 추가 자원(컨테이너)을 할당해줌
- Application Manager: 제출된 작업의 유효성 검사 후 스케줄러 호출
- Scheduler: 임의의 slave container에게 작업을 할당함
- Application Master: Application 상의 job scheduling, monitoring 역할을 하며, Application의 실행과 에러처리까지 담당

> MapReduce
- Map -> Shuffle -> Reduce


---

## 🔍 회고 (KPT)

### ✅ Keep
- 다노님의 강의가 끝난 후, 각자 이해한 것, 이해하지 못 한 것, 궁금했던 것들에 대해 팀원들과 토의해보는 것 ==> 나만의 시각이 아닌 다른 사람의 베이스로 쌓인 이해를 알 수 있어서 더 많은 지식을 품게 되었던 것 같다.


### ⚠️ Problem
- 기본을 갖추지 않은 채로 기술을 시도한 것 ==> 하둡에 대한 개념 및 지식 등에 대한 기본적인 이해가 완전히 되지 않은 채로 미션을 수행하려고 한 것이 문제 **[공부든 운동이든 결국엔 기본기가 중요하듯 기본기를 잘 익히자..]**


### 💡 Try
- 하둡에 대한 개념을 다시 처음부터 적립한 후 미션 이해 및 수행하기


---
