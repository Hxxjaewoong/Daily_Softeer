# 📅 2025.01.23 리뷰 & 회고

---

## 📝 리뷰

### **core-site.xml ⇒ Hadoop Common**

- **fs.defaultFS**:
    
    기본 파일 시스템 URI를 지정한다. 보통 `hdfs://namenode:port/`와 같은 형식을 사용하며, 클러스터 환경에서 HDFS의 진입점 역할을 한다.
    
    - **사용 시나리오**:
        
        클러스터의 파일 시스템 URI를 지정하여 애플리케이션이 데이터를 읽고 쓸 파일 시스템을 결정한다.
        
    - **변경 필요 상황**:
        - 클러스터 환경에서 HDFS 주소가 변경된 경우.
- **hadoop.tmp.dir**:
    
    Hadoop의 임시 데이터를 저장하는 디렉토리를 지정합니다. 기본적으로 `/tmp`에 설정되며, 충분한 용량을 제공하는 디스크를 선택해야 한다.
    
    - 디스크가 꽉 차면 클러스터 작업에 장애가 발생할 수 있으므로, 디스크 모니터링과 자동 정리를 설정하는 것이 필요함 ⇒ 빠른 대응이 필요
    - **사용 시나리오**:
        
        Hadoop의 임시 데이터를 저장하는 공간으로 사용된다. 일반적으로 작업 중간 결과나 임시 파일이 저장됨.
        
    - **변경 필요 상황**:
        - **디스크 용량 부족**: 지정된 디렉토리가 꽉 차면 작업 실패 가능성이 있으므로, 용량이 큰 디스크로 이동하거나 다중 디렉토리로 분산해야 함.
- **io.file.buffer.size**:
    
    파일을 읽고 쓰는 동안 사용되는 버퍼 크기를 지정.
    
    - 기본값은 128KB로 대부분의 환경에서 적합하지만, 작업의 I/O 패턴에 따라 조정이 필요함
    - 대규모 파일 처리 시에는 버퍼 크기를 늘려 I/O 효율을 높이고, 소규모 파일 처리 시에는 작은 버퍼를 활용하여 메모리 낭비를 방지
    - **변경 필요 상황**:
        - **작업 특성 변화**: 작은 파일을 많이 처리하면 작은 버퍼를, 대용량 파일을 처리하면 큰 버퍼를 사용해야 효율적
        - I/O 속도가 낮은 경우 버퍼 크기를 조정하여 처리량을 높일 수 있을 듯?

---

### **hdfs-site.xml ⇒ Hadoop Distributed File System**

- **dfs.replication**:
    
    HDFS에서 파일의 복제본 수 (기본값은 3)
    
    - 데이터 손실 위험이 높은 환경에서는 복제본을 5 이상으로 늘릴 수 있음.
    - **변경 필요 상황**:
        - 중요한 데이터를 보호하려면 복제본 수를 늘려야 한다.
        - 테스트 환경에서는 복제본 수를 줄여 디스크 사용량을 줄일 수 있다
- **dfs.blocksize**:
    
    파일을 저장할 때 사용되는 기본 블록 크기를 정의
    
    - 큰 블록 크기는 NameNode 메타데이터 관리를 단순함 → 관리해야할 리소스는 줄어듦
    - 대신 작은 파일 처리 시 디스크 낭비를 초래할 듯
    - **작은 파일이 많을 때**: 블록 크기를 줄이면 스토리지 낭비를 줄일 수 있다.
    - **대용량 파일이 많을 때**: 블록 크기를 늘리면 NameNode 메타데이터 부담이 감소하고 처리 속도가 빨라질 수 있다.
- **dfs.namenode.name.dir**:
    
    NameNode의 메타데이터와 트랜잭션 로그를 저장하는 로컬 파일 시스템 경로를 지정하는 것
    
    - 디스크 장애를 대비해 여러 경로를 지정하여 데이터를 복제하고, 주기적인 백업을 수행하는 것이 좋다고 한다.
    - NameNode의 메타데이터와 트랜잭션 로그를 저장하는 경로를 설정
    - 관리를 안 하면 overflow 문제 발생

---

### **mapred-site.xml ⇒ MapReduce Framework**

- **mapreduce.framework.name**:
    
    사용 중인 MapReduce 프레임워크를 지정. 기본값은 `yarn`이며, YARN 위에서 MapReduce 작업을 실행
    
- **mapreduce.job.tracker**: Specifies the JobTracker host and port.
    - 최근 버전에서는 사용하지 않는다.
    - 옛날 것이므로 바꾸지 않아도 됨
- **mapreduce.task.io.sort.mb**:
    
    맵 출력 데이터를 정렬하는 동안 사용되는 메모리 크기를 정의
    
    - **변경 필요 상황**:
        - **네트워크 병목**: 데이터가 네트워크를 통해 전달되기 전에 정렬을 최적화하여 병목 현상을 줄이고자 할 때.

---

### **yarn-site.xml ⇒ YARN Resource Management**

- **yarn.resourcemanager.address**:
    
    ResourceManager의 IPC 주소를 지정
    
    - **변경 필요 상황**:
        - **ResourceManager 장애**: 마스터 노드 변경 시 새 주소로 업데이트해야 합니다.
        - **클러스터 리구성은** 새로운 ResourceManager 노드를 추가하거나 이전 노드를 대체할 때.
- **yarn.nodemanager.resource.memory-mb**:
    
    NodeManager가 사용할 수 있는 최대 메모리 용량을 정의
    
    - NodeManager에서 YARN 작업에 할당할 수 있는 최대 메모리 용량을 설정
- **yarn.scheduler.minimum-allocation-mb**:
    
    컨테이너 요청 시 할당되는 최소 메모리 크기를 정의
    
    - 작업 패턴에 따라 이 값을 조정하여 리소스 활용률을 극대화할 수 있. 예를 들어, 많은 소규모 작업이 동시에 실행된다면, 이 값을 낮게 설정하는 것이 유리


---

## 🔍 회고 (KPT)

### ✅ Keep
- 아는 만큼 들린다 ⇒ 이번주 월요일에 다노님의 강의 때는 사실 많은 것을 이해하진 못했다. 그래도 월요일 수업 이후, 오늘 진행되었던 수업 전까지 기본 개념을 잘 깔아보려고 노력했는데, 덕분에 오늘 강의는 이해가 되는 부분이 많았다. 물론 내가 놓친 부분도 있겠지만, 저번보다는 많은 것을 습득한 것 같다. 아는 만큼 들리는 법이므로 더 열심히 공부하자..!

### 💡 Try
- 많이 해보기 ⇒ 프로젝트를 수행하든 공부를 하든 결국 많이 해보는 사람이 승리한다

---
