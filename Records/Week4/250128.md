# 📅 2025.01.23 리뷰 & 회고

---

# 📝 리뷰

### 프로토 타입 작성해보기 (손으로라도)

![제목을-입력해주세요_-001.png](%E1%84%92%E1%85%AC%E1%84%80%E1%85%A9%20185c9b995f19808380b3d308766cad98/%E1%84%8C%E1%85%A6%E1%84%86%E1%85%A9%E1%86%A8%E1%84%8B%E1%85%B3%E1%86%AF-%E1%84%8B%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A7%E1%86%A8%E1%84%92%E1%85%A2%E1%84%8C%E1%85%AE%E1%84%89%E1%85%A6%E1%84%8B%E1%85%AD_-001.png)

### 문제점

- 나는 손으로 (PPT)로 하나하나 만들었는데 다른 팀원들은 AI 툴을 사용하거나 노션을 사용함 ⇒ 나보다 시간이 적게 들었음에도 불구하고 좋은 퀄리티가 나왔었음. 시간은 결국 돈.. 현명하게 일할 수 있는 방법을 항상 생각해보고 일을 해보자..

## Apache Spark 개인 공부

## 왜 Spark를 사용할까?

1. 속도
   - In-memory 컴퓨팅 방식을 활용하기 때문에 Hadoop MapReduce보다 빠른 연산
   - 디스크 I/O 의존도를 줄이고 자주 사용하는 데이터를 메모리에 유지해 연산 속도 향상 시키는 듯!
2. 편의성
   - 다양한 언어에 대해 고수준 API 제공
   - 복잡한 데이터 처리 로직도 간결하고 직관적인 코드로 작성이 가능하다고 한다.
3. 다양성
   - 배치 처리, 스트리밍 처리 등 다양하게 가능 → 하나의 엔진에서 다양한 분석 시나리오 처리
4. 통합 플랫폼

- 하나의 인터페이스만 배우면 결국 다 쓸 수 있다는 것!

## Apache Spark on JVM

- Scala 언어로 구현
- JVM 위에서 실행 → JVM을 잘 이해해야할 듯

## Cluster Manager Types

1. Standalone Mode
   - 스파크가 자체적으로 클러스터를 관리
   - **SparkContext가 클러스터 매니저 내부에**서 동작하며, 별도의 외부 리소스 관리자 없이 스파크 만으로 클러스터 환경을 구성 ⇒ YARN이나 Mesos, Kubernetes 같은 외부 자원 관리자 없이, Spark의 **Master**와 **Worker** 프로세스로 구성된 독립적인 클러스터를 구성
   - 배포는 간단하지만, 클러스터 관리 기능이 제한적
   - **Standalone의 뜻인 “자립형/독립형”라는 뜻에 맞게 Standalone 모드에서는 Master 노드가 Cluster Manager의 역할까지 수행**
2. YARN Mode
   - 스파크를 Yarn 위에서 실행 가능 → Yarn이 제공하는 자원 할당 및 관리 기능 활용
   - Hadoop 클러스터에서 Spark를 사용하려면 일반적으로 Yarn 모드를 많이 사용한다고 한다.
3. Mesos Mode
   - Mesos는 또 다른 클러스터 관리 플랫폼 → 스파크를 Mesos 위에서 실행 가능
   - 유연하고 확장 가능한 자원 관리를 통해 다양한 워크 로드를 한곳에서 운영 가능
4. Kubernetes Mode
   - Kubernetes는 컨테이너 오케스트레이션 플랫폼 → 스파크도 이 위에서 동작 가능
   - 클라우드 환경이나 컨테이너 중심의 인프라에서 스파크를 유연하게 운영하려 할 때 자주 사용한다고 함

## Spark 실행 배포 옵션

1. 로컬 실행

   - 단일 머신에서 스파크 앱 실행하는 방식

   ```bash
   spark-submit --master local[*]
   ```

2. Standalone Cluster
   - 스파크가 자체 내장된 클러스터 매니저를 사용해서 Master와 Worker 노드를 구성
   - Master Node: 클러스터 자원을 관리하고 애플리케이션 요청을 스케줄링 (하둡의 Resource Manager 같은 것…?!)
   - Worker Node: Master 노드의 지시에 따라 실제 작업 수행
3. Cluster Manager 활용
   - 외부 클러스터 매니저 (YARN, Mesos, Kubernetes) 위에서 Spark를 실행하는 방식

## Spark 아키텍처

Apache Spark의 중심에는 RDD (Resilient Distributed Dataset)가 있다. RDD는 fault-tolerance와 immutability를 특징으로 하며, 분산 환경에서 병렬로 처리가 가능한 데이터의 집합니다.

1. Driver Program
   - 전체 작업의 실행을 제어하고 작업을 여러 Task로 분할해 클러스터 매니저에게 전달
2. Cluster Manager (YARN, Mesos ….)
   - 클러스터의 자원을 할당하고 작업을 스케줄링
   - 클러스터 전체의 자원(CPU, 메모리, 스토리지 등)을 관리하고 작업을 스케줄링
   - Spark Driver가 요청하는 자원을 분배하고, 노드 상태를 모니터링
3. Executors
   - 각 노드에서 Task를 실제로 수행하고 RDD 연산을 수행

## Driver & Executors

Spark 애플리케이션은 **Driver**와 여러 개의 **Executor**로 구성

Agnostic하다는 걸 기억 ! (어떤 클러스터 매니저를 사용하는지에 대해)

- Driver
  - SparkContext를 통해 애플리케이션의 시작점을 제공
  - 전체 작업을 분할하여 Task로 만들어 Executor에게 전달 (클러스터 매니저와 협력해서?)
  - 애플리이션의 상태 (메타데이터, DAG, RDD)를 관리
  - 클라이언트 입장에서는 Spark App을 제어하고 모니터링할 수 있는 주체인 듯 하다
  - **Executor**들과의 연결을 유지해야 함 ⇒ park.driver.port 설정을 통해 드라이버가 사용할 포트를 지정
- Executor
  - Driver가 분할 한 일을 실제로 수행
  - 클러스터의 각 노드에서 동작 → 여러 Executor가 동시에 병렬로 작업 실행
  - 중간 결과가 캐시 데이터를 메모리나 디스크에 저장해서 후속 작업 처리 속도를 높인다고 한다
  - Driver와 소통하며 상태를 업데이트 함

**드라이버 프로그램의 위치? ⇒ 최대한 가까이 !**

- 드라이버는 클러스터에서 태스크를 스케줄링하므로 워커 노드와 물리적으로 가까운 게 좋음 (동일 LAN)
- 원격에서 클러스터에 요청해야한다면 RPC 요청 등을 사용
- 드라이버가 워커 노드와 멀리 떨어진 곳 (WAN)에 위치하면 효율 떨어질 수도 있음

Spark에서는 애플리케이션을 제출할 때, 해당 애플리케이션만을 위한 Executor 프로세스들이 생성됨

각 애플리케이션을 고유한 executor를 확보하고 유지하는 구조 덕분에 스케줄링 측면에서 애플리케이션의 간섭이 없고 (각각의 드라이버가 자신의 태스크를 독립적으로 스케줄링) Executor 측면에서도 서로 다른 애플리케이션의 태스크는 각기 다른 JVM에서 실행 되므로 격리 되어있음 **⇒ 애플리케이션 간 데이터 공유를 어렵게 만든다. 공유하려면 HDFS 같은 외부 스토리지 사용해야함**

그래도 애플리케이션 간 격리가 높아 스케줄링과 실행 측면에서 충돌이나 간섭이 적을 듯 !

참고로 여기서 애플리케이션이란 하나의 SpartContext를 중심으로 전체 작업(Job)을 수행하는 실행 단위임!

## 3가지 배포 모드

1. Cluster Mode
   - Spark 애플리케이션 (JAR, 파이썬 스크립트 등)을 클러스터 매니저 (YARN, Mesos 등)에 제출하면 Driver와 Executor가 모두 클러스터 내부의 노드에서 실행됨
   - **클러스터 매니저**가 Spark Driver와 Executor를 관리하므로, 드라이버 프로세스도 클러스터 안의 워커 노드 중 한 곳에서 실행됨
   - 가장 일반적인 사용 모드
   - Driver JVM이 죽어도 스스로 복구함 ⇒ fault tolerant (대신 리소스가 무거워짐)
   - 클러스터 매니저에 작업을 제출하면 자원 할당이나 스케줄링을 얘네가 처리함 → 실패나 재시작 등에 대해 더 견고함 안정성!!
2. Client Mode
   - Cluster mode와 유사하지만 드라이버 프로세스가 사용자 클라이언트 머신에서 실행됨
   - 클러스터 매니저는 Executor만 클러스터 안에서 관리
   - 로컬에서 드라이버가 실행 → 사용자가 유지해야함
   - 네트워크 지연이 있으면 안될 듯!!!
   - 사용자(개발자)가 드라이버 프로세스와 직접 상호작용 가능 ⇒ 대화형 앱이나 디버깅 상황에서 빠른 피드백 가능
3. Local Mode
   - 한 대의 머신에서 전체 Spark 앱 실행
   - 드라이버, executor 모두 스레드를 통해 병렬 실행

> **클러스터(Cluster)**란 여러 대의 컴퓨터(서버)들이 **네트워크**로 연결되어 하나의 통합된 시스템처럼 동작하도록 구성된 환경을 의미한다. 즉, 단일 머신이 아닌 여러 노드(서버)들이 협력하여 **컴퓨팅 자원(CPU, 메모리, 스토리지 등)을 공유**하고, 대규모 데이터나 복잡한 작업을 **분산(Parallel) 및 병렬(Concurrent) 처리**하기 위해 만들어진 구조

https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qeXmu_bZBwSYXjrb07g7Gw.png

![image.png](%E1%84%92%E1%85%AC%E1%84%80%E1%85%A9%20185c9b995f19808380b3d308766cad98/image.png)

---

## 공부할 때 참고했던 좋은 사이트들 정리

- https://forum.huawei.com/enterprise/intl/en/thread/what-is-ocr-and-omr-and-what-is-the-difference-between-ocr-and-omr/680084552757952512?blogId=680084552757952512
- https://mjs1995.tistory.com/226#article-1--spark-%ED%81%B4%EB%9F%AC%EC%8A%A4%ED%84%B0
- [https://www.researchgate.net/figure/MOS-architecture-A-master-node-rounded-rectangle-with-a-number-of-slaves-ones-rounded_fig3_330614514](https://www.researchgate.net/figure/MOS-architecture-A-master-node-rounded-rectangle-with-a-number-of-slaves-ones-rounded_fig3_330614514)
- [https://bluehorn07.github.io/2024/08/18/run-spark-on-local-2/](https://bluehorn07.github.io/2024/08/18/run-spark-on-local-2/)
- [https://blog.devgenius.io/spark-execution-environments-877f8fe158c8](https://blog.devgenius.io/spark-execution-environments-877f8fe158c8)

---

# 🔍 회고 (KPT)

## ✅ Keep

- 나의 언어로 정리한 것
  - 항상 노팅을 할 때 입이나 머리로만 읽고 복붙해서 정리를 해놓는 버릇이 있었는데, 이번에는 절대 복붙의 기능을 사용하지 않고 오로지 나의 언어로 바꾼 타이핑으로 정리를 해보았다. 그랬더니 나의 언어로 해석하고 받아들여서 그런지 내 머리속에서도 정리가 더 잘되고 기억도 오래 간 것 같았다.

## ⚠️ Problem

- 연휴라는 것에 안주한 내 자신….

## 💡 Try

- 팀 프로젝트 일정 수행시 더 세분화된 일정 구축하기
  - 오전/오후로만 나뉘어진 스케줄링은 생각보다 세분화되지 못하여서 팀 프로젝트를 빠르게 진도 나가기 위한 방향에는 좋지 못한 방향인 것 같았다.

---
