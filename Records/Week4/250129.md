# 📅 2025.01.29 리뷰 & 회고

---

# 📝 리뷰

## W4M1 진행

### Dockerfile

```docker
FROM bitnami/spark:latest

ENV SPARK_MASTER_URL=spark://spark-master:7077
ENV SPARK_WORKER_CORES=2
ENV SPARK_WORKER_MEMORY=2G

EXPOSE 8080 7077 8081 4040

CMD ["/opt/bitnami/scripts/spark/entrypoint.sh"]
```

Bitnami의 Spark 이미지?

- Bitmami가 관리하고 배포하는 Apache Spark의 Docker 이미지
- 해당 이미지를 사용시 설치 및 설정 과정을 단순화 가능

`SPARK_MASTER_URL`: Spark 마스터 노드의 URL을 지정

`SPARK_WORKER_CORES`: 워커 노드가 사용할 CPU 코어 수를 지정

`SPARK_WORKER_MEMORY`: 워커 노드가 사용할 메모리 양을 지정

CMD 명령어를 통하여 컨테이너가 시작될 때 Bitnami Spark 이미지에 포함된 엔트리포인트 스크립트를 실행

### Pi.py

```python
from pyspark.sql import SparkSession
import random

# import os

# output_dir = "/opt/bitnami/spark/output/"
# if not os.path.exists(output_dir):
#     os.makedirs(output_dir)

def inside(_):
    x, y = random.random(), random.random()
    return 1 if x*x + y*y < 1 else 0

if __name__ == "__main__":
    spark = SparkSession.builder.appName("Pi Estimation").getOrCreate()

    num_samples = 1000000
    count = spark.sparkContext.parallelize(range(num_samples)).map(inside).reduce(lambda a, b: a + b)

    pi = (4.0 * count) / num_samples
    print(f"Estimated value of π: {pi}")

    output_path = "/opt/bitnami/spark/output/pi_result.csv"
    df = spark.createDataFrame([(pi,)], ["estimated_pi"])
    df.write.csv(output_path, mode="overwrite", header=True)

    print(f"Pi value saved to {output_path}")
    spark.stop()

```

- pyspark.sql.SparkSession: Spark 애플리케이션을 시작하고 관리하는 데 사용됨
- SparkSession.builder.appName("Pi Estimation").getOrCreate(): SparkSession을 생성하여 Spark 애플리케이션을 시작 → 애플리케이션 이름은 "Pi Estimation”
- spark.sparkContext.parallelize(range(num_samples)): 0부터 num_samples까지의 숫자를 RDD로 병렬화
- `.map(inside)`: 각 숫자에 대해 inside 함수를 적용하여 단위 원 안에 있는 점의 수를 계산
- `.reduce(lambda a, b: a + b)`: 모든 값을 더하여 단위 원 안에 있는 총 점의 수를 계산

<aside>
💡

현재 문제점

로그로는 PI 값이 출력되는데 파일이 저장되지 않는 문제..

</aside>

### compose.yml

```yaml
version: "3"
services:
  spark-master:
    image: bitnami/spark:latest
    container_name: spark-master
    hostname: spark-master
    ports:
      - "8080:8080" # Spark Web UI
      - "7077:7077" # Spark Master URL
    environment:
      - SPARK_MODE=master
    volumes:
      - ./output:/opt/bitnami/spark/output # <== 파일을 로컬 시스템과 공유

  spark-worker-1:
    image: bitnami/spark:latest
    container_name: spark-worker-1
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077

  spark-worker-2:
    image: bitnami/spark:latest
    container_name: spark-worker-2
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
```

## Mini Team Project

우리의 프로젝트의 아이디어 세부 사항이 “Actionable 한 데이터”인지 생각해보기

- 어떤 상황에서 어떤 문제를 겪을까?
  - 여러 경기가 동시에 열려 다양한 팀과 선수의 데이터를 빠르게 확보해야 하는 문제
  - 개별 사이트를 일일이 돌아다니며 데이터를 수집하는 데 많은 시간이 소요되는 문제
  - 급작스럽게 투입된 선수(평소에 주전이 아니었던 선수)에 대한 준비된 정보가 부족해 당황하는 문제
  - (중계 중 실시간으로 빠르게 해당 선수의 객관적 기록을 확인해야 하는 문제)
  - 선수에 대한 전문가의 '체감 퍼포먼스' 등 정성적 요소가 흩어져 있고 일관적으로 취합하기 어렵다는 문제
  - (여러 명의 전문가, 사이트들이 특정 선수에 대해 다르게 평가하므로)
  - (해당 선수의 자료가 여러 출력물에 분산되어 있거나 단순히 숫자 값으로만 적혀있다면 빠르게 멘트를 치기 어려울 것이다.)
  - 선수 명단은 경기 1시간 전에 발표됨 -> 그 전에 예상치 못했던 선수가 등장시 대처가 빨라야하지만 매우 힘듦.
  - 예상치 못했던 선수가 급작스런 활약으로 "이 선수가 왜 이렇게 잘해?" 하는 궁금증이 커졌지만, 단순한 정보로는 설명이 어려운 문제
- 이를 통해 어떤 의사 결정을 할 수 있는가?
  1. 경기별 주요 선발·교체 명단 예측이 가능하며, 예상치 못한 선수 등장 (상황) 등이 발생해도 미리 준비하지 않은 데이터에 대한 빠른 대처가 가능
  2. 효율적인 분석 포인트 선정이 가능하다. 공격 포인트가 가장 뛰어난 선수, 수비 지표가 우수한 선수 등을 객관적 통계로 선별해 방송 중 강조해야 할 선수를 결정
  3. 방송 기획·구성 시 효율적인 대본 구성이 가능 -> 많은 데이터를 빠르게 취합해 방송 대본을 작성할 때 어떤 정보를 우선할지 빠른 정보 검색을 토대로 빠른 판단이 가능
  4. 정성적 데이터를 확보해 "이 선수가 이렇게 활약할 수 있었던 이유"를 다량의 데이터를 통해 해석 및 전달이 가능
  5. 사이트 (국가 및 기관 별로)마다 편차가 있던 정보(주관적)를 최대한 객관적인 정보로 전환하여 정보를 전달할 수 있으므로 가끔씩 편향된 정보만을 제공한다는 기존 해설의 문제점 완화 가능

Code Demo 작성

---

# 🔍 회고 (KPT)

## ✅ Keep

- 짜투리 시간 잘 활용하기 !
  - 설날 당일이라서 여러 곳을 왔다갔다 했지만, 이동 중이나 할 일이 없을 때 틈틈히 노트북을 봤기에 조금이라도 작업을 할 수 있었던 것 같다.

## ⚠️ Problem

-

## 💡 Try

- 팀 프로젝트 뿐만 아니라 내 할 일에 대한 일정도 더 세분화 하기 !

---
