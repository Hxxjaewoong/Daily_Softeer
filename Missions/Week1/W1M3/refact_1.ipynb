{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 원본"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countries with GDP >= 100B USD:\n",
      "+----------------------+-------------------+\n",
      "| Country              |   GDP_USD_billion |\n",
      "|----------------------+-------------------|\n",
      "| World                |         115494    |\n",
      "| United States        |          30337.2  |\n",
      "| China                |          19534.9  |\n",
      "| Germany              |           4921.56 |\n",
      "| Japan                |           4389.33 |\n",
      "| India                |           4271.92 |\n",
      "| United Kingdom       |           3730.26 |\n",
      "| France               |           3283.43 |\n",
      "| Italy                |           2459.6  |\n",
      "| Canada               |           2330.31 |\n",
      "| Brazil               |           2307.16 |\n",
      "| Russia               |           2195.71 |\n",
      "| South Korea          |           1947.13 |\n",
      "| Australia            |           1881.14 |\n",
      "| Spain                |           1827.58 |\n",
      "| Mexico               |           1817.82 |\n",
      "| Indonesia            |           1492.62 |\n",
      "| Turkey               |           1455.41 |\n",
      "| Netherlands          |           1272.96 |\n",
      "| Saudi Arabia         |           1136.58 |\n",
      "| Switzerland          |            999.6  |\n",
      "| Poland               |            915.45 |\n",
      "| Taiwan               |            814.44 |\n",
      "| Belgium              |            689.36 |\n",
      "| Sweden               |            638.78 |\n",
      "| Argentina            |            604.2  |\n",
      "| Ireland              |            587.22 |\n",
      "| United Arab Emirates |            568.57 |\n",
      "| Singapore            |            561.72 |\n",
      "| Austria              |            559.22 |\n",
      "| Israel               |            550.9  |\n",
      "| Thailand             |            545.34 |\n",
      "| Philippines          |            507.67 |\n",
      "| Vietnam              |            506.43 |\n",
      "| Norway               |            503.47 |\n",
      "| Malaysia             |            488.25 |\n",
      "| Iran                 |            463.75 |\n",
      "| Bangladesh           |            455.86 |\n",
      "| Czech Republic       |            452.23 |\n",
      "| Denmark              |            431.23 |\n",
      "| Hong Kong            |            422.06 |\n",
      "| Colombia             |            419.33 |\n",
      "| South Africa         |            418.05 |\n",
      "| Romania              |            406.2  |\n",
      "| Egypt                |            380.04 |\n",
      "| Pakistan             |            374.6  |\n",
      "| Chile                |            362.24 |\n",
      "| Finland              |            319.99 |\n",
      "| Portugal             |            319.93 |\n",
      "| Hungary              |            312.62 |\n",
      "| Kazakhstan           |            306.63 |\n",
      "| Peru                 |            294.9  |\n",
      "| Iraq                 |            270.87 |\n",
      "| Greece               |            265.17 |\n",
      "| Algeria              |            264.27 |\n",
      "| New Zealand          |            262.92 |\n",
      "| Qatar                |            240.22 |\n",
      "| Ethiopia             |            230.03 |\n",
      "| Nigeria              |            199.72 |\n",
      "| Ukraine              |            189.83 |\n",
      "| Morocco              |            168.6  |\n",
      "| Kuwait               |            161.95 |\n",
      "| Slovakia             |            142.62 |\n",
      "| Dominican Republic   |            126.24 |\n",
      "| Uzbekistan           |            125.51 |\n",
      "| Bulgaria             |            123.42 |\n",
      "| Ecuador              |            121.42 |\n",
      "| Puerto Rico          |            120.97 |\n",
      "| Kenya                |            116.32 |\n",
      "| Angola               |            113.29 |\n",
      "| Guatemala            |            112.37 |\n",
      "| Oman                 |            110.99 |\n",
      "| Venezuela            |            106.33 |\n",
      "+----------------------+-------------------+\n",
      "Average GDP of top 5 countries by region (excluding None):\n",
      "+---------------+----------------+\n",
      "| Region        |   Avg_Top5_GDP |\n",
      "|---------------+----------------|\n",
      "| Africa        |        256.134 |\n",
      "| Asia          |       6255.97  |\n",
      "| Europe        |       3318.11  |\n",
      "| North America |       6946.5   |\n",
      "| Oceania       |        734.84  |\n",
      "| South America |        797.566 |\n",
      "+---------------+----------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rd/d9knhb6x6nj7rd817gqlcsr00000gn/T/ipykernel_20546/3236592670.py:56: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import sqlite3\n",
    "import configparser\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tabulate import tabulate\n",
    "\n",
    "def log_started():\n",
    "    \"\"\"Log the start of a new ETL execution.\"\"\"\n",
    "    with open('etl_project_log.txt', 'a') as log_file:\n",
    "        log_file.write(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "        timestamp = datetime.datetime.now().strftime('%Y-%B-%d-%H-%M-%S')\n",
    "        log_file.write(f\"New Execution at {timestamp}\\n\")\n",
    "        log_file.write(\"=\" * 50 + \"\\n\\n\")\n",
    "\n",
    "\n",
    "def log_message(message, level=\"INFO\"):\n",
    "    \"\"\"Log a message with a timestamp and severity level.\"\"\"\n",
    "    timestamp = datetime.datetime.now().strftime('%Y-%b-%d %H:%M:%S')\n",
    "    with open('etl_project_log.txt', 'a') as log_file:\n",
    "        log_file.write(f\"{timestamp} - {level} - {message}\\n\")\n",
    "\n",
    "\n",
    "def load_config(config_path='config.ini'):\n",
    "    \"\"\"Load configuration values from the given config file.\"\"\"\n",
    "    if not os.path.exists(config_path):\n",
    "        log_message(f\"Configuration file '{config_path}' not found.\", level=\"ERROR\")\n",
    "        raise FileNotFoundError(f\"Configuration file '{config_path}' not found.\")\n",
    "\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(config_path)\n",
    "\n",
    "    if 'DEFAULT' not in config or 'URL' not in config['DEFAULT'] or 'TABLE_CLASS' not in config['DEFAULT']:\n",
    "        log_message(\"Invalid or missing configuration values in 'config.ini'.\", level=\"ERROR\")\n",
    "        raise ValueError(\"Invalid or missing configuration values in 'config.ini'.\")\n",
    "\n",
    "    return config['DEFAULT']['URL'], config['DEFAULT']['TABLE_CLASS']\n",
    "\n",
    "\n",
    "def extract_gdp_data(url, table_class):\n",
    "    \"\"\"Extract GDP data from the given URL and table class.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        table = soup.find('table', {'class': table_class})\n",
    "\n",
    "        if table is None:\n",
    "            log_message(\"No table found with the specified class.\", level=\"ERROR\")\n",
    "            raise ValueError(\"Failed to locate the GDP table on the webpage.\")\n",
    "\n",
    "        df = pd.read_html(str(table))[0]\n",
    "        df = df.iloc[:, [0, 1, 2]]\n",
    "        df.columns = ['Country', 'GDP (Nominal)', 'Year']\n",
    "        df = df.dropna(subset=['Country', 'GDP (Nominal)'])\n",
    "        df['GDP (B USD)'] = (\n",
    "            df['GDP (Nominal)']\n",
    "            .str.replace(r'[^\\d.]', '', regex=True)\n",
    "            .replace('', '0')\n",
    "            .astype(float) / 1e3\n",
    "        )\n",
    "        df['Year'] = df['Year'].str.replace(r'\\[.*?\\]', '', regex=True)\n",
    "        df = df[['Country', 'GDP (B USD)', 'Year']]\n",
    "        df = df.sort_values(by='GDP (B USD)', ascending=False)\n",
    "        df['GDP (B USD)'] = df['GDP (B USD)'].round(2)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error during data extraction: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def transform_gdp_data(df):\n",
    "    \"\"\"Transform the extracted GDP data.\"\"\"\n",
    "    log_message(\"Starting Data Transformation\")\n",
    "    try:\n",
    "        with open('country_region_table.json', 'r', encoding='utf-8') as region_file:\n",
    "            region_data = json.load(region_file)\n",
    "        df['Region'] = df['Country'].map(region_data)\n",
    "        log_message(\"Data Transformation Completed\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error during data transformation: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def load_gdp_data(df):\n",
    "    \"\"\"Load the transformed data into an SQLite database.\"\"\"\n",
    "    log_message(\"Loading data into SQLite database\")\n",
    "    try:\n",
    "        conn = sqlite3.connect('World_Economies.db')\n",
    "        df[['Country', 'GDP (B USD)', 'Year', 'Region']].rename(\n",
    "            columns={'GDP (B USD)': 'GDP_USD_billion'}\n",
    "        ).to_sql('Countries_by_GDP', conn, if_exists='replace', index=False)\n",
    "        conn.close()\n",
    "        log_message(\"Data successfully loaded into SQLite database\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error while loading data into SQLite database: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def display_countries_with_gdp_over_100():\n",
    "    \"\"\"Display countries with GDP over 100B USD.\"\"\"\n",
    "    log_message(\"Displaying countries with GDP over 100B USD\")\n",
    "    try:\n",
    "        conn = sqlite3.connect('World_Economies.db')\n",
    "        query = \"\"\"\n",
    "        SELECT Country, GDP_USD_billion\n",
    "        FROM Countries_by_GDP\n",
    "        WHERE GDP_USD_billion >= 100\n",
    "        \"\"\"\n",
    "        result = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "        print(\"Countries with GDP >= 100B USD:\")\n",
    "        print(tabulate(result, headers='keys', tablefmt='psql', showindex=False))\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error querying database for countries with GDP >= 100B: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def display_region_top5_average_gdp():\n",
    "    \"\"\"Calculate and display the average GDP of the top 5 countries by region.\"\"\"\n",
    "    log_message(\"Calculating average GDP of top 5 countries by region\")\n",
    "    try:\n",
    "        conn = sqlite3.connect('World_Economies.db')\n",
    "        query = \"\"\"\n",
    "        WITH RankedCountries AS (\n",
    "            SELECT Country, GDP_USD_billion, Region,\n",
    "                   RANK() OVER (PARTITION BY Region ORDER BY GDP_USD_billion DESC) AS Rank\n",
    "            FROM Countries_by_GDP\n",
    "            WHERE Region IS NOT NULL\n",
    "        )\n",
    "        SELECT Region, AVG(GDP_USD_billion) AS Avg_Top5_GDP\n",
    "        FROM RankedCountries\n",
    "        WHERE Rank <= 5\n",
    "        GROUP BY Region\n",
    "        \"\"\"\n",
    "        result = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "        print(\"Average GDP of top 5 countries by region (excluding None):\")\n",
    "        print(tabulate(result, headers='keys', tablefmt='psql', showindex=False))\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error querying database for top 5 average GDP: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def save_gdp_data(df, output_csv_file='extracted_gdp_data.csv', output_json_file='extracted_gdp_data.json'):\n",
    "    \"\"\"Save the GDP data to CSV and JSON files.\"\"\"\n",
    "    log_message(\"Saving Extracted Data\")\n",
    "    try:\n",
    "        df.to_csv(output_csv_file, index=False)\n",
    "        df.to_json(output_json_file, orient='records', force_ascii=False, indent=4)\n",
    "        log_message(f\"Data saved: CSV ({output_csv_file}), JSON ({output_json_file})\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"Failed to save data: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "    \n",
    "# # GDP가 100B USD 이상인 국가 필터링\n",
    "# def filtered_100USD(df):\n",
    "#     filtered_100 = df[df['GDP (B USD)'] >= 100]\n",
    "#     print(\"Countries with a GDP of over 100B USD\")\n",
    "#     print(filtered_100)\n",
    "#     return filtered_100\n",
    "\n",
    "\n",
    "# # Region별 상위 5개 국가의 GDP 평균 계산\n",
    "# def region_top5_calculate(df):\n",
    "#     region_top5_avg = (\n",
    "#         df.groupby('Region')\n",
    "#         .apply(lambda x: x.nlargest(5, 'GDP (B USD)')['GDP (B USD)'].mean())\n",
    "#         .reset_index(name='Top 5 Avg GDP (B USD)')\n",
    "#     )\n",
    "#     print(\"Average GDP of top 5 countries by region\")\n",
    "#     print(region_top5_avg)\n",
    "#     return region_top5_avg\n",
    "\n",
    "\n",
    "def etl_process():\n",
    "    \"\"\"Main ETL process for GDP data.\"\"\"\n",
    "    try:\n",
    "        log_started()\n",
    "        log_message(\"ETL Process Started\")\n",
    "\n",
    "        url, table_class = load_config()\n",
    "        extracted_data = extract_gdp_data(url, table_class)\n",
    "        #save_gdp_data(extracted_data)\n",
    "        transformed_data = transform_gdp_data(extracted_data)\n",
    "        #save_gdp_data(transformed_data, 'transformed_gdp_data.csv', 'transformed_gdp_data.json')\n",
    "        load_gdp_data(transformed_data)\n",
    "        display_countries_with_gdp_over_100()\n",
    "        display_region_top5_average_gdp()\n",
    "        \n",
    "        ## 추가요구사항 전 출력과정\n",
    "        #filtered_data = filtered_100USD(transformed_data)\n",
    "        #region_top5_data = region_top5_calculate(transformed_data)\n",
    "\n",
    "        log_message(\"ETL Process Completed Successfully\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"ETL Process Failed: {str(e)}\", level=\"ERROR\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    etl_process()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 리팩토링 최종"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import sqlite3\n",
    "import configparser\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "def log_started():\n",
    "    \"\"\"\n",
    "    Log the start of a new ETL execution.\n",
    "    \n",
    "    This function creates a separator in the log file and records a timestamp\n",
    "    to indicate the beginning of a new ETL execution.\n",
    "    \"\"\"\n",
    "    with open('etl_project_log.txt', 'a') as log_file:\n",
    "        log_file.write(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "        timestamp = datetime.datetime.now().strftime('%Y-%B-%d-%H-%M-%S')\n",
    "        log_file.write(f\"New Execution at {timestamp}\\n\")\n",
    "        log_file.write(\"=\" * 50 + \"\\n\\n\")\n",
    "\n",
    "\n",
    "def log_message(message, level=\"INFO\"):\n",
    "    \"\"\"\n",
    "    Log a message with a timestamp and severity level.\n",
    "\n",
    "    Parameters:\n",
    "        message (str): The message to log.\n",
    "        level (str): The severity level of the message (default: \"INFO\").\n",
    "    \"\"\"\n",
    "    timestamp = datetime.datetime.now().strftime('%Y-%b-%d %H:%M:%S')\n",
    "    with open('etl_project_log.txt', 'a') as log_file:\n",
    "        log_file.write(f\"{timestamp} - {level} - {message}\\n\")\n",
    "\n",
    "\n",
    "def extract_gdp_data(config_path='config.ini'):\n",
    "    \"\"\"\n",
    "    Extract GDP data from a webpage based on a configuration file.\n",
    "\n",
    "    Parameters:\n",
    "        config_path (str): Path to the configuration file (default: 'config.ini').\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Raw GDP data extracted from the webpage.\n",
    "    \"\"\"\n",
    "    log_message(\"Starting data extraction process\")\n",
    "\n",
    "    # Step 1: Read and validate the configuration file\n",
    "    if not os.path.exists(config_path):\n",
    "        log_message(f\"Configuration file '{config_path}' not found.\", level=\"ERROR\")\n",
    "        raise FileNotFoundError(f\"Configuration file '{config_path}' not found.\")\n",
    "\n",
    "    try:\n",
    "        config = configparser.ConfigParser()\n",
    "        config.read(config_path)\n",
    "        url = config['DEFAULT']['URL']\n",
    "        table_class = config['DEFAULT']['TABLE_CLASS']\n",
    "        log_message(\"Configuration file read successfully\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error reading configuration file: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "    # Step 2: Fetch the webpage data\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        log_message(f\"Successfully fetched data from URL: {url}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        log_message(f\"Error during requests to the URL: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "    # Step 3: Parse the HTML and extract the table\n",
    "    try:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        table = soup.find('table', {'class': table_class})\n",
    "        if table is None:\n",
    "            log_message(f\"No table found with the specified class '{table_class}'.\", level=\"ERROR\")\n",
    "            raise ValueError(\"Failed to locate the GDP table on the webpage.\")\n",
    "        log_message(\"Successfully located the GDP table in the HTML\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error parsing HTML or finding table: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "    # Step 4: Convert the table to a DataFrame and save raw data\n",
    "    try:\n",
    "        raw_df = pd.read_html(str(table))[0]\n",
    "        raw_df.to_csv('raw_gdp_data.csv', index=False)\n",
    "        raw_df.to_json('raw_gdp_data.json', orient='records', force_ascii=False, indent=4)\n",
    "        log_message(\"Raw data saved successfully\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error converting table to DataFrame or saving raw data: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "    log_message(\"Data extraction process completed successfully\")\n",
    "    return raw_df\n",
    "\n",
    "\n",
    "def transform_gdp_data(df):\n",
    "    \"\"\"\n",
    "    Transform the extracted GDP data for further analysis.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Raw GDP data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Transformed GDP data.\n",
    "    \"\"\"\n",
    "    log_message(\"Starting data transformation process\")\n",
    "    try:\n",
    "        # Step 1: Clean and process the data\n",
    "        df = df.iloc[:, [0, 1, 2]]\n",
    "        df.columns = ['Country', 'GDP (Nominal)', 'Year']\n",
    "        df = df.dropna(subset=['Country', 'GDP (Nominal)'])\n",
    "        df['GDP (B USD)'] = (\n",
    "            df['GDP (Nominal)']\n",
    "            .str.replace(r'[^\\d.]', '', regex=True)  # Remove non-numeric characters\n",
    "            .astype(float) / 1e3\n",
    "        )\n",
    "        df['Year'] = df['Year'].str.replace(r'\\[.*?\\]', '', regex=True)\n",
    "        df = df[['Country', 'GDP (B USD)', 'Year']]\n",
    "        df.sort_values(by='GDP (B USD)', ascending=False, inplace=True)\n",
    "        log_message(\"Data cleaned and transformed successfully\")\n",
    "\n",
    "        # Step 2: Merge with region data\n",
    "        with open('country_region_table.json', 'r', encoding='utf-8') as region_file:\n",
    "            region_data = json.load(region_file)\n",
    "        region_df = pd.DataFrame(list(region_data.items()), columns=['Country', 'Region'])\n",
    "        df = pd.merge(df, region_df, on='Country', how='left')\n",
    "\n",
    "        # Step 3: Save transformed data\n",
    "        df.to_csv('transformed_gdp_data.csv', index=False)\n",
    "        df.to_json('transformed_gdp_data.json', orient='records', force_ascii=False, indent=4)\n",
    "        log_message(\"Transformed data saved successfully\")\n",
    "\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error in data transformation: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_gdp_data(df):\n",
    "    \"\"\"\n",
    "    Load transformed GDP data into an SQLite database.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Transformed GDP data.\n",
    "    \"\"\"\n",
    "    log_message(\"Loading data into SQLite database\")\n",
    "    try:\n",
    "        conn = sqlite3.connect('World_Economies.db')\n",
    "        df.to_sql('Countries_by_GDP', conn, if_exists='replace', index=False)\n",
    "        conn.close()\n",
    "        log_message(\"Data successfully loaded into SQLite database\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error while loading data into SQLite database: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def display_countries_with_gdp_over_100():\n",
    "    \"\"\"\n",
    "    Display countries with GDP over 100 billion USD.\n",
    "\n",
    "    Prints a table of countries with GDP greater than or equal to 100B USD from the database.\n",
    "    \"\"\"\n",
    "    log_message(\"Displaying countries with GDP over 100B USD\")\n",
    "    try:\n",
    "        conn = sqlite3.connect('World_Economies.db')\n",
    "        query = \"\"\"\n",
    "        SELECT Country, GDP_USD_billion\n",
    "        FROM Countries_by_GDP\n",
    "        WHERE GDP_USD_billion >= 100\n",
    "        \"\"\"\n",
    "        result = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "        print(\"Countries with GDP >= 100B USD:\")\n",
    "        print(tabulate(result, headers='keys', tablefmt='psql', showindex=False))\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error querying database for countries with GDP >= 100B: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def display_region_top5_average_gdp():\n",
    "    \"\"\"\n",
    "    Calculate and display the average GDP of the top 5 countries by region.\n",
    "\n",
    "    Prints the average GDP of the top 5 countries for each region from the database.\n",
    "    \"\"\"\n",
    "    log_message(\"Calculating average GDP of top 5 countries by region\")\n",
    "    try:\n",
    "        conn = sqlite3.connect('World_Economies.db')\n",
    "        query = \"\"\"\n",
    "        WITH RankedCountries AS (\n",
    "            SELECT Country, GDP_USD_billion, Region,\n",
    "                   RANK() OVER (PARTITION BY Region ORDER BY GDP_USD_billion DESC) AS Rank\n",
    "            FROM Countries_by_GDP\n",
    "            WHERE Region IS NOT NULL\n",
    "        )\n",
    "        SELECT Region, AVG(GDP_USD_billion) AS Avg_Top5_GDP\n",
    "        FROM RankedCountries\n",
    "        WHERE Rank <= 5\n",
    "        GROUP BY Region\n",
    "        \"\"\"\n",
    "        result = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "        print(\"Average GDP of top 5 countries by region (excluding None):\")\n",
    "        print(tabulate(result, headers='keys', tablefmt='psql', showindex=False))\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error querying database for top 5 average GDP: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def etl_process():\n",
    "    \"\"\"\n",
    "    Execute the ETL process for GDP data.\n",
    "\n",
    "    Steps:\n",
    "        1. Extract raw data from a webpage.\n",
    "        2. Transform the data into a cleaned(required) format.\n",
    "        3. Load the data into an SQLite database.\n",
    "        4. Display additional analytical results.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        log_started()\n",
    "        log_message(\"ETL Process Started\")\n",
    "\n",
    "        # Extract\n",
    "        raw_data = extract_gdp_data()\n",
    "\n",
    "        # Transform\n",
    "        transformed_data = transform_gdp_data(raw_data)\n",
    "\n",
    "        # Load\n",
    "        load_gdp_data(transformed_data)\n",
    "\n",
    "        # Display analysis\n",
    "        display_countries_with_gdp_over_100()\n",
    "        display_region_top5_average_gdp()\n",
    "\n",
    "        log_message(\"ETL Process Completed Successfully\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"ETL Process Failed: {str(e)}\", level=\"ERROR\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    etl_process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load_config()함수에서 진행하는 것을 load_config()함수를 없애고 extract_gdp_data()함수에서 진행할 수 있도록 옮김"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countries with GDP >= 100B USD:\n",
      "+----------------------+-------------------+\n",
      "| Country              |   GDP_USD_billion |\n",
      "|----------------------+-------------------|\n",
      "| World                |         115494    |\n",
      "| United States        |          30337.2  |\n",
      "| China                |          19534.9  |\n",
      "| Germany              |           4921.56 |\n",
      "| Japan                |           4389.33 |\n",
      "| India                |           4271.92 |\n",
      "| United Kingdom       |           3730.26 |\n",
      "| France               |           3283.43 |\n",
      "| Italy                |           2459.6  |\n",
      "| Canada               |           2330.31 |\n",
      "| Brazil               |           2307.16 |\n",
      "| Russia               |           2195.71 |\n",
      "| South Korea          |           1947.13 |\n",
      "| Australia            |           1881.14 |\n",
      "| Spain                |           1827.58 |\n",
      "| Mexico               |           1817.82 |\n",
      "| Indonesia            |           1492.62 |\n",
      "| Turkey               |           1455.41 |\n",
      "| Netherlands          |           1272.96 |\n",
      "| Saudi Arabia         |           1136.58 |\n",
      "| Switzerland          |            999.6  |\n",
      "| Poland               |            915.45 |\n",
      "| Taiwan               |            814.44 |\n",
      "| Belgium              |            689.36 |\n",
      "| Sweden               |            638.78 |\n",
      "| Argentina            |            604.2  |\n",
      "| Ireland              |            587.22 |\n",
      "| United Arab Emirates |            568.57 |\n",
      "| Singapore            |            561.72 |\n",
      "| Austria              |            559.22 |\n",
      "| Israel               |            550.9  |\n",
      "| Thailand             |            545.34 |\n",
      "| Philippines          |            507.67 |\n",
      "| Vietnam              |            506.43 |\n",
      "| Norway               |            503.47 |\n",
      "| Malaysia             |            488.25 |\n",
      "| Iran                 |            463.75 |\n",
      "| Bangladesh           |            455.86 |\n",
      "| Czech Republic       |            452.23 |\n",
      "| Denmark              |            431.23 |\n",
      "| Hong Kong            |            422.06 |\n",
      "| Colombia             |            419.33 |\n",
      "| South Africa         |            418.05 |\n",
      "| Romania              |            406.2  |\n",
      "| Egypt                |            380.04 |\n",
      "| Pakistan             |            374.6  |\n",
      "| Chile                |            362.24 |\n",
      "| Finland              |            319.99 |\n",
      "| Portugal             |            319.93 |\n",
      "| Hungary              |            312.62 |\n",
      "| Kazakhstan           |            306.63 |\n",
      "| Peru                 |            294.9  |\n",
      "| Iraq                 |            270.87 |\n",
      "| Greece               |            265.17 |\n",
      "| Algeria              |            264.27 |\n",
      "| New Zealand          |            262.92 |\n",
      "| Qatar                |            240.22 |\n",
      "| Ethiopia             |            230.03 |\n",
      "| Nigeria              |            199.72 |\n",
      "| Ukraine              |            189.83 |\n",
      "| Morocco              |            168.6  |\n",
      "| Kuwait               |            161.95 |\n",
      "| Slovakia             |            142.62 |\n",
      "| Dominican Republic   |            126.24 |\n",
      "| Uzbekistan           |            125.51 |\n",
      "| Bulgaria             |            123.42 |\n",
      "| Ecuador              |            121.42 |\n",
      "| Puerto Rico          |            120.97 |\n",
      "| Kenya                |            116.32 |\n",
      "| Angola               |            113.29 |\n",
      "| Guatemala            |            112.37 |\n",
      "| Oman                 |            110.99 |\n",
      "| Venezuela            |            106.33 |\n",
      "+----------------------+-------------------+\n",
      "Average GDP of top 5 countries by region (excluding None):\n",
      "+---------------+----------------+\n",
      "| Region        |   Avg_Top5_GDP |\n",
      "|---------------+----------------|\n",
      "| Africa        |        256.134 |\n",
      "| Asia          |       6255.97  |\n",
      "| Europe        |       3318.11  |\n",
      "| North America |       6946.5   |\n",
      "| Oceania       |        734.84  |\n",
      "| South America |        797.566 |\n",
      "+---------------+----------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rd/d9knhb6x6nj7rd817gqlcsr00000gn/T/ipykernel_20546/1397898256.py:52: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import sqlite3\n",
    "import configparser\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tabulate import tabulate\n",
    "\n",
    "def log_started():\n",
    "    \"\"\"Log the start of a new ETL execution.\"\"\"\n",
    "    with open('etl_project_log.txt', 'a') as log_file:\n",
    "        log_file.write(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "        timestamp = datetime.datetime.now().strftime('%Y-%B-%d-%H-%M-%S')\n",
    "        log_file.write(f\"New Execution at {timestamp}\\n\")\n",
    "        log_file.write(\"=\" * 50 + \"\\n\\n\")\n",
    "\n",
    "def log_message(message, level=\"INFO\"):\n",
    "    \"\"\"Log a message with a timestamp and severity level.\"\"\"\n",
    "    timestamp = datetime.datetime.now().strftime('%Y-%b-%d %H:%M:%S')\n",
    "    with open('etl_project_log.txt', 'a') as log_file:\n",
    "        log_file.write(f\"{timestamp} - {level} - {message}\\n\")\n",
    "\n",
    "def extract_gdp_data(config_path='config.ini'):\n",
    "    \"\"\"Extract GDP data from the URL and table class specified in the config file.\"\"\"\n",
    "    if not os.path.exists(config_path):\n",
    "        log_message(f\"Configuration file '{config_path}' not found.\", level=\"ERROR\")\n",
    "        raise FileNotFoundError(f\"Configuration file '{config_path}' not found.\")\n",
    "\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(config_path)\n",
    "\n",
    "    if 'DEFAULT' not in config or 'URL' not in config['DEFAULT'] or 'TABLE_CLASS' not in config['DEFAULT']:\n",
    "        log_message(\"Invalid or missing configuration values in 'config.ini'.\", level=\"ERROR\")\n",
    "        raise ValueError(\"Invalid or missing configuration values in 'config.ini'.\")\n",
    "\n",
    "    url = config['DEFAULT']['URL']\n",
    "    table_class = config['DEFAULT']['TABLE_CLASS']\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        table = soup.find('table', {'class': table_class})\n",
    "\n",
    "        if table is None:\n",
    "            log_message(\"No table found with the specified class.\", level=\"ERROR\")\n",
    "            raise ValueError(\"Failed to locate the GDP table on the webpage.\")\n",
    "\n",
    "        df = pd.read_html(str(table))[0]\n",
    "        df = df.iloc[:, [0, 1, 2]]\n",
    "        df.columns = ['Country', 'GDP (Nominal)', 'Year']\n",
    "        df = df.dropna(subset=['Country', 'GDP (Nominal)'])\n",
    "        df['GDP (B USD)'] = (\n",
    "            df['GDP (Nominal)']\n",
    "            .str.replace(r'[^\\d.]', '', regex=True)\n",
    "            .replace('', '0')\n",
    "            .astype(float) / 1e3\n",
    "        )\n",
    "        df['Year'] = df['Year'].str.replace(r'\\[.*?\\]', '', regex=True)\n",
    "        df = df[['Country', 'GDP (B USD)', 'Year']]\n",
    "        df = df.sort_values(by='GDP (B USD)', ascending=False)\n",
    "        df['GDP (B USD)'] = df['GDP (B USD)'].round(2)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error during data extraction: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "def transform_gdp_data(df):\n",
    "    \"\"\"Transform the extracted GDP data.\"\"\"\n",
    "    log_message(\"Starting Data Transformation\")\n",
    "    try:\n",
    "        with open('country_region_table.json', 'r', encoding='utf-8') as region_file:\n",
    "            region_data = json.load(region_file)\n",
    "        df['Region'] = df['Country'].map(region_data)\n",
    "        log_message(\"Data Transformation Completed\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error during data transformation: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "def load_gdp_data(df):\n",
    "    \"\"\"Load the transformed data into an SQLite database.\"\"\"\n",
    "    log_message(\"Loading data into SQLite database\")\n",
    "    try:\n",
    "        conn = sqlite3.connect('World_Economies.db')\n",
    "        df[['Country', 'GDP (B USD)', 'Year', 'Region']].rename(\n",
    "            columns={'GDP (B USD)': 'GDP_USD_billion'}\n",
    "        ).to_sql('Countries_by_GDP', conn, if_exists='replace', index=False)\n",
    "        conn.close()\n",
    "        log_message(\"Data successfully loaded into SQLite database\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error while loading data into SQLite database: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "def display_countries_with_gdp_over_100():\n",
    "    \"\"\"Display countries with GDP over 100B USD.\"\"\"\n",
    "    log_message(\"Displaying countries with GDP over 100B USD\")\n",
    "    try:\n",
    "        conn = sqlite3.connect('World_Economies.db')\n",
    "        query = \"\"\"\n",
    "        SELECT Country, GDP_USD_billion\n",
    "        FROM Countries_by_GDP\n",
    "        WHERE GDP_USD_billion >= 100\n",
    "        \"\"\"\n",
    "        result = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "        print(\"Countries with GDP >= 100B USD:\")\n",
    "        print(tabulate(result, headers='keys', tablefmt='psql', showindex=False))\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error querying database for countries with GDP >= 100B: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "def display_region_top5_average_gdp():\n",
    "    \"\"\"Calculate and display the average GDP of the top 5 countries by region.\"\"\"\n",
    "    log_message(\"Calculating average GDP of top 5 countries by region\")\n",
    "    try:\n",
    "        conn = sqlite3.connect('World_Economies.db')\n",
    "        query = \"\"\"\n",
    "        WITH RankedCountries AS (\n",
    "            SELECT Country, GDP_USD_billion, Region,\n",
    "                   RANK() OVER (PARTITION BY Region ORDER BY GDP_USD_billion DESC) AS Rank\n",
    "            FROM Countries_by_GDP\n",
    "            WHERE Region IS NOT NULL\n",
    "        )\n",
    "        SELECT Region, AVG(GDP_USD_billion) AS Avg_Top5_GDP\n",
    "        FROM RankedCountries\n",
    "        WHERE Rank <= 5\n",
    "        GROUP BY Region\n",
    "        \"\"\"\n",
    "        result = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "        print(\"Average GDP of top 5 countries by region (excluding None):\")\n",
    "        print(tabulate(result, headers='keys', tablefmt='psql', showindex=False))\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error querying database for top 5 average GDP: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "def save_gdp_data(df, output_csv_file='extracted_gdp_data.csv', output_json_file='extracted_gdp_data.json'):\n",
    "    \"\"\"Save the GDP data to CSV and JSON files.\"\"\"\n",
    "    log_message(\"Saving Extracted Data\")\n",
    "    try:\n",
    "        df.to_csv(output_csv_file, index=False)\n",
    "        df.to_json(output_json_file, orient='records', force_ascii=False, indent=4)\n",
    "        log_message(f\"Data saved: CSV ({output_csv_file}), JSON ({output_json_file})\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"Failed to save data: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "def etl_process():\n",
    "    \"\"\"Main ETL process for GDP data.\"\"\"\n",
    "    try:\n",
    "        log_started()\n",
    "        log_message(\"ETL Process Started\")\n",
    "\n",
    "        extracted_data = extract_gdp_data()\n",
    "        save_gdp_data(extracted_data)\n",
    "        transformed_data = transform_gdp_data(extracted_data)\n",
    "        save_gdp_data(transformed_data, 'transformed_gdp_data.csv', 'transformed_gdp_data.json')\n",
    "        load_gdp_data(transformed_data)\n",
    "        display_countries_with_gdp_over_100()\n",
    "        display_region_top5_average_gdp()\n",
    "\n",
    "        log_message(\"ETL Process Completed Successfully\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"ETL Process Failed: {str(e)}\", level=\"ERROR\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    etl_process()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  extract_gdp_data()에서 BeautifulSoap를 활용해 웹스크래핑을 한 뒤, 스크래핑한 데이터를 수정('Country', 'GDP (Nominal)', 'Year'만 남겨놓는 것)하기 전에 raw data를 CSV 와 JSON files 로 저장하는 작업을 추가\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import sqlite3\n",
    "import configparser\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tabulate import tabulate\n",
    "\n",
    "def log_started():\n",
    "    \"\"\"Log the start of a new ETL execution.\"\"\"\n",
    "    with open('etl_project_log.txt', 'a') as log_file:\n",
    "        log_file.write(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "        timestamp = datetime.datetime.now().strftime('%Y-%B-%d-%H-%M-%S')\n",
    "        log_file.write(f\"New Execution at {timestamp}\\n\")\n",
    "        log_file.write(\"=\" * 50 + \"\\n\\n\")\n",
    "\n",
    "def log_message(message, level=\"INFO\"):\n",
    "    \"\"\"Log a message with a timestamp and severity level.\"\"\"\n",
    "    timestamp = datetime.datetime.now().strftime('%Y-%b-%d %H:%M:%S')\n",
    "    with open('etl_project_log.txt', 'a') as log_file:\n",
    "        log_file.write(f\"{timestamp} - {level} - {message}\\n\")\n",
    "\n",
    "def extract_gdp_data(config_path='config.ini'):\n",
    "    \"\"\"Extract GDP data from the URL and table class specified in the config file.\"\"\"\n",
    "    if not os.path.exists(config_path):\n",
    "        log_message(f\"Configuration file '{config_path}' not found.\", level=\"ERROR\")\n",
    "        raise FileNotFoundError(f\"Configuration file '{config_path}' not found.\")\n",
    "\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(config_path)\n",
    "\n",
    "    if 'DEFAULT' not in config or 'URL' not in config['DEFAULT'] or 'TABLE_CLASS' not in config['DEFAULT']:\n",
    "        log_message(\"Invalid or missing configuration values in 'config.ini'.\", level=\"ERROR\")\n",
    "        raise ValueError(\"Invalid or missing configuration values in 'config.ini'.\")\n",
    "\n",
    "    url = config['DEFAULT']['URL']\n",
    "    table_class = config['DEFAULT']['TABLE_CLASS']\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        table = soup.find('table', {'class': table_class})\n",
    "\n",
    "        if table is None:\n",
    "            log_message(\"No table found with the specified class.\", level=\"ERROR\")\n",
    "            raise ValueError(\"Failed to locate the GDP table on the webpage.\")\n",
    "\n",
    "        raw_df = pd.read_html(str(table))[0]\n",
    "        raw_output_csv_file = 'raw_gdp_data.csv'\n",
    "        raw_output_json_file = 'raw_gdp_data.json'\n",
    "\n",
    "        # Save raw data before any processing\n",
    "        raw_df.to_csv(raw_output_csv_file, index=False)\n",
    "        raw_df.to_json(raw_output_json_file, orient='records', force_ascii=False, indent=4)\n",
    "        log_message(f\"Raw data saved: CSV ({raw_output_csv_file}), JSON ({raw_output_json_file})\")\n",
    "\n",
    "        df = raw_df.iloc[:, [0, 1, 2]]\n",
    "        df.columns = ['Country', 'GDP (Nominal)', 'Year']\n",
    "        df = df.dropna(subset=['Country', 'GDP (Nominal)'])\n",
    "        df['GDP (B USD)'] = (\n",
    "            df['GDP (Nominal)']\n",
    "            .str.replace(r'[^\\d.]', '', regex=True)\n",
    "            .replace('', '0')\n",
    "            .astype(float) / 1e3\n",
    "        )\n",
    "        df['Year'] = df['Year'].str.replace(r'\\[.*?\\]', '', regex=True)\n",
    "        df = df[['Country', 'GDP (B USD)', 'Year']]\n",
    "        df = df.sort_values(by='GDP (B USD)', ascending=False)\n",
    "        df['GDP (B USD)'] = df['GDP (B USD)'].round(2)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error during data extraction: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "def transform_gdp_data(df):\n",
    "    \"\"\"Transform the extracted GDP data.\"\"\"\n",
    "    log_message(\"Starting Data Transformation\")\n",
    "    try:\n",
    "        with open('country_region_table.json', 'r', encoding='utf-8') as region_file:\n",
    "            region_data = json.load(region_file)\n",
    "        df['Region'] = df['Country'].map(region_data)\n",
    "        log_message(\"Data Transformation Completed\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error during data transformation: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "def load_gdp_data(df):\n",
    "    \"\"\"Load the transformed data into an SQLite database.\"\"\"\n",
    "    log_message(\"Loading data into SQLite database\")\n",
    "    try:\n",
    "        conn = sqlite3.connect('World_Economies.db')\n",
    "        df[['Country', 'GDP (B USD)', 'Year', 'Region']].rename(\n",
    "            columns={'GDP (B USD)': 'GDP_USD_billion'}\n",
    "        ).to_sql('Countries_by_GDP', conn, if_exists='replace', index=False)\n",
    "        conn.close()\n",
    "        log_message(\"Data successfully loaded into SQLite database\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error while loading data into SQLite database: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "def display_countries_with_gdp_over_100():\n",
    "    \"\"\"Display countries with GDP over 100B USD.\"\"\"\n",
    "    log_message(\"Displaying countries with GDP over 100B USD\")\n",
    "    try:\n",
    "        conn = sqlite3.connect('World_Economies.db')\n",
    "        query = \"\"\"\n",
    "        SELECT Country, GDP_USD_billion\n",
    "        FROM Countries_by_GDP\n",
    "        WHERE GDP_USD_billion >= 100\n",
    "        \"\"\"\n",
    "        result = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "        print(\"Countries with GDP >= 100B USD:\")\n",
    "        print(tabulate(result, headers='keys', tablefmt='psql', showindex=False))\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error querying database for countries with GDP >= 100B: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "def display_region_top5_average_gdp():\n",
    "    \"\"\"Calculate and display the average GDP of the top 5 countries by region.\"\"\"\n",
    "    log_message(\"Calculating average GDP of top 5 countries by region\")\n",
    "    try:\n",
    "        conn = sqlite3.connect('World_Economies.db')\n",
    "        query = \"\"\"\n",
    "        WITH RankedCountries AS (\n",
    "            SELECT Country, GDP_USD_billion, Region,\n",
    "                   RANK() OVER (PARTITION BY Region ORDER BY GDP_USD_billion DESC) AS Rank\n",
    "            FROM Countries_by_GDP\n",
    "            WHERE Region IS NOT NULL\n",
    "        )\n",
    "        SELECT Region, AVG(GDP_USD_billion) AS Avg_Top5_GDP\n",
    "        FROM RankedCountries\n",
    "        WHERE Rank <= 5\n",
    "        GROUP BY Region\n",
    "        \"\"\"\n",
    "        result = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "        print(\"Average GDP of top 5 countries by region (excluding None):\")\n",
    "        print(tabulate(result, headers='keys', tablefmt='psql', showindex=False))\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error querying database for top 5 average GDP: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "def save_gdp_data(df, output_csv_file='extracted_gdp_data.csv', output_json_file='extracted_gdp_data.json'):\n",
    "    \"\"\"Save the GDP data to CSV and JSON files.\"\"\"\n",
    "    log_message(\"Saving Extracted Data\")\n",
    "    try:\n",
    "        df.to_csv(output_csv_file, index=False)\n",
    "        df.to_json(output_json_file, orient='records', force_ascii=False, indent=4)\n",
    "        log_message(f\"Data saved: CSV ({output_csv_file}), JSON ({output_json_file})\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"Failed to save data: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "def etl_process():\n",
    "    \"\"\"Main ETL process for GDP data.\"\"\"\n",
    "    try:\n",
    "        log_started()\n",
    "        log_message(\"ETL Process Started\")\n",
    "\n",
    "        extracted_data = extract_gdp_data()\n",
    "        save_gdp_data(extracted_data)\n",
    "        transformed_data = transform_gdp_data(extracted_data)\n",
    "        save_gdp_data(transformed_data, 'transformed_gdp_data.csv', 'transformed_gdp_data.json')\n",
    "        load_gdp_data(transformed_data)\n",
    "        display_countries_with_gdp_over_100()\n",
    "        display_region_top5_average_gdp()\n",
    "\n",
    "        log_message(\"ETL Process Completed Successfully\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"ETL Process Failed: {str(e)}\", level=\"ERROR\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    etl_process()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract_gdp_data()에서 진행하는 데이터 프레임 전처리 과정을 transfrom_gdp_data()함수에서 진행되도록 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import sqlite3\n",
    "import configparser\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tabulate import tabulate\n",
    "\n",
    "def log_started():\n",
    "    \"\"\"Log the start of a new ETL execution.\"\"\"\n",
    "    with open('etl_project_log.txt', 'a') as log_file:\n",
    "        log_file.write(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "        timestamp = datetime.datetime.now().strftime('%Y-%B-%d-%H-%M-%S')\n",
    "        log_file.write(f\"New Execution at {timestamp}\\n\")\n",
    "        log_file.write(\"=\" * 50 + \"\\n\\n\")\n",
    "\n",
    "def log_message(message, level=\"INFO\"):\n",
    "    \"\"\"Log a message with a timestamp and severity level.\"\"\"\n",
    "    timestamp = datetime.datetime.now().strftime('%Y-%b-%d %H:%M:%S')\n",
    "    with open('etl_project_log.txt', 'a') as log_file:\n",
    "        log_file.write(f\"{timestamp} - {level} - {message}\\n\")\n",
    "\n",
    "def extract_gdp_data(config_path='config.ini'):\n",
    "    \"\"\"Extract GDP data from the URL and table class specified in the config file.\"\"\"\n",
    "    if not os.path.exists(config_path):\n",
    "        log_message(f\"Configuration file '{config_path}' not found.\", level=\"ERROR\")\n",
    "        raise FileNotFoundError(f\"Configuration file '{config_path}' not found.\")\n",
    "\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(config_path)\n",
    "\n",
    "    if 'DEFAULT' not in config or 'URL' not in config['DEFAULT'] or 'TABLE_CLASS' not in config['DEFAULT']:\n",
    "        log_message(\"Invalid or missing configuration values in 'config.ini'.\", level=\"ERROR\")\n",
    "        raise ValueError(\"Invalid or missing configuration values in 'config.ini'.\")\n",
    "\n",
    "    url = config['DEFAULT']['URL']\n",
    "    table_class = config['DEFAULT']['TABLE_CLASS']\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        table = soup.find('table', {'class': table_class})\n",
    "\n",
    "        if table is None:\n",
    "            log_message(\"No table found with the specified class.\", level=\"ERROR\")\n",
    "            raise ValueError(\"Failed to locate the GDP table on the webpage.\")\n",
    "\n",
    "        raw_df = pd.read_html(str(table))[0]\n",
    "        raw_output_csv_file = 'raw_gdp_data.csv'\n",
    "        raw_output_json_file = 'raw_gdp_data.json'\n",
    "\n",
    "        # Save raw data before any processing\n",
    "        raw_df.to_csv(raw_output_csv_file, index=False)\n",
    "        raw_df.to_json(raw_output_json_file, orient='records', force_ascii=False, indent=4)\n",
    "        log_message(f\"Raw data saved: CSV ({raw_output_csv_file}), JSON ({raw_output_json_file})\")\n",
    "\n",
    "        return raw_df\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error during data extraction: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "def transform_gdp_data(df):\n",
    "    \"\"\"Transform the extracted GDP data.\"\"\"\n",
    "    log_message(\"Starting Data Transformation\")\n",
    "    try:\n",
    "        df = df.iloc[:, [0, 1, 2]]\n",
    "        df.columns = ['Country', 'GDP (Nominal)', 'Year']\n",
    "        df = df.dropna(subset=['Country', 'GDP (Nominal)'])\n",
    "        df['GDP (B USD)'] = (\n",
    "            df['GDP (Nominal)']\n",
    "            .str.replace(r'[^\\d.]', '', regex=True)\n",
    "            .replace('', '0')\n",
    "            .astype(float) / 1e3\n",
    "        )\n",
    "        df['Year'] = df['Year'].str.replace(r'\\[.*?\\]', '', regex=True)\n",
    "        df = df[['Country', 'GDP (B USD)', 'Year']]\n",
    "        df = df.sort_values(by='GDP (B USD)', ascending=False)\n",
    "        df['GDP (B USD)'] = df['GDP (B USD)'].round(2)\n",
    "\n",
    "        with open('country_region_table.json', 'r', encoding='utf-8') as region_file:\n",
    "            region_data = json.load(region_file)\n",
    "        df['Region'] = df['Country'].map(region_data)\n",
    "\n",
    "        log_message(\"Data Transformation Completed\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error during data transformation: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "def load_gdp_data(df):\n",
    "    \"\"\"Load the transformed data into an SQLite database.\"\"\"\n",
    "    log_message(\"Loading data into SQLite database\")\n",
    "    try:\n",
    "        conn = sqlite3.connect('World_Economies.db')\n",
    "        df[['Country', 'GDP (B USD)', 'Year', 'Region']].rename(\n",
    "            columns={'GDP (B USD)': 'GDP_USD_billion'}\n",
    "        ).to_sql('Countries_by_GDP', conn, if_exists='replace', index=False)\n",
    "        conn.close()\n",
    "        log_message(\"Data successfully loaded into SQLite database\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error while loading data into SQLite database: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "def display_countries_with_gdp_over_100():\n",
    "    \"\"\"Display countries with GDP over 100B USD.\"\"\"\n",
    "    log_message(\"Displaying countries with GDP over 100B USD\")\n",
    "    try:\n",
    "        conn = sqlite3.connect('World_Economies.db')\n",
    "        query = \"\"\"\n",
    "        SELECT Country, GDP_USD_billion\n",
    "        FROM Countries_by_GDP\n",
    "        WHERE GDP_USD_billion >= 100\n",
    "        \"\"\"\n",
    "        result = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "        print(\"Countries with GDP >= 100B USD:\")\n",
    "        print(tabulate(result, headers='keys', tablefmt='psql', showindex=False))\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error querying database for countries with GDP >= 100B: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "def display_region_top5_average_gdp():\n",
    "    \"\"\"Calculate and display the average GDP of the top 5 countries by region.\"\"\"\n",
    "    log_message(\"Calculating average GDP of top 5 countries by region\")\n",
    "    try:\n",
    "        conn = sqlite3.connect('World_Economies.db')\n",
    "        query = \"\"\"\n",
    "        WITH RankedCountries AS (\n",
    "            SELECT Country, GDP_USD_billion, Region,\n",
    "                   RANK() OVER (PARTITION BY Region ORDER BY GDP_USD_billion DESC) AS Rank\n",
    "            FROM Countries_by_GDP\n",
    "            WHERE Region IS NOT NULL\n",
    "        )\n",
    "        SELECT Region, AVG(GDP_USD_billion) AS Avg_Top5_GDP\n",
    "        FROM RankedCountries\n",
    "        WHERE Rank <= 5\n",
    "        GROUP BY Region\n",
    "        \"\"\"\n",
    "        result = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "        print(\"Average GDP of top 5 countries by region (excluding None):\")\n",
    "        print(tabulate(result, headers='keys', tablefmt='psql', showindex=False))\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error querying database for top 5 average GDP: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "def save_gdp_data(df, output_csv_file='extracted_gdp_data.csv', output_json_file='extracted_gdp_data.json'):\n",
    "    \"\"\"Save the GDP data to CSV and JSON files.\"\"\"\n",
    "    log_message(\"Saving Extracted Data\")\n",
    "    try:\n",
    "        df.to_csv(output_csv_file, index=False)\n",
    "        df.to_json(output_json_file, orient='records', force_ascii=False, indent=4)\n",
    "        log_message(f\"Data saved: CSV ({output_csv_file}), JSON ({output_json_file})\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"Failed to save data: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "def etl_process():\n",
    "    \"\"\"Main ETL process for GDP data.\"\"\"\n",
    "    try:\n",
    "        log_started()\n",
    "        log_message(\"ETL Process Started\")\n",
    "\n",
    "        # Extract \n",
    "        raw_data = extract_gdp_data()\n",
    "        # Transform\n",
    "        transformed_data = transform_gdp_data(raw_data)\n",
    "        save_gdp_data(transformed_data, 'transformed_gdp_data.csv', 'transformed_gdp_data.json')\n",
    "        load_gdp_data(transformed_data)\n",
    "        display_countries_with_gdp_over_100()\n",
    "        display_region_top5_average_gdp()\n",
    "\n",
    "        log_message(\"ETL Process Completed Successfully\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"ETL Process Failed: {str(e)}\", level=\"ERROR\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    etl_process()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save_gdp_data() 함수를 없애고  save_gdp_data()에서 하던 저장 과정을 transform_gdp_data(df)함수 안에 넣기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countries with GDP >= 100B USD:\n",
      "+----------------------+-------------------+\n",
      "| Country              |   GDP_USD_billion |\n",
      "|----------------------+-------------------|\n",
      "| World                |         115494    |\n",
      "| United States        |          30337.2  |\n",
      "| China                |          19534.9  |\n",
      "| Germany              |           4921.56 |\n",
      "| Japan                |           4389.33 |\n",
      "| India                |           4271.92 |\n",
      "| United Kingdom       |           3730.26 |\n",
      "| France               |           3283.43 |\n",
      "| Italy                |           2459.6  |\n",
      "| Canada               |           2330.31 |\n",
      "| Brazil               |           2307.16 |\n",
      "| Russia               |           2195.71 |\n",
      "| South Korea          |           1947.13 |\n",
      "| Australia            |           1881.14 |\n",
      "| Spain                |           1827.58 |\n",
      "| Mexico               |           1817.82 |\n",
      "| Indonesia            |           1492.62 |\n",
      "| Turkey               |           1455.41 |\n",
      "| Netherlands          |           1272.96 |\n",
      "| Saudi Arabia         |           1136.58 |\n",
      "| Switzerland          |            999.6  |\n",
      "| Poland               |            915.45 |\n",
      "| Taiwan               |            814.44 |\n",
      "| Belgium              |            689.36 |\n",
      "| Sweden               |            638.78 |\n",
      "| Argentina            |            604.2  |\n",
      "| Ireland              |            587.22 |\n",
      "| United Arab Emirates |            568.57 |\n",
      "| Singapore            |            561.72 |\n",
      "| Austria              |            559.22 |\n",
      "| Israel               |            550.9  |\n",
      "| Thailand             |            545.34 |\n",
      "| Philippines          |            507.67 |\n",
      "| Vietnam              |            506.43 |\n",
      "| Norway               |            503.47 |\n",
      "| Malaysia             |            488.25 |\n",
      "| Iran                 |            463.75 |\n",
      "| Bangladesh           |            455.86 |\n",
      "| Czech Republic       |            452.23 |\n",
      "| Denmark              |            431.23 |\n",
      "| Hong Kong            |            422.06 |\n",
      "| Colombia             |            419.33 |\n",
      "| South Africa         |            418.05 |\n",
      "| Romania              |            406.2  |\n",
      "| Egypt                |            380.04 |\n",
      "| Pakistan             |            374.6  |\n",
      "| Chile                |            362.24 |\n",
      "| Finland              |            319.99 |\n",
      "| Portugal             |            319.93 |\n",
      "| Hungary              |            312.62 |\n",
      "| Kazakhstan           |            306.63 |\n",
      "| Peru                 |            294.9  |\n",
      "| Iraq                 |            270.87 |\n",
      "| Greece               |            265.17 |\n",
      "| Algeria              |            264.27 |\n",
      "| New Zealand          |            262.92 |\n",
      "| Qatar                |            240.22 |\n",
      "| Ethiopia             |            230.03 |\n",
      "| Nigeria              |            199.72 |\n",
      "| Ukraine              |            189.83 |\n",
      "| Morocco              |            168.6  |\n",
      "| Kuwait               |            161.95 |\n",
      "| Slovakia             |            142.62 |\n",
      "| Dominican Republic   |            126.24 |\n",
      "| Uzbekistan           |            125.51 |\n",
      "| Bulgaria             |            123.42 |\n",
      "| Ecuador              |            121.42 |\n",
      "| Puerto Rico          |            120.97 |\n",
      "| Kenya                |            116.32 |\n",
      "| Angola               |            113.29 |\n",
      "| Guatemala            |            112.37 |\n",
      "| Oman                 |            110.99 |\n",
      "| Venezuela            |            106.33 |\n",
      "+----------------------+-------------------+\n",
      "Average GDP of top 5 countries by region (excluding None):\n",
      "+---------------+----------------+\n",
      "| Region        |   Avg_Top5_GDP |\n",
      "|---------------+----------------|\n",
      "| Africa        |        256.134 |\n",
      "| Asia          |       6255.97  |\n",
      "| Europe        |       3318.11  |\n",
      "| North America |       6946.5   |\n",
      "| Oceania       |        734.84  |\n",
      "| South America |        797.566 |\n",
      "+---------------+----------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rd/d9knhb6x6nj7rd817gqlcsr00000gn/T/ipykernel_20546/2074477927.py:52: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  raw_df = pd.read_html(str(table))[0]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import sqlite3\n",
    "import configparser\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "def log_started():\n",
    "    \"\"\"Log the start of a new ETL execution.\"\"\"\n",
    "    with open('etl_project_log.txt', 'a') as log_file:\n",
    "        log_file.write(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "        timestamp = datetime.datetime.now().strftime('%Y-%B-%d-%H-%M-%S')\n",
    "        log_file.write(f\"New Execution at {timestamp}\\n\")\n",
    "        log_file.write(\"=\" * 50 + \"\\n\\n\")\n",
    "        \n",
    "\n",
    "def log_message(message, level=\"INFO\"):\n",
    "    \"\"\"Log a message with a timestamp and severity level.\"\"\"\n",
    "    timestamp = datetime.datetime.now().strftime('%Y-%b-%d %H:%M:%S')\n",
    "    with open('etl_project_log.txt', 'a') as log_file:\n",
    "        log_file.write(f\"{timestamp} - {level} - {message}\\n\")\n",
    "        \n",
    "\n",
    "def extract_gdp_data(config_path='config.ini'):\n",
    "    \"\"\"Extract GDP data from the URL and table class specified in the config file.\"\"\"\n",
    "    if not os.path.exists(config_path):\n",
    "        log_message(f\"Configuration file '{config_path}' not found.\", level=\"ERROR\")\n",
    "        raise FileNotFoundError(f\"Configuration file '{config_path}' not found.\")\n",
    "\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(config_path)\n",
    "\n",
    "    if 'DEFAULT' not in config or 'URL' not in config['DEFAULT'] or 'TABLE_CLASS' not in config['DEFAULT']:\n",
    "        log_message(\"Invalid or missing configuration values in 'config.ini'.\", level=\"ERROR\")\n",
    "        raise ValueError(\"Invalid or missing configuration values in 'config.ini'.\")\n",
    "\n",
    "    url = config['DEFAULT']['URL']\n",
    "    table_class = config['DEFAULT']['TABLE_CLASS']\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        table = soup.find('table', {'class': table_class})\n",
    "\n",
    "        if table is None:\n",
    "            log_message(\"No table found with the specified class.\", level=\"ERROR\")\n",
    "            raise ValueError(\"Failed to locate the GDP table on the webpage.\")\n",
    "\n",
    "        raw_df = pd.read_html(str(table))[0]\n",
    "        raw_output_csv_file = 'raw_gdp_data.csv'\n",
    "        raw_output_json_file = 'raw_gdp_data.json'\n",
    "\n",
    "        # Save raw data before any processing\n",
    "        raw_df.to_csv(raw_output_csv_file, index=False)\n",
    "        raw_df.to_json(raw_output_json_file, orient='records', force_ascii=False, indent=4)\n",
    "        log_message(f\"Raw data saved: CSV ({raw_output_csv_file}), JSON ({raw_output_json_file})\")\n",
    "\n",
    "        return raw_df\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error during data extraction: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "    \n",
    "\n",
    "def transform_gdp_data(df):\n",
    "    \"\"\"Transform the extracted GDP data and save it.\"\"\"\n",
    "    log_message(\"Starting Data Transformation\")\n",
    "    try:\n",
    "        df = df.iloc[:, [0, 1, 2]]\n",
    "        df.columns = ['Country', 'GDP (Nominal)', 'Year']\n",
    "        df = df.dropna(subset=['Country', 'GDP (Nominal)'])\n",
    "        df['GDP (B USD)'] = (\n",
    "            df['GDP (Nominal)']\n",
    "            .str.replace(r'[^\\d.]', '', regex=True)\n",
    "            .replace('', '0')\n",
    "            .astype(float) / 1e3\n",
    "        )\n",
    "        df['Year'] = df['Year'].str.replace(r'\\[.*?\\]', '', regex=True)\n",
    "        df = df[['Country', 'GDP (B USD)', 'Year']]\n",
    "        df = df.sort_values(by='GDP (B USD)', ascending=False)\n",
    "        df['GDP (B USD)'] = df['GDP (B USD)'].round(2)\n",
    "\n",
    "        with open('country_region_table.json', 'r', encoding='utf-8') as region_file:\n",
    "            region_data = json.load(region_file)\n",
    "        df['Region'] = df['Country'].map(region_data)\n",
    "\n",
    "        transformed_output_csv_file = 'transformed_gdp_data.csv'\n",
    "        transformed_output_json_file = 'transformed_gdp_data.json'\n",
    "\n",
    "        # Save transformed data\n",
    "        df.to_csv(transformed_output_csv_file, index=False)\n",
    "        df.to_json(transformed_output_json_file, orient='records', force_ascii=False, indent=4)\n",
    "        log_message(f\"Transformed data saved: CSV ({transformed_output_csv_file}), JSON ({transformed_output_json_file})\")\n",
    "\n",
    "        log_message(\"Data Transformation Completed\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error during data transformation: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def load_gdp_data(df):\n",
    "    \"\"\"Load the transformed data into an SQLite database.\"\"\"\n",
    "    log_message(\"Loading data into SQLite database\")\n",
    "    try:\n",
    "        conn = sqlite3.connect('World_Economies.db')\n",
    "        df[['Country', 'GDP (B USD)', 'Year', 'Region']].rename(\n",
    "            columns={'GDP (B USD)': 'GDP_USD_billion'}\n",
    "        ).to_sql('Countries_by_GDP', conn, if_exists='replace', index=False)\n",
    "        conn.close()\n",
    "        log_message(\"Data successfully loaded into SQLite database\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error while loading data into SQLite database: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def display_countries_with_gdp_over_100():\n",
    "    \"\"\"Display countries with GDP over 100B USD.\"\"\"\n",
    "    log_message(\"Displaying countries with GDP over 100B USD\")\n",
    "    try:\n",
    "        conn = sqlite3.connect('World_Economies.db')\n",
    "        query = \"\"\"\n",
    "        SELECT Country, GDP_USD_billion\n",
    "        FROM Countries_by_GDP\n",
    "        WHERE GDP_USD_billion >= 100\n",
    "        \"\"\"\n",
    "        result = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "        print(\"Countries with GDP >= 100B USD:\")\n",
    "        print(tabulate(result, headers='keys', tablefmt='psql', showindex=False))\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error querying database for countries with GDP >= 100B: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def display_region_top5_average_gdp():\n",
    "    \"\"\"Calculate and display the average GDP of the top 5 countries by region.\"\"\"\n",
    "    log_message(\"Calculating average GDP of top 5 countries by region\")\n",
    "    try:\n",
    "        conn = sqlite3.connect('World_Economies.db')\n",
    "        query = \"\"\"\n",
    "        WITH RankedCountries AS (\n",
    "            SELECT Country, GDP_USD_billion, Region,\n",
    "                   RANK() OVER (PARTITION BY Region ORDER BY GDP_USD_billion DESC) AS Rank\n",
    "            FROM Countries_by_GDP\n",
    "            WHERE Region IS NOT NULL\n",
    "        )\n",
    "        SELECT Region, AVG(GDP_USD_billion) AS Avg_Top5_GDP\n",
    "        FROM RankedCountries\n",
    "        WHERE Rank <= 5\n",
    "        GROUP BY Region\n",
    "        \"\"\"\n",
    "        result = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "        print(\"Average GDP of top 5 countries by region (excluding None):\")\n",
    "        print(tabulate(result, headers='keys', tablefmt='psql', showindex=False))\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error querying database for top 5 average GDP: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "def etl_process():\n",
    "    \"\"\"Main ETL process for GDP data.\"\"\"\n",
    "    try:\n",
    "        log_started()\n",
    "        log_message(\"ETL Process Started\")\n",
    "\n",
    "        # Extract\n",
    "        raw_data = extract_gdp_data()\n",
    "        # Transform\n",
    "        transformed_data = transform_gdp_data(raw_data)\n",
    "        # Load\n",
    "        load_gdp_data(transformed_data)\n",
    "        \n",
    "        # 화면 출력 요구사항\n",
    "        display_countries_with_gdp_over_100()\n",
    "        display_region_top5_average_gdp()\n",
    "\n",
    "        log_message(\"ETL Process Completed Successfully\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"ETL Process Failed: {str(e)}\", level=\"ERROR\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    etl_process()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python의 반복문은 Pandas의 병합 연산보다 속도가 느리므로 transform에 해당 부분 개선\n",
    "```python\n",
    "with open('country_region_table.json', 'r', encoding='utf-8') as region_file:\n",
    "            region_data = json.load(region_file)\n",
    "        df['Region'] = df['Country'].map(region_data)\n",
    "```\n",
    "\n",
    "### Pandas 병합의 장점\n",
    "- 최적화된 C 라이브러리 사용: Pandas는 내부적으로 C로 구현된 병합 연산을 사용하기 때문에 반복문에 비해 훨씬 빠르게 동작합니다.\n",
    "- 벡터화 연산: Pandas 병합은 벡터화 방식으로 작동하므로, 각 행에 대해 개별적으로 처리하지 않고 한 번에 데이터프레임 전체를 처리합니다.\n",
    "- 큰 데이터셋에 적합: 수천에서 수백만 개의 행이 있는 데이터셋에서도 효율적입니다.\n",
    "- Python 반복문의 단점: 해석기 방식 실행 (Python 반복문은 한 행씩 처리하며, 이는 Python 인터프리터에서 실행되기 때문에 속도가 상대적으로 느리다)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Python 반복문 vs Pandas 병합\n",
    "\n",
    "\t- Python 반복문\n",
    "\t\t-\t반복문 방식(map 또는 apply)은 각 행마다 순차적으로 데이터를 처리합니다.\n",
    "\t\t-\t각 국가에 대해 JSON 데이터를 검색하고 매칭해야 하므로 ￼의 시간 복잡도가 발생합니다.\n",
    "\t\t-\t여기서 ￼은 데이터프레임의 행 수, ￼는 JSON 딕셔너리 키의 수입니다.\n",
    "\t\t-\tPython의 반복문은 인터프리터 방식으로 실행되기 때문에, 대량 데이터셋에서 비효율적입니다.\n",
    "\n",
    "\t- Pandas 병합\n",
    "\t\t-\tPandas 병합은 벡터화 연산을 사용하며, 내부적으로 최적화된 C 라이브러리를 통해 동작합니다.\n",
    "\t\t-\t병합 연산의 시간 복잡도는 ￼으로, ￼은 데이터프레임의 행 수, ￼은 병합 대상(region_df) 데이터프레임의 행 수입니다.\n",
    "\t\t-\t대량 데이터셋에서도 병합 속도가 훨씬 빠릅니다.\n",
    "\n",
    "2. JSON 데이터를 Pandas DataFrame으로 변환\n",
    "\n",
    "\t- 변경된 코드에서 json.load()로 읽은 데이터를 Pandas DataFrame으로 변환했기 때문에:\n",
    "\t\t1. \tJSON 데이터를 DataFrame으로 한 번만 변환하면 됩니다.\n",
    "\t\t2.\tPandas 병합 연산으로 모든 국가와 지역 정보를 한 번에 매칭할 수 있습니다.\n",
    "\n",
    "3. 연산 속도의 차이\n",
    "\t- 기존 방식 (Python 반복문):\n",
    "\t\t- 각 행마다 JSON 딕셔너리를 검색하며, 반복적으로 키를 확인해야 하므로 시간이 오래 걸립니다.\n",
    "\t- 변경된 방식 (Pandas 병합):\n",
    "\t\t- 두 DataFrame을 효율적으로 병합하며, 전체 데이터를 벡터화 연산으로 처리하기 때문에 실행 속도가 매우 빨라집니다.\n",
    "\n",
    "4. 결론\n",
    "- 변경된 코드는 Python 반복문 대신 Pandas의 병합 연산을 사용하여 연산 속도가 크게 개선되었습니다. 특히 데이터셋이 커질수록 성능 차이가 더 두드러질 것입니다. 따라서 Pandas 병합 방식을 사용하는 것이 더 효율적이고 확장성이 뛰어난 선택입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countries with GDP >= 100B USD:\n",
      "+----------------------+-------------------+\n",
      "| Country              |   GDP_USD_billion |\n",
      "|----------------------+-------------------|\n",
      "| World                |         115494    |\n",
      "| United States        |          30337.2  |\n",
      "| China                |          19534.9  |\n",
      "| Germany              |           4921.56 |\n",
      "| Japan                |           4389.33 |\n",
      "| India                |           4271.92 |\n",
      "| United Kingdom       |           3730.26 |\n",
      "| France               |           3283.43 |\n",
      "| Italy                |           2459.6  |\n",
      "| Canada               |           2330.31 |\n",
      "| Brazil               |           2307.16 |\n",
      "| Russia               |           2195.71 |\n",
      "| South Korea          |           1947.13 |\n",
      "| Australia            |           1881.14 |\n",
      "| Spain                |           1827.58 |\n",
      "| Mexico               |           1817.82 |\n",
      "| Indonesia            |           1492.62 |\n",
      "| Turkey               |           1455.41 |\n",
      "| Netherlands          |           1272.96 |\n",
      "| Saudi Arabia         |           1136.58 |\n",
      "| Switzerland          |            999.6  |\n",
      "| Poland               |            915.45 |\n",
      "| Taiwan               |            814.44 |\n",
      "| Belgium              |            689.36 |\n",
      "| Sweden               |            638.78 |\n",
      "| Argentina            |            604.2  |\n",
      "| Ireland              |            587.22 |\n",
      "| United Arab Emirates |            568.57 |\n",
      "| Singapore            |            561.72 |\n",
      "| Austria              |            559.22 |\n",
      "| Israel               |            550.9  |\n",
      "| Thailand             |            545.34 |\n",
      "| Philippines          |            507.67 |\n",
      "| Vietnam              |            506.43 |\n",
      "| Norway               |            503.47 |\n",
      "| Malaysia             |            488.25 |\n",
      "| Iran                 |            463.75 |\n",
      "| Bangladesh           |            455.86 |\n",
      "| Czech Republic       |            452.23 |\n",
      "| Denmark              |            431.23 |\n",
      "| Hong Kong            |            422.06 |\n",
      "| Colombia             |            419.33 |\n",
      "| South Africa         |            418.05 |\n",
      "| Romania              |            406.2  |\n",
      "| Egypt                |            380.04 |\n",
      "| Pakistan             |            374.6  |\n",
      "| Chile                |            362.24 |\n",
      "| Finland              |            319.99 |\n",
      "| Portugal             |            319.93 |\n",
      "| Hungary              |            312.62 |\n",
      "| Kazakhstan           |            306.63 |\n",
      "| Peru                 |            294.9  |\n",
      "| Iraq                 |            270.87 |\n",
      "| Greece               |            265.17 |\n",
      "| Algeria              |            264.27 |\n",
      "| New Zealand          |            262.92 |\n",
      "| Qatar                |            240.22 |\n",
      "| Ethiopia             |            230.03 |\n",
      "| Nigeria              |            199.72 |\n",
      "| Ukraine              |            189.83 |\n",
      "| Morocco              |            168.6  |\n",
      "| Kuwait               |            161.95 |\n",
      "| Slovakia             |            142.62 |\n",
      "| Dominican Republic   |            126.24 |\n",
      "| Uzbekistan           |            125.51 |\n",
      "| Bulgaria             |            123.42 |\n",
      "| Ecuador              |            121.42 |\n",
      "| Puerto Rico          |            120.97 |\n",
      "| Kenya                |            116.32 |\n",
      "| Angola               |            113.29 |\n",
      "| Guatemala            |            112.37 |\n",
      "| Oman                 |            110.99 |\n",
      "| Venezuela            |            106.33 |\n",
      "+----------------------+-------------------+\n",
      "Average GDP of top 5 countries by region (excluding None):\n",
      "+---------------+----------------+\n",
      "| Region        |   Avg_Top5_GDP |\n",
      "|---------------+----------------|\n",
      "| Africa        |        256.134 |\n",
      "| Asia          |       6255.97  |\n",
      "| Europe        |       3318.11  |\n",
      "| North America |       6946.5   |\n",
      "| Oceania       |        734.84  |\n",
      "| South America |        797.566 |\n",
      "+---------------+----------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rd/d9knhb6x6nj7rd817gqlcsr00000gn/T/ipykernel_20546/2778556365.py:55: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  raw_df = pd.read_html(str(table))[0]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import sqlite3\n",
    "import configparser\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "def log_started():\n",
    "    \"\"\"Log the start of a new ETL execution.\"\"\"\n",
    "    with open('etl_project_log.txt', 'a') as log_file:\n",
    "        log_file.write(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "        timestamp = datetime.datetime.now().strftime('%Y-%B-%d-%H-%M-%S')\n",
    "        log_file.write(f\"New Execution at {timestamp}\\n\")\n",
    "        log_file.write(\"=\" * 50 + \"\\n\\n\")\n",
    "        \n",
    "\n",
    "def log_message(message, level=\"INFO\"):\n",
    "    \"\"\"Log a message with a timestamp and severity level.\"\"\"\n",
    "    timestamp = datetime.datetime.now().strftime('%Y-%b-%d %H:%M:%S')\n",
    "    with open('etl_project_log.txt', 'a') as log_file:\n",
    "        log_file.write(f\"{timestamp} - {level} - {message}\\n\")\n",
    "        \n",
    "\n",
    "def extract_gdp_data(config_path='config.ini'):\n",
    "    \"\"\"Extract GDP data from the URL and table class specified in the config file.\"\"\"\n",
    "    if not os.path.exists(config_path):\n",
    "        log_message(f\"Configuration file '{config_path}' not found.\", level=\"ERROR\")\n",
    "        raise FileNotFoundError(f\"Configuration file '{config_path}' not found.\")\n",
    "\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(config_path)\n",
    "\n",
    "    if 'DEFAULT' not in config or 'URL' not in config['DEFAULT'] or 'TABLE_CLASS' not in config['DEFAULT']:\n",
    "        log_message(\"Invalid or missing configuration values in 'config.ini'.\", level=\"ERROR\")\n",
    "        raise ValueError(\"Invalid or missing configuration values in 'config.ini'.\")\n",
    "\n",
    "    url = config['DEFAULT']['URL']\n",
    "    table_class = config['DEFAULT']['TABLE_CLASS']\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        table = soup.find('table', {'class': table_class})\n",
    "\n",
    "        if table is None:\n",
    "            log_message(\"No table found with the specified class.\", level=\"ERROR\")\n",
    "            raise ValueError(\"Failed to locate the GDP table on the webpage.\")\n",
    "\n",
    "        raw_df = pd.read_html(str(table))[0]\n",
    "        raw_output_csv_file = 'raw_gdp_data.csv'\n",
    "        raw_output_json_file = 'raw_gdp_data.json'\n",
    "\n",
    "        # Save raw data before any processing\n",
    "        raw_df.to_csv(raw_output_csv_file, index=False)\n",
    "        raw_df.to_json(raw_output_json_file, orient='records', force_ascii=False, indent=4)\n",
    "        log_message(f\"Raw data saved: CSV ({raw_output_csv_file}), JSON ({raw_output_json_file})\")\n",
    "\n",
    "        return raw_df\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error during data extraction: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "    \n",
    "\n",
    "def transform_gdp_data(df):\n",
    "    \"\"\"Transform the extracted GDP data and save it.\"\"\"\n",
    "    log_message(\"Starting Data Transformation\")\n",
    "    try:\n",
    "        # 기본 데이터 정리 및 변환\n",
    "        df = df.iloc[:, [0, 1, 2]]\n",
    "        df.columns = ['Country', 'GDP (Nominal)', 'Year']\n",
    "        df = df.dropna(subset=['Country', 'GDP (Nominal)'])\n",
    "        df['GDP (B USD)'] = (\n",
    "            df['GDP (Nominal)']\n",
    "            .str.replace(r'[^\\d.]', '', regex=True)\n",
    "            .replace('', '0')\n",
    "            .astype(float) / 1e3\n",
    "        )\n",
    "        df['Year'] = df['Year'].str.replace(r'\\[.*?\\]', '', regex=True)\n",
    "        df = df[['Country', 'GDP (B USD)', 'Year']]\n",
    "        df = df.sort_values(by='GDP (B USD)', ascending=False)\n",
    "        df['GDP (B USD)'] = df['GDP (B USD)'].round(2)\n",
    "\n",
    "        # JSON 파일을 DataFrame으로 변환\n",
    "        with open('country_region_table.json', 'r', encoding='utf-8') as region_file:\n",
    "            region_data = json.load(region_file)\n",
    "        \n",
    "        # JSON 데이터를 DataFrame으로 변환\n",
    "        region_df = pd.DataFrame(list(region_data.items()), columns=['Country', 'Region'])\n",
    "\n",
    "        # 데이터 병합\n",
    "        df = pd.merge(df, region_df, on='Country', how='left')\n",
    "\n",
    "        # 변환된 데이터 저장\n",
    "        transformed_output_csv_file = 'transformed_gdp_data.csv'\n",
    "        transformed_output_json_file = 'transformed_gdp_data.json'\n",
    "\n",
    "        df.to_csv(transformed_output_csv_file, index=False)\n",
    "        df.to_json(transformed_output_json_file, orient='records', force_ascii=False, indent=4)\n",
    "\n",
    "        log_message(f\"Transformed data saved: CSV ({transformed_output_csv_file}), JSON ({transformed_output_json_file})\")\n",
    "        log_message(\"Data Transformation Completed\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error during data transformation: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def load_gdp_data(df):\n",
    "    \"\"\"Load the transformed data into an SQLite database.\"\"\"\n",
    "    log_message(\"Loading data into SQLite database\")\n",
    "    try:\n",
    "        conn = sqlite3.connect('World_Economies.db')\n",
    "        df[['Country', 'GDP (B USD)', 'Year', 'Region']].rename(\n",
    "            columns={'GDP (B USD)': 'GDP_USD_billion'}\n",
    "        ).to_sql('Countries_by_GDP', conn, if_exists='replace', index=False)\n",
    "        conn.close()\n",
    "        log_message(\"Data successfully loaded into SQLite database\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error while loading data into SQLite database: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def display_countries_with_gdp_over_100():\n",
    "    \"\"\"Display countries with GDP over 100B USD.\"\"\"\n",
    "    log_message(\"Displaying countries with GDP over 100B USD\")\n",
    "    try:\n",
    "        conn = sqlite3.connect('World_Economies.db')\n",
    "        query = \"\"\"\n",
    "        SELECT Country, GDP_USD_billion\n",
    "        FROM Countries_by_GDP\n",
    "        WHERE GDP_USD_billion >= 100\n",
    "        \"\"\"\n",
    "        result = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "        print(\"Countries with GDP >= 100B USD:\")\n",
    "        print(tabulate(result, headers='keys', tablefmt='psql', showindex=False))\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error querying database for countries with GDP >= 100B: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def display_region_top5_average_gdp():\n",
    "    \"\"\"Calculate and display the average GDP of the top 5 countries by region.\"\"\"\n",
    "    log_message(\"Calculating average GDP of top 5 countries by region\")\n",
    "    try:\n",
    "        conn = sqlite3.connect('World_Economies.db')\n",
    "        query = \"\"\"\n",
    "        WITH RankedCountries AS (\n",
    "            SELECT Country, GDP_USD_billion, Region,\n",
    "                   RANK() OVER (PARTITION BY Region ORDER BY GDP_USD_billion DESC) AS Rank\n",
    "            FROM Countries_by_GDP\n",
    "            WHERE Region IS NOT NULL\n",
    "        )\n",
    "        SELECT Region, AVG(GDP_USD_billion) AS Avg_Top5_GDP\n",
    "        FROM RankedCountries\n",
    "        WHERE Rank <= 5\n",
    "        GROUP BY Region\n",
    "        \"\"\"\n",
    "        result = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "        print(\"Average GDP of top 5 countries by region (excluding None):\")\n",
    "        print(tabulate(result, headers='keys', tablefmt='psql', showindex=False))\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error querying database for top 5 average GDP: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "def etl_process():\n",
    "    \"\"\"Main ETL process for GDP data.\"\"\"\n",
    "    try:\n",
    "        log_started()\n",
    "        log_message(\"ETL Process Started\")\n",
    "\n",
    "        # Extract\n",
    "        raw_data = extract_gdp_data()\n",
    "        # Transform\n",
    "        transformed_data = transform_gdp_data(raw_data)\n",
    "        # Load\n",
    "        load_gdp_data(transformed_data)\n",
    "        \n",
    "        # 화면 출력 요구사항\n",
    "        display_countries_with_gdp_over_100()\n",
    "        display_region_top5_average_gdp()\n",
    "\n",
    "        log_message(\"ETL Process Completed Successfully\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"ETL Process Failed: {str(e)}\", level=\"ERROR\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    etl_process()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transform_gdp_data(df)에서 진행하는 과정 중 try문에서 오류를 더 정확히 확인하기 위해서 더 작게 쪼갬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countries with GDP >= 100B USD:\n",
      "+----------------------+-------------------+\n",
      "| Country              |   GDP_USD_billion |\n",
      "|----------------------+-------------------|\n",
      "| World                |         115494    |\n",
      "| United States        |          30337.2  |\n",
      "| China                |          19534.9  |\n",
      "| Germany              |           4921.56 |\n",
      "| Japan                |           4389.33 |\n",
      "| India                |           4271.92 |\n",
      "| United Kingdom       |           3730.26 |\n",
      "| France               |           3283.43 |\n",
      "| Italy                |           2459.6  |\n",
      "| Canada               |           2330.31 |\n",
      "| Brazil               |           2307.16 |\n",
      "| Russia               |           2195.71 |\n",
      "| South Korea          |           1947.13 |\n",
      "| Australia            |           1881.14 |\n",
      "| Spain                |           1827.58 |\n",
      "| Mexico               |           1817.82 |\n",
      "| Indonesia            |           1492.62 |\n",
      "| Turkey               |           1455.41 |\n",
      "| Netherlands          |           1272.96 |\n",
      "| Saudi Arabia         |           1136.58 |\n",
      "| Switzerland          |            999.6  |\n",
      "| Poland               |            915.45 |\n",
      "| Taiwan               |            814.44 |\n",
      "| Belgium              |            689.36 |\n",
      "| Sweden               |            638.78 |\n",
      "| Argentina            |            604.2  |\n",
      "| Ireland              |            587.22 |\n",
      "| United Arab Emirates |            568.57 |\n",
      "| Singapore            |            561.72 |\n",
      "| Austria              |            559.22 |\n",
      "| Israel               |            550.9  |\n",
      "| Thailand             |            545.34 |\n",
      "| Philippines          |            507.67 |\n",
      "| Vietnam              |            506.43 |\n",
      "| Norway               |            503.47 |\n",
      "| Malaysia             |            488.25 |\n",
      "| Iran                 |            463.75 |\n",
      "| Bangladesh           |            455.86 |\n",
      "| Czech Republic       |            452.23 |\n",
      "| Denmark              |            431.23 |\n",
      "| Hong Kong            |            422.06 |\n",
      "| Colombia             |            419.33 |\n",
      "| South Africa         |            418.05 |\n",
      "| Romania              |            406.2  |\n",
      "| Egypt                |            380.04 |\n",
      "| Pakistan             |            374.6  |\n",
      "| Chile                |            362.24 |\n",
      "| Finland              |            319.99 |\n",
      "| Portugal             |            319.93 |\n",
      "| Hungary              |            312.62 |\n",
      "| Kazakhstan           |            306.63 |\n",
      "| Peru                 |            294.9  |\n",
      "| Iraq                 |            270.87 |\n",
      "| Greece               |            265.17 |\n",
      "| Algeria              |            264.27 |\n",
      "| New Zealand          |            262.92 |\n",
      "| Qatar                |            240.22 |\n",
      "| Ethiopia             |            230.03 |\n",
      "| Nigeria              |            199.72 |\n",
      "| Ukraine              |            189.83 |\n",
      "| Morocco              |            168.6  |\n",
      "| Kuwait               |            161.95 |\n",
      "| Slovakia             |            142.62 |\n",
      "| Dominican Republic   |            126.24 |\n",
      "| Uzbekistan           |            125.51 |\n",
      "| Bulgaria             |            123.42 |\n",
      "| Ecuador              |            121.42 |\n",
      "| Puerto Rico          |            120.97 |\n",
      "| Kenya                |            116.32 |\n",
      "| Angola               |            113.29 |\n",
      "| Guatemala            |            112.37 |\n",
      "| Oman                 |            110.99 |\n",
      "| Venezuela            |            106.33 |\n",
      "+----------------------+-------------------+\n",
      "Average GDP of top 5 countries by region (excluding None):\n",
      "+---------------+----------------+\n",
      "| Region        |   Avg_Top5_GDP |\n",
      "|---------------+----------------|\n",
      "| Africa        |        256.134 |\n",
      "| Asia          |       6255.97  |\n",
      "| Europe        |       3318.11  |\n",
      "| North America |       6946.5   |\n",
      "| Oceania       |        734.84  |\n",
      "| South America |        797.566 |\n",
      "+---------------+----------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rd/d9knhb6x6nj7rd817gqlcsr00000gn/T/ipykernel_20546/1493506717.py:55: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  raw_df = pd.read_html(str(table))[0]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import sqlite3\n",
    "import configparser\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "def log_started():\n",
    "    \"\"\"Log the start of a new ETL execution.\"\"\"\n",
    "    with open('etl_project_log.txt', 'a') as log_file:\n",
    "        log_file.write(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "        timestamp = datetime.datetime.now().strftime('%Y-%B-%d-%H-%M-%S')\n",
    "        log_file.write(f\"New Execution at {timestamp}\\n\")\n",
    "        log_file.write(\"=\" * 50 + \"\\n\\n\")\n",
    "        \n",
    "\n",
    "def log_message(message, level=\"INFO\"):\n",
    "    \"\"\"Log a message with a timestamp and severity level.\"\"\"\n",
    "    timestamp = datetime.datetime.now().strftime('%Y-%b-%d %H:%M:%S')\n",
    "    with open('etl_project_log.txt', 'a') as log_file:\n",
    "        log_file.write(f\"{timestamp} - {level} - {message}\\n\")\n",
    "        \n",
    "\n",
    "def extract_gdp_data(config_path='config.ini'):\n",
    "    \"\"\"Extract GDP data from the URL and table class specified in the config file.\"\"\"\n",
    "    if not os.path.exists(config_path):\n",
    "        log_message(f\"Configuration file '{config_path}' not found.\", level=\"ERROR\")\n",
    "        raise FileNotFoundError(f\"Configuration file '{config_path}' not found.\")\n",
    "\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(config_path)\n",
    "\n",
    "    if 'DEFAULT' not in config or 'URL' not in config['DEFAULT'] or 'TABLE_CLASS' not in config['DEFAULT']:\n",
    "        log_message(\"Invalid or missing configuration values in 'config.ini'.\", level=\"ERROR\")\n",
    "        raise ValueError(\"Invalid or missing configuration values in 'config.ini'.\")\n",
    "\n",
    "    url = config['DEFAULT']['URL']\n",
    "    table_class = config['DEFAULT']['TABLE_CLASS']\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        table = soup.find('table', {'class': table_class})\n",
    "\n",
    "        if table is None:\n",
    "            log_message(\"No table found with the specified class.\", level=\"ERROR\")\n",
    "            raise ValueError(\"Failed to locate the GDP table on the webpage.\")\n",
    "\n",
    "        raw_df = pd.read_html(str(table))[0]\n",
    "        raw_output_csv_file = 'raw_gdp_data.csv'\n",
    "        raw_output_json_file = 'raw_gdp_data.json'\n",
    "\n",
    "        # Save raw data before any processing\n",
    "        raw_df.to_csv(raw_output_csv_file, index=False)\n",
    "        raw_df.to_json(raw_output_json_file, orient='records', force_ascii=False, indent=4)\n",
    "        log_message(f\"Raw data saved: CSV ({raw_output_csv_file}), JSON ({raw_output_json_file})\")\n",
    "\n",
    "        return raw_df\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error during data extraction: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "    \n",
    "\n",
    "def transform_gdp_data(df):\n",
    "    \"\"\"Transform the extracted GDP data and save it.\"\"\"\n",
    "    log_message(\"Starting Data Transformation\")\n",
    "    try:\n",
    "        # 1. 기본 데이터 정리 및 변환\n",
    "        try:\n",
    "            df = df.iloc[:, [0, 1, 2]]\n",
    "            df.columns = ['Country', 'GDP (Nominal)', 'Year']\n",
    "            df = df.dropna(subset=['Country', 'GDP (Nominal)'])\n",
    "            df['GDP (B USD)'] = (\n",
    "                df['GDP (Nominal)']\n",
    "                .str.replace(r'[^\\d.]', '', regex=True)\n",
    "                .replace('', '0')\n",
    "                .astype(float) / 1e3\n",
    "            )\n",
    "            df['Year'] = df['Year'].str.replace(r'\\[.*?\\]', '', regex=True)\n",
    "            df = df[['Country', 'GDP (B USD)', 'Year']]\n",
    "            df = df.sort_values(by='GDP (B USD)', ascending=False)\n",
    "            df['GDP (B USD)'] = df['GDP (B USD)'].round(2)\n",
    "            log_message(\"Data cleaning and transformation completed.\")\n",
    "        except Exception as e:\n",
    "            log_message(f\"Error in data cleaning and transformation: {str(e)}\", level=\"ERROR\")\n",
    "            raise\n",
    "\n",
    "        # 2. JSON 파일 읽기 및 데이터 병합\n",
    "        try:\n",
    "            with open('country_region_table.json', 'r', encoding='utf-8') as region_file:\n",
    "                region_data = json.load(region_file)\n",
    "            region_df = pd.DataFrame(list(region_data.items()), columns=['Country', 'Region'])\n",
    "            df = pd.merge(df, region_df, on='Country', how='left')\n",
    "            log_message(\"Region data merged successfully.\")\n",
    "        except FileNotFoundError:\n",
    "            log_message(\"Region mapping file 'country_region_table.json' not found.\", level=\"ERROR\")\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            log_message(f\"Error during region data merging: {str(e)}\", level=\"ERROR\")\n",
    "            raise\n",
    "\n",
    "        # 3. 변환된 데이터 저장\n",
    "        try:\n",
    "            transformed_output_csv_file = 'transformed_gdp_data.csv'\n",
    "            transformed_output_json_file = 'transformed_gdp_data.json'\n",
    "\n",
    "            df.to_csv(transformed_output_csv_file, index=False)\n",
    "            df.to_json(transformed_output_json_file, orient='records', force_ascii=False, indent=4)\n",
    "            log_message(f\"Transformed data saved: CSV ({transformed_output_csv_file}), JSON ({transformed_output_json_file})\")\n",
    "        except Exception as e:\n",
    "            log_message(f\"Error while saving transformed data: {str(e)}\", level=\"ERROR\")\n",
    "            raise\n",
    "\n",
    "        log_message(\"Data Transformation Completed\")\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error during data transformation: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def load_gdp_data(df):\n",
    "    \"\"\"Load the transformed data into an SQLite database.\"\"\"\n",
    "    log_message(\"Loading data into SQLite database\")\n",
    "    try:\n",
    "        conn = sqlite3.connect('World_Economies.db')\n",
    "        df[['Country', 'GDP (B USD)', 'Year', 'Region']].rename(\n",
    "            columns={'GDP (B USD)': 'GDP_USD_billion'}\n",
    "        ).to_sql('Countries_by_GDP', conn, if_exists='replace', index=False)\n",
    "        conn.close()\n",
    "        log_message(\"Data successfully loaded into SQLite database\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error while loading data into SQLite database: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def display_countries_with_gdp_over_100():\n",
    "    \"\"\"Display countries with GDP over 100B USD.\"\"\"\n",
    "    log_message(\"Displaying countries with GDP over 100B USD\")\n",
    "    try:\n",
    "        conn = sqlite3.connect('World_Economies.db')\n",
    "        query = \"\"\"\n",
    "        SELECT Country, GDP_USD_billion\n",
    "        FROM Countries_by_GDP\n",
    "        WHERE GDP_USD_billion >= 100\n",
    "        \"\"\"\n",
    "        result = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "        print(\"Countries with GDP >= 100B USD:\")\n",
    "        print(tabulate(result, headers='keys', tablefmt='psql', showindex=False))\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error querying database for countries with GDP >= 100B: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def display_region_top5_average_gdp():\n",
    "    \"\"\"Calculate and display the average GDP of the top 5 countries by region.\"\"\"\n",
    "    log_message(\"Calculating average GDP of top 5 countries by region\")\n",
    "    try:\n",
    "        conn = sqlite3.connect('World_Economies.db')\n",
    "        query = \"\"\"\n",
    "        WITH RankedCountries AS (\n",
    "            SELECT Country, GDP_USD_billion, Region,\n",
    "                   RANK() OVER (PARTITION BY Region ORDER BY GDP_USD_billion DESC) AS Rank\n",
    "            FROM Countries_by_GDP\n",
    "            WHERE Region IS NOT NULL\n",
    "        )\n",
    "        SELECT Region, AVG(GDP_USD_billion) AS Avg_Top5_GDP\n",
    "        FROM RankedCountries\n",
    "        WHERE Rank <= 5\n",
    "        GROUP BY Region\n",
    "        \"\"\"\n",
    "        result = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "        print(\"Average GDP of top 5 countries by region (excluding None):\")\n",
    "        print(tabulate(result, headers='keys', tablefmt='psql', showindex=False))\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error querying database for top 5 average GDP: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "def etl_process():\n",
    "    \"\"\"Main ETL process for GDP data.\"\"\"\n",
    "    try:\n",
    "        log_started()\n",
    "        log_message(\"ETL Process Started\")\n",
    "\n",
    "        # Extract\n",
    "        raw_data = extract_gdp_data()\n",
    "        # Transform\n",
    "        transformed_data = transform_gdp_data(raw_data)\n",
    "        # Load\n",
    "        load_gdp_data(transformed_data)\n",
    "        \n",
    "        # 화면 출력 요구사항\n",
    "        display_countries_with_gdp_over_100()\n",
    "        display_region_top5_average_gdp()\n",
    "\n",
    "        log_message(\"ETL Process Completed Successfully\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"ETL Process Failed: {str(e)}\", level=\"ERROR\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    etl_process()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract_gdp_data()에서 진행하는 과정 중 try문에서 오류를 더 정확히 확인하기 위해서 더 작게 쪼갬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countries with GDP >= 100B USD:\n",
      "+----------------------+-------------------+\n",
      "| Country              |   GDP_USD_billion |\n",
      "|----------------------+-------------------|\n",
      "| World                |         115494    |\n",
      "| United States        |          30337.2  |\n",
      "| China                |          19534.9  |\n",
      "| Germany              |           4921.56 |\n",
      "| Japan                |           4389.33 |\n",
      "| India                |           4271.92 |\n",
      "| United Kingdom       |           3730.26 |\n",
      "| France               |           3283.43 |\n",
      "| Italy                |           2459.6  |\n",
      "| Canada               |           2330.31 |\n",
      "| Brazil               |           2307.16 |\n",
      "| Russia               |           2195.71 |\n",
      "| South Korea          |           1947.13 |\n",
      "| Australia            |           1881.14 |\n",
      "| Spain                |           1827.58 |\n",
      "| Mexico               |           1817.82 |\n",
      "| Indonesia            |           1492.62 |\n",
      "| Turkey               |           1455.41 |\n",
      "| Netherlands          |           1272.96 |\n",
      "| Saudi Arabia         |           1136.58 |\n",
      "| Switzerland          |            999.6  |\n",
      "| Poland               |            915.45 |\n",
      "| Taiwan               |            814.44 |\n",
      "| Belgium              |            689.36 |\n",
      "| Sweden               |            638.78 |\n",
      "| Argentina            |            604.2  |\n",
      "| Ireland              |            587.22 |\n",
      "| United Arab Emirates |            568.57 |\n",
      "| Singapore            |            561.72 |\n",
      "| Austria              |            559.22 |\n",
      "| Israel               |            550.9  |\n",
      "| Thailand             |            545.34 |\n",
      "| Philippines          |            507.67 |\n",
      "| Vietnam              |            506.43 |\n",
      "| Norway               |            503.47 |\n",
      "| Malaysia             |            488.25 |\n",
      "| Iran                 |            463.75 |\n",
      "| Bangladesh           |            455.86 |\n",
      "| Czech Republic       |            452.23 |\n",
      "| Denmark              |            431.23 |\n",
      "| Hong Kong            |            422.06 |\n",
      "| Colombia             |            419.33 |\n",
      "| South Africa         |            418.05 |\n",
      "| Romania              |            406.2  |\n",
      "| Egypt                |            380.04 |\n",
      "| Pakistan             |            374.6  |\n",
      "| Chile                |            362.24 |\n",
      "| Finland              |            319.99 |\n",
      "| Portugal             |            319.93 |\n",
      "| Hungary              |            312.62 |\n",
      "| Kazakhstan           |            306.63 |\n",
      "| Peru                 |            294.9  |\n",
      "| Iraq                 |            270.87 |\n",
      "| Greece               |            265.17 |\n",
      "| Algeria              |            264.27 |\n",
      "| New Zealand          |            262.92 |\n",
      "| Qatar                |            240.22 |\n",
      "| Ethiopia             |            230.03 |\n",
      "| Nigeria              |            199.72 |\n",
      "| Ukraine              |            189.83 |\n",
      "| Morocco              |            168.6  |\n",
      "| Kuwait               |            161.95 |\n",
      "| Slovakia             |            142.62 |\n",
      "| Dominican Republic   |            126.24 |\n",
      "| Uzbekistan           |            125.51 |\n",
      "| Bulgaria             |            123.42 |\n",
      "| Ecuador              |            121.42 |\n",
      "| Puerto Rico          |            120.97 |\n",
      "| Kenya                |            116.32 |\n",
      "| Angola               |            113.29 |\n",
      "| Guatemala            |            112.37 |\n",
      "| Oman                 |            110.99 |\n",
      "| Venezuela            |            106.33 |\n",
      "+----------------------+-------------------+\n",
      "Average GDP of top 5 countries by region (excluding None):\n",
      "+---------------+----------------+\n",
      "| Region        |   Avg_Top5_GDP |\n",
      "|---------------+----------------|\n",
      "| Africa        |        256.134 |\n",
      "| Asia          |       6255.97  |\n",
      "| Europe        |       3318.11  |\n",
      "| North America |       6946.5   |\n",
      "| Oceania       |        734.84  |\n",
      "| South America |        797.566 |\n",
      "+---------------+----------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rd/d9knhb6x6nj7rd817gqlcsr00000gn/T/ipykernel_20546/2855098984.py:77: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  raw_df = pd.read_html(str(table))[0]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import sqlite3\n",
    "import configparser\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "def log_started():\n",
    "    \"\"\"Log the start of a new ETL execution.\"\"\"\n",
    "    with open('etl_project_log.txt', 'a') as log_file:\n",
    "        log_file.write(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "        timestamp = datetime.datetime.now().strftime('%Y-%B-%d-%H-%M-%S')\n",
    "        log_file.write(f\"New Execution at {timestamp}\\n\")\n",
    "        log_file.write(\"=\" * 50 + \"\\n\\n\")\n",
    "        \n",
    "\n",
    "def log_message(message, level=\"INFO\"):\n",
    "    \"\"\"Log a message with a timestamp and severity level.\"\"\"\n",
    "    timestamp = datetime.datetime.now().strftime('%Y-%b-%d %H:%M:%S')\n",
    "    with open('etl_project_log.txt', 'a') as log_file:\n",
    "        log_file.write(f\"{timestamp} - {level} - {message}\\n\")\n",
    "        \n",
    "\n",
    "def extract_gdp_data(config_path='config.ini'):\n",
    "    \"\"\"Extract GDP data from the URL and table class specified in the config file.\"\"\"\n",
    "    log_message(\"Starting data extraction process\")\n",
    "    \n",
    "    # 1. 설정 파일 확인 및 읽기\n",
    "    if not os.path.exists(config_path):\n",
    "        log_message(f\"Configuration file '{config_path}' not found.\", level=\"ERROR\")\n",
    "        raise FileNotFoundError(f\"Configuration file '{config_path}' not found.\")\n",
    "    \n",
    "    try:\n",
    "        config = configparser.ConfigParser()\n",
    "        config.read(config_path)\n",
    "        if 'DEFAULT' not in config or 'URL' not in config['DEFAULT'] or 'TABLE_CLASS' not in config['DEFAULT']:\n",
    "            log_message(\"Invalid or missing configuration values in 'config.ini'.\", level=\"ERROR\")\n",
    "            raise ValueError(\"Invalid or missing configuration values in 'config.ini'.\")\n",
    "        url = config['DEFAULT']['URL']\n",
    "        table_class = config['DEFAULT']['TABLE_CLASS']\n",
    "        log_message(\"Configuration file read successfully\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error reading configuration file: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "    \n",
    "    # 2. 웹 페이지 요청 및 HTML 가져오기\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        log_message(f\"Successfully fetched data from URL: {url}\")\n",
    "    except requests.exceptions.Timeout:\n",
    "        log_message(\"Request timed out while accessing the URL.\", level=\"ERROR\")\n",
    "        raise\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        log_message(f\"Error during requests to the URL: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "    \n",
    "    # 3. HTML 파싱 및 테이블 찾기\n",
    "    try:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        table = soup.find('table', {'class': table_class})\n",
    "        if table is None:\n",
    "            log_message(f\"No table found with the specified class '{table_class}'.\", level=\"ERROR\")\n",
    "            raise ValueError(\"Failed to locate the GDP table on the webpage.\")\n",
    "        log_message(\"Successfully located the GDP table in the HTML\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error parsing HTML or finding table: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "    \n",
    "    # 4. 테이블 데이터를 DataFrame으로 변환\n",
    "    try:\n",
    "        raw_df = pd.read_html(str(table))[0]\n",
    "        raw_output_csv_file = 'raw_gdp_data.csv'\n",
    "        raw_output_json_file = 'raw_gdp_data.json'\n",
    "\n",
    "        # Save raw data before any processing\n",
    "        raw_df.to_csv(raw_output_csv_file, index=False)\n",
    "        raw_df.to_json(raw_output_json_file, orient='records', force_ascii=False, indent=4)\n",
    "        log_message(f\"Raw data saved: CSV ({raw_output_csv_file}), JSON ({raw_output_json_file})\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error converting table to DataFrame or saving raw data: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "    \n",
    "    log_message(\"Data extraction process completed successfully\")\n",
    "    return raw_df\n",
    "    \n",
    "\n",
    "def transform_gdp_data(df):\n",
    "    \"\"\"Transform the extracted GDP data and save it.\"\"\"\n",
    "    log_message(\"Starting Data Transformation\")\n",
    "    try:\n",
    "        # 1. 기본 데이터 정리 및 변환\n",
    "        try:\n",
    "            df = df.iloc[:, [0, 1, 2]]\n",
    "            df.columns = ['Country', 'GDP (Nominal)', 'Year']\n",
    "            df = df.dropna(subset=['Country', 'GDP (Nominal)'])\n",
    "            df['GDP (B USD)'] = (\n",
    "                df['GDP (Nominal)']\n",
    "                .str.replace(r'[^\\d.]', '', regex=True)\n",
    "                .replace('', '0')\n",
    "                .astype(float) / 1e3\n",
    "            )\n",
    "            df['Year'] = df['Year'].str.replace(r'\\[.*?\\]', '', regex=True)\n",
    "            df = df[['Country', 'GDP (B USD)', 'Year']]\n",
    "            df = df.sort_values(by='GDP (B USD)', ascending=False)\n",
    "            df['GDP (B USD)'] = df['GDP (B USD)'].round(2)\n",
    "            log_message(\"Data cleaning and transformation completed.\")\n",
    "        except Exception as e:\n",
    "            log_message(f\"Error in data cleaning and transformation: {str(e)}\", level=\"ERROR\")\n",
    "            raise\n",
    "\n",
    "        # 2. JSON 파일 읽기 및 데이터 병합\n",
    "        try:\n",
    "            with open('country_region_table.json', 'r', encoding='utf-8') as region_file:\n",
    "                region_data = json.load(region_file)\n",
    "            region_df = pd.DataFrame(list(region_data.items()), columns=['Country', 'Region'])\n",
    "            df = pd.merge(df, region_df, on='Country', how='left')\n",
    "            log_message(\"Region data merged successfully.\")\n",
    "        except FileNotFoundError:\n",
    "            log_message(\"Region mapping file 'country_region_table.json' not found.\", level=\"ERROR\")\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            log_message(f\"Error during region data merging: {str(e)}\", level=\"ERROR\")\n",
    "            raise\n",
    "\n",
    "        # 3. 변환된 데이터 저장\n",
    "        try:\n",
    "            transformed_output_csv_file = 'transformed_gdp_data.csv'\n",
    "            transformed_output_json_file = 'transformed_gdp_data.json'\n",
    "\n",
    "            df.to_csv(transformed_output_csv_file, index=False)\n",
    "            df.to_json(transformed_output_json_file, orient='records', force_ascii=False, indent=4)\n",
    "            log_message(f\"Transformed data saved: CSV ({transformed_output_csv_file}), JSON ({transformed_output_json_file})\")\n",
    "        except Exception as e:\n",
    "            log_message(f\"Error while saving transformed data: {str(e)}\", level=\"ERROR\")\n",
    "            raise\n",
    "\n",
    "        log_message(\"Data Transformation Completed\")\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error during data transformation: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def load_gdp_data(df):\n",
    "    \"\"\"Load the transformed data into an SQLite database.\"\"\"\n",
    "    log_message(\"Loading data into SQLite database\")\n",
    "    try:\n",
    "        conn = sqlite3.connect('World_Economies.db')\n",
    "        df[['Country', 'GDP (B USD)', 'Year', 'Region']].rename(\n",
    "            columns={'GDP (B USD)': 'GDP_USD_billion'}\n",
    "        ).to_sql('Countries_by_GDP', conn, if_exists='replace', index=False)\n",
    "        conn.close()\n",
    "        log_message(\"Data successfully loaded into SQLite database\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error while loading data into SQLite database: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def display_countries_with_gdp_over_100():\n",
    "    \"\"\"Display countries with GDP over 100B USD.\"\"\"\n",
    "    log_message(\"Displaying countries with GDP over 100B USD\")\n",
    "    try:\n",
    "        conn = sqlite3.connect('World_Economies.db')\n",
    "        query = \"\"\"\n",
    "        SELECT Country, GDP_USD_billion\n",
    "        FROM Countries_by_GDP\n",
    "        WHERE GDP_USD_billion >= 100\n",
    "        \"\"\"\n",
    "        result = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "        print(\"Countries with GDP >= 100B USD:\")\n",
    "        print(tabulate(result, headers='keys', tablefmt='psql', showindex=False))\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error querying database for countries with GDP >= 100B: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def display_region_top5_average_gdp():\n",
    "    \"\"\"Calculate and display the average GDP of the top 5 countries by region.\"\"\"\n",
    "    log_message(\"Calculating average GDP of top 5 countries by region\")\n",
    "    try:\n",
    "        conn = sqlite3.connect('World_Economies.db')\n",
    "        query = \"\"\"\n",
    "        WITH RankedCountries AS (\n",
    "            SELECT Country, GDP_USD_billion, Region,\n",
    "                   RANK() OVER (PARTITION BY Region ORDER BY GDP_USD_billion DESC) AS Rank\n",
    "            FROM Countries_by_GDP\n",
    "            WHERE Region IS NOT NULL\n",
    "        )\n",
    "        SELECT Region, AVG(GDP_USD_billion) AS Avg_Top5_GDP\n",
    "        FROM RankedCountries\n",
    "        WHERE Rank <= 5\n",
    "        GROUP BY Region\n",
    "        \"\"\"\n",
    "        result = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "        print(\"Average GDP of top 5 countries by region (excluding None):\")\n",
    "        print(tabulate(result, headers='keys', tablefmt='psql', showindex=False))\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error querying database for top 5 average GDP: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "def etl_process():\n",
    "    \"\"\"Main ETL process for GDP data.\"\"\"\n",
    "    try:\n",
    "        log_started()\n",
    "        log_message(\"ETL Process Started\")\n",
    "\n",
    "        # Extract\n",
    "        raw_data = extract_gdp_data()\n",
    "        # Transform\n",
    "        transformed_data = transform_gdp_data(raw_data)\n",
    "        # Load\n",
    "        load_gdp_data(transformed_data)\n",
    "        \n",
    "        # 화면 출력 요구사항\n",
    "        display_countries_with_gdp_over_100()\n",
    "        display_region_top5_average_gdp()\n",
    "\n",
    "        log_message(\"ETL Process Completed Successfully\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"ETL Process Failed: {str(e)}\", level=\"ERROR\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    etl_process()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 내 코드를 모르는 사람이 처음 보았을 때, 이해 가능하도록 하는 설명 및 주석 추가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import sqlite3\n",
    "import configparser\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "def log_started():\n",
    "    \"\"\"\n",
    "    Log the start of a new ETL execution.\n",
    "    \n",
    "    This function creates a separator in the log file and records a timestamp\n",
    "    to indicate the beginning of a new ETL execution.\n",
    "    \"\"\"\n",
    "    with open('etl_project_log.txt', 'a') as log_file:\n",
    "        log_file.write(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "        timestamp = datetime.datetime.now().strftime('%Y-%B-%d-%H-%M-%S')\n",
    "        log_file.write(f\"New Execution at {timestamp}\\n\")\n",
    "        log_file.write(\"=\" * 50 + \"\\n\\n\")\n",
    "\n",
    "\n",
    "def log_message(message, level=\"INFO\"):\n",
    "    \"\"\"\n",
    "    Log a message with a timestamp and severity level.\n",
    "\n",
    "    Parameters:\n",
    "        message (str): The message to log.\n",
    "        level (str): The severity level of the message (default: \"INFO\").\n",
    "    \"\"\"\n",
    "    timestamp = datetime.datetime.now().strftime('%Y-%b-%d %H:%M:%S')\n",
    "    with open('etl_project_log.txt', 'a') as log_file:\n",
    "        log_file.write(f\"{timestamp} - {level} - {message}\\n\")\n",
    "\n",
    "\n",
    "def extract_gdp_data(config_path='config.ini'):\n",
    "    \"\"\"\n",
    "    Extract GDP data from a webpage based on a configuration file.\n",
    "\n",
    "    Parameters:\n",
    "        config_path (str): Path to the configuration file (default: 'config.ini').\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Raw GDP data extracted from the webpage.\n",
    "    \"\"\"\n",
    "    log_message(\"Starting data extraction process\")\n",
    "\n",
    "    # Step 1: Read and validate the configuration file\n",
    "    if not os.path.exists(config_path):\n",
    "        log_message(f\"Configuration file '{config_path}' not found.\", level=\"ERROR\")\n",
    "        raise FileNotFoundError(f\"Configuration file '{config_path}' not found.\")\n",
    "\n",
    "    try:\n",
    "        config = configparser.ConfigParser()\n",
    "        config.read(config_path)\n",
    "        url = config['DEFAULT']['URL']\n",
    "        table_class = config['DEFAULT']['TABLE_CLASS']\n",
    "        log_message(\"Configuration file read successfully\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error reading configuration file: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "    # Step 2: Fetch the webpage data\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        log_message(f\"Successfully fetched data from URL: {url}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        log_message(f\"Error during requests to the URL: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "    # Step 3: Parse the HTML and extract the table\n",
    "    try:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        table = soup.find('table', {'class': table_class})\n",
    "        if table is None:\n",
    "            log_message(f\"No table found with the specified class '{table_class}'.\", level=\"ERROR\")\n",
    "            raise ValueError(\"Failed to locate the GDP table on the webpage.\")\n",
    "        log_message(\"Successfully located the GDP table in the HTML\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error parsing HTML or finding table: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "    # Step 4: Convert the table to a DataFrame and save raw data\n",
    "    try:\n",
    "        raw_df = pd.read_html(str(table))[0]\n",
    "        raw_df.to_csv('raw_gdp_data.csv', index=False)\n",
    "        raw_df.to_json('raw_gdp_data.json', orient='records', force_ascii=False, indent=4)\n",
    "        log_message(\"Raw data saved successfully\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error converting table to DataFrame or saving raw data: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "    log_message(\"Data extraction process completed successfully\")\n",
    "    return raw_df\n",
    "\n",
    "\n",
    "def transform_gdp_data(df):\n",
    "    \"\"\"\n",
    "    Transform the extracted GDP data for further analysis.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Raw GDP data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Transformed GDP data.\n",
    "    \"\"\"\n",
    "    log_message(\"Starting data transformation process\")\n",
    "    try:\n",
    "        # Step 1: Clean and process the data\n",
    "        df = df.iloc[:, [0, 1, 2]]\n",
    "        df.columns = ['Country', 'GDP (Nominal)', 'Year']\n",
    "        df = df.dropna(subset=['Country', 'GDP (Nominal)'])\n",
    "        df['GDP (B USD)'] = (\n",
    "            df['GDP (Nominal)']\n",
    "            .str.replace(r'[^\\d.]', '', regex=True)  # Remove non-numeric characters\n",
    "            .astype(float) / 1e3\n",
    "        )\n",
    "        df['Year'] = df['Year'].str.replace(r'\\[.*?\\]', '', regex=True)\n",
    "        df = df[['Country', 'GDP (B USD)', 'Year']]\n",
    "        df.sort_values(by='GDP (B USD)', ascending=False, inplace=True)\n",
    "        log_message(\"Data cleaned and transformed successfully\")\n",
    "\n",
    "        # Step 2: Merge with region data\n",
    "        with open('country_region_table.json', 'r', encoding='utf-8') as region_file:\n",
    "            region_data = json.load(region_file)\n",
    "        region_df = pd.DataFrame(list(region_data.items()), columns=['Country', 'Region'])\n",
    "        df = pd.merge(df, region_df, on='Country', how='left')\n",
    "\n",
    "        # Step 3: Save transformed data\n",
    "        df.to_csv('transformed_gdp_data.csv', index=False)\n",
    "        df.to_json('transformed_gdp_data.json', orient='records', force_ascii=False, indent=4)\n",
    "        log_message(\"Transformed data saved successfully\")\n",
    "\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error in data transformation: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_gdp_data(df):\n",
    "    \"\"\"\n",
    "    Load transformed GDP data into an SQLite database.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Transformed GDP data.\n",
    "    \"\"\"\n",
    "    log_message(\"Loading data into SQLite database\")\n",
    "    try:\n",
    "        conn = sqlite3.connect('World_Economies.db')\n",
    "        df.to_sql('Countries_by_GDP', conn, if_exists='replace', index=False)\n",
    "        conn.close()\n",
    "        log_message(\"Data successfully loaded into SQLite database\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error while loading data into SQLite database: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def display_countries_with_gdp_over_100():\n",
    "    \"\"\"\n",
    "    Display countries with GDP over 100 billion USD.\n",
    "\n",
    "    Prints a table of countries with GDP greater than or equal to 100B USD from the database.\n",
    "    \"\"\"\n",
    "    log_message(\"Displaying countries with GDP over 100B USD\")\n",
    "    try:\n",
    "        conn = sqlite3.connect('World_Economies.db')\n",
    "        query = \"\"\"\n",
    "        SELECT Country, GDP_USD_billion\n",
    "        FROM Countries_by_GDP\n",
    "        WHERE GDP_USD_billion >= 100\n",
    "        \"\"\"\n",
    "        result = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "        print(\"Countries with GDP >= 100B USD:\")\n",
    "        print(tabulate(result, headers='keys', tablefmt='psql', showindex=False))\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error querying database for countries with GDP >= 100B: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def display_region_top5_average_gdp():\n",
    "    \"\"\"\n",
    "    Calculate and display the average GDP of the top 5 countries by region.\n",
    "\n",
    "    Prints the average GDP of the top 5 countries for each region from the database.\n",
    "    \"\"\"\n",
    "    log_message(\"Calculating average GDP of top 5 countries by region\")\n",
    "    try:\n",
    "        conn = sqlite3.connect('World_Economies.db')\n",
    "        query = \"\"\"\n",
    "        WITH RankedCountries AS (\n",
    "            SELECT Country, GDP_USD_billion, Region,\n",
    "                   RANK() OVER (PARTITION BY Region ORDER BY GDP_USD_billion DESC) AS Rank\n",
    "            FROM Countries_by_GDP\n",
    "            WHERE Region IS NOT NULL\n",
    "        )\n",
    "        SELECT Region, AVG(GDP_USD_billion) AS Avg_Top5_GDP\n",
    "        FROM RankedCountries\n",
    "        WHERE Rank <= 5\n",
    "        GROUP BY Region\n",
    "        \"\"\"\n",
    "        result = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "        print(\"Average GDP of top 5 countries by region (excluding None):\")\n",
    "        print(tabulate(result, headers='keys', tablefmt='psql', showindex=False))\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error querying database for top 5 average GDP: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def etl_process():\n",
    "    \"\"\"\n",
    "    Execute the ETL process for GDP data.\n",
    "\n",
    "    Steps:\n",
    "        1. Extract raw data from a webpage.\n",
    "        2. Transform the data into a cleaned(required) format.\n",
    "        3. Load the data into an SQLite database.\n",
    "        4. Display additional analytical results.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        log_started()\n",
    "        log_message(\"ETL Process Started\")\n",
    "\n",
    "        # Extract\n",
    "        raw_data = extract_gdp_data()\n",
    "\n",
    "        # Transform\n",
    "        transformed_data = transform_gdp_data(raw_data)\n",
    "\n",
    "        # Load\n",
    "        load_gdp_data(transformed_data)\n",
    "\n",
    "        # Display analysis\n",
    "        display_countries_with_gdp_over_100()\n",
    "        display_region_top5_average_gdp()\n",
    "\n",
    "        log_message(\"ETL Process Completed Successfully\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"ETL Process Failed: {str(e)}\", level=\"ERROR\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    etl_process()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
