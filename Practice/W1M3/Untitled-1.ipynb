{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average GDP of top 5 countries by region (excluding None):\n",
      "+---------------+-------------------+\n",
      "|    Region     |   Avg_Top5_GDP    |\n",
      "+---------------+-------------------+\n",
      "|    Africa     |      256.134      |\n",
      "|     Asia      | 6255.969999999999 |\n",
      "|    Europe     |     3318.112      |\n",
      "| North America |      6946.5       |\n",
      "|    Oceania    | 734.8399999999999 |\n",
      "| South America |      797.566      |\n",
      "+---------------+-------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rd/d9knhb6x6nj7rd817gqlcsr00000gn/T/ipykernel_17505/3329315340.py:63: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]  # 위키피디아에서 제공하는 표를 Pandas로 읽고 객체를 문자열로 변환\n"
     ]
    }
   ],
   "source": [
    "import configparser\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sqlite3\n",
    "import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from tabulate import tabulate\n",
    "\n",
    "# 로그 기록 시작 함수\n",
    "def log_started():\n",
    "    with open('etl_project_log.txt', 'a') as log_file:\n",
    "        log_file.write(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "        timestamp = datetime.datetime.now().strftime('%Y-%B-%d-%H-%M-%S')\n",
    "        log_file.write(f\"New execution at {timestamp}\")\n",
    "        log_file.write(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# 로그 기록 함수\n",
    "def log_message(message, level=\"INFO\"):\n",
    "    timestamp = datetime.datetime.now().strftime('%Y-%B-%d-%H-%M-%S')\n",
    "    with open('etl_project_log.txt', 'a') as log_file:\n",
    "        log_file.write(f\"{timestamp} - {level} - {message}\\n\")\n",
    "\n",
    "# 설정 파일 읽기\n",
    "def load_config(config_path='config.ini'):\n",
    "    if not os.path.exists(config_path):\n",
    "        log_message(f\"Configuration file '{config_path}' not found.\", level=\"ERROR\")\n",
    "        raise FileNotFoundError((f\"Configuration file '{config_path}' not found.\"))\n",
    "    \n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(config_path)\n",
    "    \n",
    "    if 'DEFAULT' not in config or 'URL' not in config['DEFAULT'] or 'TABLE_CLASS' not in config['DEFAULT']:\n",
    "        log_message(\"Invalid or missing configuration values in 'config.ini'.\", level=\"ERROR\")\n",
    "        raise ValueError(\"Invalid or missing configuration values in 'config.ini'.\")\n",
    "    \n",
    "    return config['DEFAULT']['URL'], config['DEFAULT']['TABLE_CLASS']\n",
    "    \n",
    "\n",
    "# Save\n",
    "def save_gdp_data(df, output_csv_file='extracted_gdp_data.csv', output_json_file='extracted_gdp_data.json'):\n",
    "    log_message(\"Saving Extracted Data\")\n",
    "    try:\n",
    "        df.to_csv(output_csv_file, index=False)\n",
    "        df.to_json(output_json_file, orient='records', force_ascii=False, indent=4)\n",
    "        log_message(f\"Data saved: CSV ({output_csv_file}), JSON ({output_json_file})\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"Failed to save data: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "    \n",
    "def extract_gdp_data(url, table_class):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status() # HTTP 응답 상태 코드를 확인. 200번대가 아닌 경우(예: 404, 500 등) HTTPError 예외를 발생시킴\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        table = soup.find('table', {'class': table_class})\n",
    "        \n",
    "        if table is None:\n",
    "            log_message(\"No table found with the specified class.\", level=\"ERROR\")\n",
    "            raise ValueError(\"Failed to locate the GDP table on the webpage.\")\n",
    "            \n",
    "        df = pd.read_html(str(table))[0]  # 위키피디아에서 제공하는 표를 Pandas로 읽고 객체를 문자열로 변환\n",
    "        \n",
    "        df = df.iloc[:, [0, 1, 2]]  # 필요한 칼럼만 선택 (모든 행과 0, 1, 2번째 열을 선택)\n",
    "        df.columns = ['Country', 'GDP (Nominal)', 'Year']\n",
    "        \n",
    "        df = df.dropna(subset=['Country', 'GDP (Nominal)']) # NaN 데이터 제거 \n",
    "        df['GDP (B USD)'] = ( # GDP 값 정리 및 변환\n",
    "            df['GDP (Nominal)']\n",
    "            .str.replace(r'[^\\d.]', '', regex=True)  # 숫자와 소수점 이외 제거\n",
    "            .replace('', '0')  # 빈 문자열을 '0'으로 대체\n",
    "            .astype(float)  # float으로 변환\n",
    "            / 1e3  # 단위를 B USD로 변환\n",
    "        )\n",
    "        df['Year'] = df['Year'].str.replace(r'\\[.*?\\]', '', regex=True) # 각주 제거 (sup 이런 게 자꾸 따라와서..)\n",
    "        df = df[['Country', 'GDP (B USD)', 'Year']]\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        log_message(f\"Error during data extraction: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# Transform\n",
    "def transform_gdp_data(df):\n",
    "    log_message(\"Starting Data Transmission\")\n",
    "    try:\n",
    "        df = df.sort_values(by='GDP (B USD)', ascending=False)  # 정렬\n",
    "        df['GDP (B USD)'] = df['GDP (B USD)'].round(2)  # 소수점 2자리로 반올림\n",
    "        \n",
    "        with open('country_region_table.json', 'r', encoding='utf-8') as region_file:\n",
    "            region_data = json.load(region_file)\n",
    "        df['Region'] = df['Country'].map(region_data)\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        log_message(f\"Error during data transformation: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "\n",
    "\n",
    "def load_gdp_data(df):\n",
    "    log_message(\"Loading data into SQLite database\")\n",
    "    try:\n",
    "        # SQLite 데이터베이스에 연결\n",
    "        conn = sqlite3.connect('World_Economies.db')\n",
    "        \n",
    "        df[['Country', 'GDP (B USD)', 'Year', 'Region']].rename(\n",
    "            columns={'GDP (B USD)': 'GDP_USD_billion'}\n",
    "        ).to_sql( # 데이터프레임 데이터를 SQL 테이블로 변환하여 데이터베이스에 저장하는 pandas 메서드입\n",
    "            'Countries_by_GDP', conn, if_exists='replace', index=False\n",
    "        )\n",
    "        \n",
    "        conn.close()\n",
    "        log_message(\"Data successfully loaded into SQLite database\")\n",
    "        \n",
    "        \n",
    "    except Exception as e:\n",
    "        log_message(f\"Error while loading data into SQLite database: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "\n",
    "\n",
    "# GDP가 100B USD 이상인 국가 필터링\n",
    "def filtered_100USD(df):\n",
    "    filtered_100 = df[df['GDP (B USD)'] >= 100]\n",
    "    print(\"Countries with a GDP of over 100B USD\")\n",
    "    print(filtered_100)\n",
    "    return filtered_100\n",
    "\n",
    "\n",
    "# Region별 상위 5개 국가의 GDP 평균 계산\n",
    "def region_top5_calculate(df):\n",
    "    region_top5_avg = (\n",
    "        df.groupby('Region')\n",
    "        .apply(lambda x: x.nlargest(5, 'GDP (B USD)')['GDP (B USD)'].mean())\n",
    "        .reset_index(name='Top 5 Avg GDP (B USD)')\n",
    "    )\n",
    "    print(\"Average GDP of top 5 countries by region\")\n",
    "    print(region_top5_avg)\n",
    "    return region_top5_avg\n",
    "\n",
    "\n",
    "# 추가 요구사항 구현\n",
    "def display_countries_with_gdp_over_100():\n",
    "    log_message(\"Displaying countries with GDP over 100B USD\")\n",
    "    try:\n",
    "        conn = sqlite3.connect('World_Economies.db')\n",
    "        query = \"SELECT Country, GDP_USD_billion FROM Countries_by_GDP WHERE GDP_USD_billion >= 100\"\n",
    "        result = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "        \n",
    "        print(\"Countries with GDP >= 100B USD:\")\n",
    "        print(tabulate(result, headers='keys', tablefmt='fancy', showindex=False))\n",
    "        \n",
    "    except Exception as e:\n",
    "        log_message(f\"Error querying database for countries with GDP >= 100B: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "    \n",
    "# Region별 상위 5개 국가의 GDP 평균 계산 및 출력\n",
    "def display_region_top5_average_gdp():\n",
    "    log_message(\"Calculating average GDP of top 5 countries by region\")\n",
    "    try:\n",
    "        conn = sqlite3.connect('World_Economies.db')\n",
    "        query = \"\"\"\n",
    "        WITH RankedCountries AS (\n",
    "            SELECT Country, GDP_USD_billion, Region,\n",
    "                   RANK() OVER (PARTITION BY Region ORDER BY GDP_USD_billion DESC) AS Rank\n",
    "            FROM Countries_by_GDP\n",
    "            WHERE Region IS NOT NULL\n",
    "        )\n",
    "        SELECT Region, AVG(GDP_USD_billion) AS Avg_Top5_GDP\n",
    "        FROM RankedCountries\n",
    "        WHERE Rank <= 5\n",
    "        GROUP BY Region\n",
    "        \"\"\"\n",
    "        result = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "        \n",
    "        print(\"Average GDP of top 5 countries by region (excluding None):\")\n",
    "        print(tabulate(result, headers='keys', tablefmt='pretty', showindex=False))\n",
    "        \n",
    "    except Exception as e:\n",
    "        log_message(f\"Error querying database for top 5 average GDP: {str(e)}\", level=\"ERROR\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def etl_process():\n",
    "    try:\n",
    "        log_started()\n",
    "        log_message(\"ETL Process Started\")\n",
    "        \n",
    "        # 설정 로드\n",
    "        url, table_class = load_config()\n",
    "        \n",
    "        # Extract\n",
    "        extracted_data = extract_gdp_data(url, table_class)\n",
    "        \n",
    "        # Save Extracted Data\n",
    "        save_gdp_data(extracted_data)\n",
    "        \n",
    "        # Transform\n",
    "        transformed_data = transform_gdp_data(extracted_data)\n",
    "        \n",
    "        # Save Transformed Data\n",
    "        save_gdp_data(transformed_data, 'transformed_gdp_data.csv', 'transformed_gdp_data.json')\n",
    "        \n",
    "        # Load into SQLite Database\n",
    "        load_gdp_data(transformed_data)\n",
    "\n",
    "\n",
    "        # Additional Analyses\n",
    "        # display_countries_with_gdp_over_100()\n",
    "        display_region_top5_average_gdp()\n",
    "\n",
    "\n",
    "        # # 추가요구사항 전 출력과정\n",
    "        # filtered_data = filtered_100USD(transformed_data)\n",
    "        # region_top5_data = region_top5_calculate(transformed_data)\n",
    "        \n",
    "        log_message(\"ETL Process Completed Successfully\")        \n",
    "    except Exception as e:\n",
    "        log_message(f\"ETL Process is Failed: {str(e)}\", level=\"ERROR\")\n",
    "        \n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    etl_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2020  2021  2022  2023\n",
      "0  2500  2700  3000  3500\n",
      "1  1500  1800  2400  3000\n",
      "2  3000  3600  4200  5600\n",
      "--------------------------------------------------\n",
      "      1     2     3     4\n",
      "0  2500  2700  3000  3500\n",
      "1  1500  1800  2400  3000\n",
      "2  3000  3600  4200  5600\n",
      "--------------------------------------------------\n",
      "      1     2     3     4\n",
      "2  3000  3600  4200  5600\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame( {\n",
    "    '2020': [2500, 1500, 3000],\n",
    "    '2021': [2700, 1800, 3600],\n",
    "    '2022': [3000, 2400, 4200],\n",
    "    '2023': [3500, 3000, 5600] \n",
    "    })\n",
    "print(df)\n",
    "print('-' * 50)\n",
    "\n",
    "df.columns = ['1', '2', '3', '4']\n",
    "print(df)\n",
    "print('-' * 50)\n",
    "\n",
    "filtered = df[df['1'] >= 3000]\n",
    "print(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
