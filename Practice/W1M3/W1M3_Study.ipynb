{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parser / Python's html.parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEVERÂ -Â êµ­ë¯¼ì˜Â ì•„ë“¤\n",
      "SIGNALÂ -Â TWICE\n",
      "LONELYÂ -Â ì”¨ìŠ¤íƒ€\n",
      "IÂ LUVÂ ITÂ -Â PSY\n",
      "NewÂ FaceÂ -Â PSY\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "html = ''' \n",
    "<ol>\n",
    "    <li>NEVERÂ -Â êµ­ë¯¼ì˜Â ì•„ë“¤</li>\n",
    "    <li>SIGNALÂ -Â TWICE</li>\n",
    "    <li>LONELYÂ -Â ì”¨ìŠ¤íƒ€</li>\n",
    "    <li>IÂ LUVÂ ITÂ -Â PSY</li>\n",
    "    <li>NewÂ FaceÂ -Â PSY</li>\n",
    "</ol>\n",
    "'''\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "for tag in soup.select('li'):\n",
    "    print(tag.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parser / lxml's HTML parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEVERÂ -Â êµ­ë¯¼ì˜Â ì•„ë“¤\n",
      "SIGNALÂ -Â TWICE\n",
      "LONELYÂ -Â ì”¨ìŠ¤íƒ€\n",
      "IÂ LUVÂ ITÂ -Â PSY\n",
      "NewÂ FaceÂ -Â PSY\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "html = ''' \n",
    "<ol>\n",
    "    <li>NEVERÂ -Â êµ­ë¯¼ì˜Â ì•„ë“¤</li>\n",
    "    <li>SIGNALÂ -Â TWICE</li>\n",
    "    <li>LONELYÂ -Â ì”¨ìŠ¤íƒ€</li>\n",
    "    <li>IÂ LUVÂ ITÂ -Â PSY</li>\n",
    "    <li>NewÂ FaceÂ -Â PSY</li>\n",
    "</ol>\n",
    "'''\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "for tag in soup.select('li'):\n",
    "    print(tag.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë§Œë“¤ì–´ì•¼ í•˜ëŠ” ê²ƒ \n",
    "1. ~~êµ­ê°€ë³„ GDP í™•ì¸ ê°€ëŠ¥í•œ í…Œì´ë¸” (GDPê°€ ë†’ì€ êµ­ê°€ë“¤ ìˆœì„œë¡œ/ ë‹¨ìœ„ëŠ” 1B USDë¡œ ì†Œìˆ˜ì  2ìë¦¬/ ê°±ì‹ í•´ë„ ì¬ì‚¬ìš© ê°€ëŠ¥í•˜ê²Œ)~~\n",
    "2. ~~ë¡œê·¸ ê¸°ë¡ì‹œ datetime Year-Monthname-Day-Hour-Minute-Second (ê° ë‹¨ê³„ì˜ ì‹œì‘ê³¼ ëì„ ë¡œê·¸ì— ê¸°ë¡(ê¸°ì¡± íŒŒì¼ì— append))~~\n",
    "3. ~~ì¶”ì¶œ (Extract)í•œ ì •ë³´ëŠ” 'Countries_by_GDP.json'ë¼ëŠ” ì´ë¦„ì˜ JSON í™”ì¼ í¬ë§·ìœ¼ë¡œ ì €ì¥~~\n",
    "\n",
    "\n",
    "ì§€ì¼œì•¼ í•˜ëŠ” ê²ƒ\n",
    "1. ì£¼ì„ ì‚¬ìš©\n",
    "2. í•¨ìˆ˜ ë§Œë“¤ì–´ ì¬ì‚¬ìš©ì„±\n",
    "\n",
    "í™”ë©´ ì¶œë ¥\n",
    "1. ~~GDPê°€ 100B USDì´ìƒì´ ë˜ëŠ” êµ­ê°€ë§Œì„ êµ¬í•´ì„œ í™”ë©´ì— ì¶œë ¥~~\n",
    "2. ~~ê° Regionë³„ë¡œ top5 êµ­ê°€ì˜ GDP í‰ê· ì„ êµ¬í•´ì„œ í™”ë©´ì— ì¶œë ¥~~\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì¤€í˜¸ë‹˜ ì½”ë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from tabulate import tabulate\n",
    "from datetime import datetime\n",
    "\n",
    "# ë¡œê·¸ ê¸°ë¡ í•¨ìˆ˜\n",
    "def log_message(message):\n",
    "    with open('etl_project_log.txt', 'a') as f:\n",
    "        current_time = datetime.now().strftime('%Y-%B-%d-%H-%M-%S')\n",
    "        f.write(f\"{current_time}, {message}\\n\")\n",
    "\n",
    "# ì‹¤í–‰ êµ¬ë¶„ì„  ì¶”ê°€ í•¨ìˆ˜\n",
    "def log_separator():\n",
    "    with open('etl_project_log.txt', 'a') as f:\n",
    "        f.write(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "        current_time = datetime.now().strftime('%Y-%B-%d-%H-%M-%S')\n",
    "        f.write(f\"ğŸš€ New Execution at {current_time}\\n\")\n",
    "        f.write(\"=\"*50 + \"\\n\\n\")\n",
    "\n",
    "# URL ì„¤ì •\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)'\n",
    "\n",
    "# ì›¹ í˜ì´ì§€ ìš”ì²­ ë° íŒŒì‹±\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# gdp í…Œì´ë¸” ì¶”ì¶œ\n",
    "def extract_gdp_table(soup):\n",
    "    log_message(\"extract_gdp_table ì‹œì‘\")\n",
    "    # í…Œì´ë¸” ì¶”ì¶œ (ì§€ì •ëœ class ì‚¬ìš©)  \n",
    "    table = soup.find('table', {'class': 'wikitable'})\n",
    "\n",
    "    # ë°ì´í„° ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”\n",
    "    data = []\n",
    "\n",
    "    # í…Œì´ë¸”ì—ì„œ ëª¨ë“  <tr> íƒœê·¸ ì¶”ì¶œ\n",
    "    rows = table.find_all('tr')\n",
    "\n",
    "    # ê° <tr>ì—ì„œ <td>ë¥¼ ì¶”ì¶œí•´ ë°ì´í„° ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "    for row in rows:\n",
    "        cols = row.find_all('td')\n",
    "        if len(cols) >= 3:  # ì ì–´ë„ 3ê°œì˜ <td>ê°€ ìˆëŠ” ê²½ìš°ë§Œ ì²˜ë¦¬\n",
    "            country = cols[0].get_text(strip=True)\n",
    "            forecast = cols[1].get_text(strip=True)\n",
    "            year = cols[2].get_text(strip=True)\n",
    "\n",
    "            # [n 1]ê³¼ ê°™ì€ íƒœê·¸ ì œê±° (ì •ê·œí‘œí˜„ì‹ ì‚¬ìš©)\n",
    "            year = re.sub(r'\\[.*?\\]', '', year)\n",
    "\n",
    "            data.append([country, forecast, year])\n",
    "\n",
    "    # ë°ì´í„°í”„ë ˆì„ ìƒì„±\n",
    "    df = pd.DataFrame(data, columns=['Country', 'GDP_USD_billion', 'Year'])\n",
    "    log_message(\"extract_gdp_table ì™„ë£Œ\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def transform_gdp_data(df):\n",
    "    log_message(\"transform_gdp_data ì‹œì‘\")\n",
    "    # 0ë²ˆ ì¸ë±ìŠ¤ (World) ì œê±°\n",
    "    df = df[df['Country'] != 'World']\n",
    "\n",
    "    # Forecastê°€ ìˆ«ìê°€ ì•„ë‹Œ ê²½ìš°(ì˜ˆ: 'â€”') ì œê±° (GDP 100B ì´ìƒ êµ­ê°€ ì¤‘ ì¿ ë°”ê°€ ì œì™¸ë˜ëŠ” ì´ìŠˆê°€ ìˆìŒ)\n",
    "    df = df[df['GDP_USD_billion'] != 'â€”']\n",
    "\n",
    "    # ì‰¼í‘œ ì œê±° í›„ ìˆ«ìë¡œ ë³€í™˜\n",
    "    df['GDP_USD_billion'] = df['GDP_USD_billion'].str.replace(',', '').astype(int)\n",
    "\n",
    "    # Forecast ê°’ì„ 100ìœ¼ë¡œ ë‚˜ëˆ„ì–´ 1B USDë¡œ ë³€í™˜ (ì†Œìˆ˜ì  ë‘˜ì§¸ ìë¦¬ê¹Œì§€)\n",
    "    df['GDP_USD_billion'] = (df['GDP_USD_billion'] / 1000).round(2)\n",
    "\n",
    "    # country_region_table.json íŒŒì¼ë¡œë¶€í„° ë°ì´í„° ë¡œë“œ\n",
    "    with open('country_region_table.json', 'r') as f:\n",
    "        region_mapping = json.load(f)\n",
    "\n",
    "    # Region ë§¤í•‘ ì¶”ê°€\n",
    "    df['Region'] = df['Country'].map(region_mapping)\n",
    "\n",
    "    log_message(\"transform_gdp_data ì™„ë£Œ\")\n",
    "    return df\n",
    "\n",
    "def load_gdp_data(df):\n",
    "    log_message(\"load_gdp_data ì‹œì‘\")\n",
    "    # Countries_by_GDP.json íŒŒì¼ë¡œ ì €ì¥\n",
    "    df.to_json('Countries_by_GDP.json', orient='records', indent=4)\n",
    "    log_message(\"load_gdp_data ì™„ë£Œ\")\n",
    "\n",
    "def print_gdp_over_100b(df):\n",
    "    log_message(\"print_gdp_over_100b ì‹œì‘\")\n",
    "    # GDP 100B USD ì´ìƒ êµ­ê°€ë§Œ í•„í„°ë§\n",
    "    gdp_over_100b = df[df['GDP_USD_billion'] >= 100]\n",
    "\n",
    "    # ì¸ë±ìŠ¤ ë¦¬ì…‹ (1ë¶€í„° ì‹œì‘)\n",
    "    gdp_over_100b.index = range(1, len(gdp_over_100b) + 1)\n",
    "\n",
    "    # GDP 100B ì´ìƒ êµ­ê°€ ì¶œë ¥\n",
    "    print(\"ğŸŒ GDP 100B USD ì´ìƒ êµ­ê°€ ëª©ë¡:\")\n",
    "    print(tabulate(gdp_over_100b, headers='keys', tablefmt='grid'))\n",
    "    log_message(\"print_gdp_over_100b ì™„ë£Œ\")\n",
    "\n",
    "def print_region_avg_gdp(df):\n",
    "    log_message(\"print_region_avg_gdp ì‹œì‘\")\n",
    "    # Regionë³„ë¡œ ê·¸ë£¹í™” ë° ìƒìœ„ 5ê°œ êµ­ê°€ ì¶”ì¶œ\n",
    "    top_5_per_region = (\n",
    "        df.groupby('Region')\n",
    "        .apply(lambda x: x.nlargest(5, 'GDP_USD_billion'))  # ìƒìœ„ 5ê°œ ì¶”ì¶œ\n",
    "        .reset_index(drop=True)  # ì¸ë±ìŠ¤ ë¦¬ì…‹\n",
    "    )\n",
    "    # Regionë³„ ìƒìœ„ 5ê°œ êµ­ê°€ì˜ GDP í‰ê·  ê³„ì‚°\n",
    "    region_avg_gdp = (\n",
    "        top_5_per_region.groupby('Region')['GDP_USD_billion']\n",
    "        .mean()\n",
    "        .round(2)\n",
    "        .reset_index()\n",
    "        .rename(columns={'GDP_USD_billion': 'Top 5 Avg GDP'})\n",
    "    )\n",
    "    # ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬\n",
    "    region_avg_gdp = region_avg_gdp.sort_values('Top 5 Avg GDP', ascending=False)\n",
    "\n",
    "    # ì¸ë±ìŠ¤ ë¦¬ì…‹ (1ë¶€í„° ì‹œì‘)\n",
    "    region_avg_gdp.index = range(1, len(region_avg_gdp) + 1)\n",
    "\n",
    "    # Regionë³„ ìƒìœ„ 5ê°œ êµ­ê°€ í‰ê·  GDP ì¶œë ¥\n",
    "    print(\"\\nğŸ“Š Regionë³„ ìƒìœ„ 5ê°œ êµ­ê°€ì˜ GDP í‰ê· :\")\n",
    "    print(tabulate(region_avg_gdp, headers='keys', tablefmt='grid'))\n",
    "    log_message(\"print_region_avg_gdp ì™„ë£Œ\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    log_separator()  # ì‹¤í–‰ êµ¬ë¶„ì„  ì¶”ê°€\n",
    "\n",
    "    # gdp í…Œì´ë¸” ì¶”ì¶œ\n",
    "    raw_df = extract_gdp_table(soup)\n",
    "\n",
    "    # ë°ì´í„° ë³€í™˜\n",
    "    transformed_df = transform_gdp_data(raw_df)\n",
    "\n",
    "    # ë°ì´í„° json í˜•íƒœë¡œ ì €ì¥\n",
    "    load_gdp_data(transformed_df)\n",
    "\n",
    "    # 100B ì´ìƒ êµ­ê°€ ì¶œë ¥\n",
    "    print_gdp_over_100b(transformed_df)\n",
    "\n",
    "    # Regionë³„ ìƒìœ„ 5ê°œ êµ­ê°€ì˜ GDP í‰ê·  ì¶œë ¥\n",
    "    print_region_avg_gdp(transformed_df)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¯¼ì¬ë‹˜ ì½”ë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\n",
    "TARGET_URL = 'https://en.wikipedia.org/wiki/List_of_countries_by_GDP_%28nominal%29'\n",
    "LOG_FILE_PATH = 'etl_project_log.txt'\n",
    "OUTPUT_FILE_PATH = 'Countries_by_GDP.json'\n",
    "COUNTRY_REGION_TABLE_PATH = 'country_region_table.json'\n",
    "\n",
    "class Logger:\n",
    "    '''\n",
    "    Logger class\n",
    "    '''\n",
    "    def __init__(self, log_file_path: str):\n",
    "        self.log_file_path = log_file_path\n",
    "\n",
    "    def info(self, message: str):\n",
    "        self.__log('INFO', message)\n",
    "\n",
    "    def error(self, message: str):\n",
    "        self.__log('ERROR', message)\n",
    "\n",
    "    def __log(self, type: str, message: str):\n",
    "        with open(self.log_file_path, 'a') as log_file:\n",
    "            timestamp = datetime.datetime.now()\n",
    "            log_data = f'{timestamp.strftime(\"%Y-%b-%d-%H-%M-%S\")}, {type}: {message}'\n",
    "            log_file.write(log_data+'\\n')\n",
    "            print(log_data)\n",
    "\n",
    "logger = Logger(LOG_FILE_PATH)\n",
    "\n",
    "def get_html(url: str) -> str:\n",
    "    '''\n",
    "    Fetch HTML from the given URL\n",
    "    '''\n",
    "    try: \n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        return response.text\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return None\n",
    "    \n",
    "def parse_html_to_table(html:str, target: str) -> list:\n",
    "    '''\n",
    "    Select HTML table by class name and parse to list\n",
    "    '''\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    table = soup.find('table', class_=target)\n",
    "    data = []\n",
    "    try:\n",
    "        if not table:\n",
    "            return data\n",
    "        rows = table.find_all('tr')\n",
    "        for row in rows[3:]:\n",
    "            columns = row.find_all('td')\n",
    "            country = columns[0].text.strip()\n",
    "            gdp = columns[1].text.strip()\n",
    "            if (not gdp or gdp == 'â€”'):\n",
    "                continue\n",
    "            data.append({'Country': country, 'GDP': gdp})\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        logger.error(f'ERROR: Error parsing HTML: {e}')\n",
    "        return []\n",
    "\n",
    "def parse_json(file_path):\n",
    "    '''\n",
    "    Read JSON file\n",
    "    '''\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def parse_to_df(target):\n",
    "    '''\n",
    "    Convert list to dataframe\n",
    "    '''\n",
    "    df = pd.DataFrame(target)\n",
    "    return df\n",
    "\n",
    "def transfrom_df(df):\n",
    "    '''\n",
    "    Transformation function\n",
    "    '''\n",
    "    # Million -> Billion\n",
    "    df['GDP'] = df['GDP'].apply(lambda x: x.replace(',', ''))\n",
    "    df['GDP'] = df['GDP'].apply(lambda x: round(float(x) / 1000, 2))\n",
    "    \n",
    "    # Sort by GDP\n",
    "    df = df.sort_values(by='GDP', ascending=False)\n",
    "    \n",
    "    # Add region\n",
    "    country_region_table = parse_json(COUNTRY_REGION_TABLE_PATH)\n",
    "    df['Region'] = df['Country'].map(country_region_table)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def save_to_json(df, file_path):\n",
    "    '''\n",
    "    Save dataframe to JSON file\n",
    "    '''\n",
    "    df.to_json(file_path, orient='records', indent=2)\n",
    "    \n",
    "def main():\n",
    "    logger.info('-'*50)\n",
    "    logger.info('Starting the ETL process')\n",
    "    logger.info(f'Fetching HTML from {TARGET_URL}...')\n",
    "    html = get_html(TARGET_URL)\n",
    "    if not html:\n",
    "        logger.error(f'Failed to fetch HTML from {TARGET_URL}')\n",
    "        return\n",
    "    logger.info('Parsing HTML to table...')\n",
    "    data = parse_html_to_table(html, 'wikitable')\n",
    "    if not data:\n",
    "        logger.error('Table Parsing Failed')\n",
    "        return\n",
    "    logger.info('Transforming data to dataframe...')\n",
    "    df = parse_to_df(data)\n",
    "    df = transfrom_df(df)\n",
    "    \n",
    "    logger.info(f'Saving data to {OUTPUT_FILE_PATH}...')\n",
    "    save_to_json(df, OUTPUT_FILE_PATH)\n",
    "    \n",
    "    logger.info('ETL process completed successfully')\n",
    "    \n",
    "    # print output\n",
    "    print(f'Countries with GDP > 100B: \\n{df[df[\"GDP\"] > 100]}')\n",
    "    df_groupby_top5 = df.groupby('Region').head(5)\n",
    "    avg_gdp = df_groupby_top5.groupby('Region')['GDP'].mean()\n",
    "    print('Top 5 Average GDP by Region:')\n",
    "    print(avg_gdp)\n",
    "    \n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë‚´ ì½”ë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countries with a GDP of over 100B USD\n",
      "          Country  GDP (B USD)  Year         Region\n",
      "0           World    115494.31  2025            NaN\n",
      "1   United States     30337.16  2025  North America\n",
      "2           China     19534.89  2025           Asia\n",
      "3         Germany      4921.56  2025         Europe\n",
      "4           Japan      4389.33  2025           Asia\n",
      "..            ...          ...   ...            ...\n",
      "68     Uzbekistan       112.65  2024           Asia\n",
      "69      Guatemala       112.37  2024  North America\n",
      "70           Oman       109.99  2024           Asia\n",
      "71       Bulgaria       108.42  2024         Europe\n",
      "72      Venezuela       106.33  2024  South America\n",
      "\n",
      "[73 rows x 4 columns]\n",
      "Average GDP of top 5 countries by region\n",
      "          Region  Top 5 Avg GDP (B USD)\n",
      "0         Africa                238.182\n",
      "1           Asia               6255.970\n",
      "2         Europe               3318.112\n",
      "3  North America               6946.500\n",
      "4        Oceania                734.840\n",
      "5  South America                791.566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rd/d9knhb6x6nj7rd817gqlcsr00000gn/T/ipykernel_5638/3158481998.py:109: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df.groupby('Region')\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "# ë¡œê·¸ ê¸°ë¡ í•¨ìˆ˜\n",
    "def log_message(message):\n",
    "    timestamp = datetime.datetime.now().strftime('%Y-%b-%d-%H-%M-%S')\n",
    "    with open('etl_project_log.txt', 'a') as log_file:\n",
    "        log_file.write(f\"{timestamp}, {message}\\n\")\n",
    "\n",
    "# Extract\n",
    "def extract_gdp_data(url):\n",
    "    log_message(\"Starting Data Extraction\")\n",
    "    # HTTP ìš”ì²­ í›„ íŒŒì‹±í•´ì„œ ë°ì´í„° ì¶”ì¶œ\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    table = soup.find('table', {'class': 'wikitable'})\n",
    "    rows = table.find_all('tr')\n",
    "\n",
    "    data = []\n",
    "    for row in rows[1:]:  # ì²« ë²ˆì§¸ í–‰ì€ í—¤ë”ì´ë¯€ë¡œ ì œì™¸í•¨\n",
    "        cols = row.find_all('td')\n",
    "        cleaned_cols = []\n",
    "        for col in cols:\n",
    "            # 'sup' íƒœê·¸ ì œê±° [n 1] ì´ëŸ°ì‹ìœ¼ë¡œ ìê¾¸ ë– ì„œ\n",
    "            for sup in col.find_all('sup'):\n",
    "                sup.decompose()\n",
    "            cleaned_cols.append(col.text.strip())  # í…ìŠ¤íŠ¸ ì •ë¦¬\n",
    "        if cleaned_cols:  # ë¹ˆ í–‰ ì œì™¸\n",
    "            try:\n",
    "                country = cleaned_cols[0]  # êµ­ê°€ëª…\n",
    "                gdp_raw = cleaned_cols[1]  # GDP ê°’ (Nominal GDP)\n",
    "                gdp_year = cleaned_cols[2]\n",
    "                gdp_cleaned = ''.join(filter(str.isdigit, gdp_raw.split('.')[0]))\n",
    "                if gdp_cleaned:  # GDP ê°’ì´ ìœ íš¨í•œ ê²½ìš°ë§Œ ì¶”ê°€\n",
    "                    gdp = int(gdp_cleaned) / 1e3  # ë‹¨ìœ„ë¥¼ 1B USDë¡œ ë³€í™˜\n",
    "                    data.append({'Country': country, 'GDP (B USD)': round(gdp, 2), 'Year': gdp_year})\n",
    "            except IndexError:\n",
    "                # ì˜ˆìƒì¹˜ ëª»í•œ ë°ì´í„° êµ¬ì¡°ë¥¼ ë¬´ì‹œ\n",
    "                continue\n",
    "    log_message(\"Data Extraction Completed\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Transform\n",
    "def transform_gdp_data(data):\n",
    "    log_message(\"Starting Data Transformation\")\n",
    "    # ë°ì´í„°í”„ë ˆì„ ìƒì„±\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # GDP ìˆœìœ¼ë¡œ ì •ë ¬\n",
    "    df = df.sort_values(by='GDP (B USD)', ascending=False)\n",
    "    \n",
    "    # êµ­ê°€ë³„ Region ì •ë³´ ë§¤í•‘\n",
    "    with open('country_region_table.json', 'r', encoding='utf-8') as region_file:\n",
    "        region_data = json.load(region_file)\n",
    "    df['Region'] = df['Country'].map(region_data)\n",
    "    \n",
    "    log_message(\"Data Transformation Completed\")\n",
    "    return df\n",
    "\n",
    "# Load\n",
    "def load_gdp_data(df, output_csv_file='gdp_by_country.csv', output_json_file='Countries_by_GDP.json'):\n",
    "    log_message(\"Starting Data Loading\")\n",
    "    try:\n",
    "        # CSV íŒŒì¼ë¡œ ì €ì¥\n",
    "        df.to_csv(output_csv_file, index=False)\n",
    "        log_message(f\"CSV file saved as {output_csv_file}\")\n",
    "        \n",
    "        # JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "        data_as_dict = df.to_dict(orient='records')  # DataFrameì„ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
    "        with open(output_json_file, 'w', encoding='utf-8') as json_file:\n",
    "            json.dump(data_as_dict, json_file, ensure_ascii=False, indent=4)\n",
    "        log_message(f\"JSON file saved as {output_json_file}\")\n",
    "        \n",
    "        log_message(\"Data Loading Completed Successfully\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        log_message(f\"Data Loading Failed: {str(e)}\")\n",
    "        raise  # ì˜ˆì™¸ë¥¼ ë‹¤ì‹œ ë˜ì ¸ ETL í”„ë¡œì„¸ìŠ¤ì—ì„œ ì²˜ë¦¬ ê°€ëŠ¥\n",
    "\n",
    "\n",
    "# GDPê°€ 100B USD ì´ìƒì¸ êµ­ê°€ë§Œ í•„í„°ë§\n",
    "def filtered_100USD(df):\n",
    "    filtered_100 = df[df['GDP (B USD)'] >= 100]\n",
    "    print(\"Countries with a GDP of over 100B USD\")\n",
    "    print(filtered_100)\n",
    "    \n",
    "    \n",
    " # Regionë³„ ìƒìœ„ 5ê°œ êµ­ê°€ì˜ GDP í‰ê·  ê³„ì‚°\n",
    "def region_top5_calculate(df):\n",
    "    region_top5_avg = (\n",
    "        df.groupby('Region')\n",
    "        .apply(lambda x: x.nlargest(5, 'GDP (B USD)')['GDP (B USD)'].mean())\n",
    "        .reset_index(name='Top 5 Avg GDP (B USD)')\n",
    "    )\n",
    "    print(\"Average GDP of top 5 countries by region\")\n",
    "    print(region_top5_avg)\n",
    "    \n",
    "\n",
    "# ë©”ì¸ ETL í•¨ìˆ˜\n",
    "def etl_process():\n",
    "    url = \"https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)\"\n",
    "    try:\n",
    "        log_message(\"ETL Process Started\")\n",
    "        # Extract\n",
    "        data = extract_gdp_data(url)\n",
    "        # Transform\n",
    "        transformed_data = transform_gdp_data(data)\n",
    "        # Load\n",
    "        load_gdp_data(transformed_data)  \n",
    "        log_message(\"ETL Process End Successfully\")\n",
    "        \n",
    "        # GDPê°€ 100B USD ì´ìƒì¸ êµ­ê°€ë§Œ í•„í„°ë§\n",
    "        filtered_100USD(transformed_data)\n",
    "        # Regionë³„ ìƒìœ„ 5ê°œ êµ­ê°€ì˜ GDP í‰ê·  ê³„ì‚°\n",
    "        region_top5_calculate(transformed_data)\n",
    "        \n",
    "    except Exception as e:\n",
    "        log_message(f\"ETL Process Failed: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    etl_process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loadì— ìˆë˜ ì €ì¥ í”„ë¡œì„¸ìŠ¤ë¥¼ Transformìœ¼ë¡œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countries with a GDP of over 100B USD\n",
      "          Country  GDP (B USD)  Year         Region\n",
      "0           World    115494.31  2025            NaN\n",
      "1   United States     30337.16  2025  North America\n",
      "2           China     19534.89  2025           Asia\n",
      "3         Germany      4921.56  2025         Europe\n",
      "4           Japan      4389.33  2025           Asia\n",
      "..            ...          ...   ...            ...\n",
      "68     Uzbekistan       112.65  2024           Asia\n",
      "69      Guatemala       112.37  2024  North America\n",
      "70           Oman       109.99  2024           Asia\n",
      "71       Bulgaria       108.42  2024         Europe\n",
      "72      Venezuela       106.33  2024  South America\n",
      "\n",
      "[73 rows x 4 columns]\n",
      "Average GDP of top 5 countries by region\n",
      "          Region  Top 5 Avg GDP (B USD)\n",
      "0         Africa                238.182\n",
      "1           Asia               6255.970\n",
      "2         Europe               3318.112\n",
      "3  North America               6946.500\n",
      "4        Oceania                734.840\n",
      "5  South America                791.566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rd/d9knhb6x6nj7rd817gqlcsr00000gn/T/ipykernel_5638/547960222.py:94: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df.groupby('Region')\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "# ë¡œê·¸ ê¸°ë¡ í•¨ìˆ˜\n",
    "def log_message(message):\n",
    "    timestamp = datetime.datetime.now().strftime('%Y-%b-%d-%H-%M-%S')\n",
    "    with open('etl_project_log.txt', 'a') as log_file:\n",
    "        log_file.write(f\"{timestamp}, {message}\\n\")\n",
    "\n",
    "# Extract\n",
    "def extract_gdp_data(url):\n",
    "    log_message(\"Starting Data Extraction\")\n",
    "    # HTTP ìš”ì²­ í›„ íŒŒì‹±í•´ì„œ ë°ì´í„° ì¶”ì¶œ\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    table = soup.find('table', {'class': 'wikitable'})\n",
    "    rows = table.find_all('tr')\n",
    "\n",
    "    data = []\n",
    "    for row in rows[1:]:  # ì²« ë²ˆì§¸ í–‰ì€ í—¤ë”ì´ë¯€ë¡œ ì œì™¸í•¨\n",
    "        cols = row.find_all('td')\n",
    "        cleaned_cols = []\n",
    "        for col in cols:\n",
    "            # 'sup' íƒœê·¸ ì œê±° [n 1] ì´ëŸ°ì‹ìœ¼ë¡œ ìê¾¸ ë– ì„œ\n",
    "            for sup in col.find_all('sup'):\n",
    "                sup.decompose()\n",
    "            cleaned_cols.append(col.text.strip())  # í…ìŠ¤íŠ¸ ì •ë¦¬\n",
    "        if cleaned_cols:  # ë¹ˆ í–‰ ì œì™¸\n",
    "            try:\n",
    "                country = cleaned_cols[0]  # êµ­ê°€ëª…\n",
    "                gdp_raw = cleaned_cols[1]  # GDP ê°’ (Nominal GDP)\n",
    "                gdp_year = cleaned_cols[2]\n",
    "                gdp_cleaned = ''.join(filter(str.isdigit, gdp_raw.split('.')[0]))\n",
    "                if gdp_cleaned:  # GDP ê°’ì´ ìœ íš¨í•œ ê²½ìš°ë§Œ ì¶”ê°€\n",
    "                    gdp = int(gdp_cleaned) / 1e3  # ë‹¨ìœ„ë¥¼ 1B USDë¡œ ë³€í™˜\n",
    "                    data.append({'Country': country, 'GDP (B USD)': round(gdp, 2), 'Year': gdp_year})\n",
    "            except IndexError:\n",
    "                # ì˜ˆìƒì¹˜ ëª»í•œ ë°ì´í„° êµ¬ì¡°ë¥¼ ë¬´ì‹œ\n",
    "                continue\n",
    "    log_message(\"Data Extraction Completed\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "# Transform\n",
    "def transform_gdp_data(data, output_csv_file='gdp_by_country.csv', output_json_file='Countries_by_GDP.json'):\n",
    "    log_message(\"Starting Data Transformation\")\n",
    "    # ë°ì´í„°í”„ë ˆì„ ìƒì„±\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # GDP ìˆœìœ¼ë¡œ ì •ë ¬\n",
    "    df = df.sort_values(by='GDP (B USD)', ascending=False)\n",
    "    \n",
    "    # êµ­ê°€ë³„ Region ì •ë³´ ë§¤í•‘\n",
    "    with open('country_region_table.json', 'r', encoding='utf-8') as region_file:\n",
    "        region_data = json.load(region_file)\n",
    "    df['Region'] = df['Country'].map(region_data)\n",
    "\n",
    "    # ë°ì´í„° ì €ì¥ (CSV ë° JSON íŒŒì¼)\n",
    "    try:\n",
    "        df.to_csv(output_csv_file, index=False)\n",
    "        log_message(f\"CSV file saved as {output_csv_file}\")\n",
    "        \n",
    "        data_as_dict = df.to_dict(orient='records')  # DataFrameì„ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
    "        with open(output_json_file, 'w', encoding='utf-8') as json_file:\n",
    "            json.dump(data_as_dict, json_file, ensure_ascii=False, indent=4)\n",
    "        log_message(f\"JSON file saved as {output_json_file}\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"Data Transformation Failed during saving: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "    log_message(\"Data Transformation Completed\")\n",
    "    return df\n",
    "\n",
    "# Load\n",
    "def load_gdp_data(df):\n",
    "    log_message(\"Data Loading step is now minimal, performing any additional post-processing if required.\")\n",
    "    # í˜„ì¬ëŠ” ë°ì´í„° ë¡œë“œ ê´€ë ¨ ì¶”ê°€ ì‘ì—…ì´ ì—†ë‹¤ë©´ ë¹ˆ í•¨ìˆ˜ë¡œ ìœ ì§€ ê°€ëŠ¥\n",
    "    pass\n",
    "\n",
    "# GDPê°€ 100B USD ì´ìƒì¸ êµ­ê°€ë§Œ í•„í„°ë§\n",
    "def filtered_100USD(df):\n",
    "    filtered_100 = df[df['GDP (B USD)'] >= 100]\n",
    "    print(\"Countries with a GDP of over 100B USD\")\n",
    "    print(filtered_100)\n",
    "    \n",
    "    \n",
    " # Regionë³„ ìƒìœ„ 5ê°œ êµ­ê°€ì˜ GDP í‰ê·  ê³„ì‚°\n",
    "def region_top5_calculate(df):\n",
    "    region_top5_avg = (\n",
    "        df.groupby('Region')\n",
    "        .apply(lambda x: x.nlargest(5, 'GDP (B USD)')['GDP (B USD)'].mean())\n",
    "        .reset_index(name='Top 5 Avg GDP (B USD)')\n",
    "    )\n",
    "    print(\"Average GDP of top 5 countries by region\")\n",
    "    print(region_top5_avg)\n",
    "\n",
    "# ë©”ì¸ ETL í•¨ìˆ˜\n",
    "def etl_process():\n",
    "    url = \"https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)\"\n",
    "    try:\n",
    "        log_message(\"ETL Process Started\")\n",
    "        # Extract\n",
    "        data = extract_gdp_data(url)\n",
    "        # Transform (includes saving)\n",
    "        transformed_data = transform_gdp_data(data)\n",
    "        # Load\n",
    "        load_gdp_data(transformed_data)  \n",
    "        log_message(\"ETL Process End Successfully\")\n",
    "        \n",
    "        # GDPê°€ 100B USD ì´ìƒì¸ êµ­ê°€ë§Œ í•„í„°ë§\n",
    "        filtered_100USD(transformed_data)\n",
    "        # Regionë³„ ìƒìœ„ 5ê°œ êµ­ê°€ì˜ GDP í‰ê·  ê³„ì‚°\n",
    "        region_top5_calculate(transformed_data)\n",
    "        \n",
    "    except Exception as e:\n",
    "        log_message(f\"ETL Process Failed: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    etl_process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì¶”ê°€ ìš”êµ¬ ì‚¬í•­\n",
    "\n",
    "\n",
    "#### ì½”ë“œë¥¼ ìˆ˜ì •í•´ì„œ ì•„ë˜ ìš”êµ¬ì‚¬í•­ì„ êµ¬í˜„í•˜ì„¸ìš”.\n",
    "- ì¶”ì¶œí•œ ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ì„¸ìš”. 'Countries_by_GDP'ë¼ëŠ” í…Œì´ë¸”ëª…ìœ¼ë¡œ 'World_Economies.db'ë¼ëŠ” ë°ì´í„° ë² ì´ìŠ¤ì— ì €ì¥ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. \n",
    "    - í•´ë‹¹ í…Œì´ë¸”ì€ 'Country', 'GDP_USD_billion'ë¼ëŠ” ì–´íŠ¸ë¦¬ë·°íŠ¸ë¥¼ ë°˜ë“œì‹œ ê°€ì ¸ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "ë°ì´í„°ë² ì´ìŠ¤ëŠ” sqlite3 ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•´ì„œ ë§Œë“œì„¸ìš”.\n",
    "- í•„ìš”í•œ ëª¨ë“  ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” 'etl_project_gdp_with_sql.py' ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n",
    "\n",
    "#### í™”ë©´ ì¶œë ¥\n",
    "- SQL Queryë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "    - GDPê°€ 100B USDì´ìƒì´ ë˜ëŠ” êµ­ê°€ë§Œì„ êµ¬í•´ì„œ í™”ë©´ì— ì¶œë ¥í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "    - ê° Regionë³„ë¡œ top5 êµ­ê°€ì˜ GDP í‰ê· ì„ êµ¬í•´ì„œ í™”ë©´ì— ì¶œë ¥í•´ì•¼ í•©ë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countries with a GDP of over 100B USD:\n",
      "          Country  GDP_USD_billion\n",
      "0           World        115494.31\n",
      "1   United States         30337.16\n",
      "2           China         19534.89\n",
      "3         Germany          4921.56\n",
      "4           Japan          4389.33\n",
      "..            ...              ...\n",
      "68     Uzbekistan           112.65\n",
      "69      Guatemala           112.37\n",
      "70           Oman           109.99\n",
      "71       Bulgaria           108.42\n",
      "72      Venezuela           106.33\n",
      "\n",
      "[73 rows x 2 columns]\n",
      "Average GDP of top 5 countries by region:\n",
      "          Region  Top 5 Avg GDP (B USD)\n",
      "0         Africa                238.182\n",
      "1           Asia               6255.970\n",
      "2         Europe               3318.112\n",
      "3  North America               6946.500\n",
      "4        Oceania                734.840\n",
      "5  South America                791.566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rd/d9knhb6x6nj7rd817gqlcsr00000gn/T/ipykernel_5638/3186562559.py:112: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df.groupby('Region')\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import json\n",
    "import sqlite3\n",
    "\n",
    "# ë¡œê·¸ ê¸°ë¡ í•¨ìˆ˜\n",
    "def log_message(message):\n",
    "    timestamp = datetime.datetime.now().strftime('%Y-%b-%d-%H-%M-%S')\n",
    "    with open('etl_project_log.txt', 'a') as log_file:\n",
    "        log_file.write(f\"{timestamp}, {message}\\n\")\n",
    "\n",
    "# Extract\n",
    "def extract_gdp_data(url):\n",
    "    log_message(\"Starting Data Extraction\")\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    table = soup.find('table', {'class': 'wikitable'})\n",
    "    rows = table.find_all('tr')\n",
    "\n",
    "    data = []\n",
    "    for row in rows[1:]:\n",
    "        cols = row.find_all('td')\n",
    "        cleaned_cols = []\n",
    "        for col in cols:\n",
    "            for sup in col.find_all('sup'):\n",
    "                sup.decompose()\n",
    "            cleaned_cols.append(col.text.strip())\n",
    "        if cleaned_cols:\n",
    "            try:\n",
    "                country = cleaned_cols[0]\n",
    "                gdp_raw = cleaned_cols[1]\n",
    "                gdp_year = cleaned_cols[2]\n",
    "                gdp_cleaned = ''.join(filter(str.isdigit, gdp_raw.split('.')[0]))\n",
    "                if gdp_cleaned:\n",
    "                    gdp = int(gdp_cleaned) / 1e3  # ë‹¨ìœ„ë¥¼ 1B USDë¡œ ë³€í™˜\n",
    "                    data.append({'Country': country, 'GDP (B USD)': round(gdp, 2), 'Year': gdp_year})\n",
    "            except IndexError:\n",
    "                continue\n",
    "    log_message(\"Data Extraction Completed\")\n",
    "    return data\n",
    "\n",
    "# Transform\n",
    "def transform_gdp_data(data, output_csv_file='gdp_by_country.csv', output_json_file='Countries_by_GDP.json'):\n",
    "    log_message(\"Starting Data Transformation\")\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.sort_values(by='GDP (B USD)', ascending=False)\n",
    "    with open('country_region_table.json', 'r', encoding='utf-8') as region_file:\n",
    "        region_data = json.load(region_file)\n",
    "    df['Region'] = df['Country'].map(region_data)\n",
    "\n",
    "    # ë°ì´í„° ì €ì¥ (CSV ë° JSON íŒŒì¼)\n",
    "    try:\n",
    "        df.to_csv(output_csv_file, index=False)\n",
    "        log_message(f\"CSV file saved as {output_csv_file}\")\n",
    "        \n",
    "        data_as_dict = df.to_dict(orient='records')\n",
    "        with open(output_json_file, 'w', encoding='utf-8') as json_file:\n",
    "            json.dump(data_as_dict, json_file, ensure_ascii=False, indent=4)\n",
    "        log_message(f\"JSON file saved as {output_json_file}\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"Data Transformation Failed during saving: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "    log_message(\"Data Transformation Completed\")\n",
    "    return df\n",
    "\n",
    "# Load to Database\n",
    "def load_gdp_to_database(df, db_name='World_Economies.db', table_name='Countries_by_GDP'):\n",
    "    log_message(\"Starting Data Loading to Database\")\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_name)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # í…Œì´ë¸” ìƒì„±\n",
    "        cursor.execute(f\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "                Country TEXT PRIMARY KEY,\n",
    "                GDP_USD_billion REAL\n",
    "            )\n",
    "        \"\"\")\n",
    "        \n",
    "        # ë°ì´í„° ì‚½ì…\n",
    "        for _, row in df.iterrows():\n",
    "            cursor.execute(f\"\"\"\n",
    "                INSERT OR REPLACE INTO {table_name} (Country, GDP_USD_billion)\n",
    "                VALUES (?, ?)\n",
    "            \"\"\", (row['Country'], row['GDP (B USD)']))\n",
    "        \n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "        log_message(\"Data Loading to Database Completed Successfully\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"Data Loading to Database Failed: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# SQL Query: GDPê°€ 100B USD ì´ìƒì¸ êµ­ê°€ ì¶œë ¥\n",
    "def query_gdp_over_100(db_name='World_Economies.db', table_name='Countries_by_GDP'):\n",
    "    log_message(\"Querying GDP over 100B USD\")\n",
    "    conn = sqlite3.connect(db_name)\n",
    "    query = f\"SELECT * FROM {table_name} WHERE GDP_USD_billion >= 100\"\n",
    "    result = pd.read_sql_query(query, conn)\n",
    "    conn.close()\n",
    "    print(\"Countries with a GDP of over 100B USD:\")\n",
    "    print(result)\n",
    "\n",
    "# SQL Query: Regionë³„ Top 5 êµ­ê°€ì˜ GDP í‰ê· \n",
    "def query_region_top5_avg(df):\n",
    "    log_message(\"Calculating Region-wise Top 5 Average GDP\")\n",
    "    region_top5_avg = (\n",
    "        df.groupby('Region')\n",
    "        .apply(lambda x: x.nlargest(5, 'GDP (B USD)')['GDP (B USD)'].mean())\n",
    "        .reset_index(name='Top 5 Avg GDP (B USD)')\n",
    "    )\n",
    "    print(\"Average GDP of top 5 countries by region:\")\n",
    "    print(region_top5_avg)\n",
    "\n",
    "# ë©”ì¸ ETL í•¨ìˆ˜\n",
    "def etl_process():\n",
    "    url = \"https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)\"\n",
    "    try:\n",
    "        log_message(\"ETL Process Started\")\n",
    "        # Extract\n",
    "        data = extract_gdp_data(url)\n",
    "        # Transform\n",
    "        transformed_data = transform_gdp_data(data)\n",
    "        # Load to Database\n",
    "        load_gdp_to_database(transformed_data)\n",
    "        log_message(\"ETL Process Completed Successfully\")\n",
    "\n",
    "        # SQL Query Outputs\n",
    "        query_gdp_over_100()\n",
    "        query_region_top5_avg(transformed_data)\n",
    "    except Exception as e:\n",
    "        log_message(f\"ETL Process Failed: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    etl_process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/Documents/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import sqlite3\n",
    "import datetime\n",
    "\n",
    "def log_started():\n",
    "    with open('etl_project_log.txt', 'a') as log_file:\n",
    "        log_file.write(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "        timestamp = datetime.datetime.now().strftime('%Y-%B-%d-%H-%M-%S')\n",
    "        log_file.write(f\"New execution at {timestamp}\\n\")\n",
    "        log_file.write(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "\n",
    "def log_message():\n",
    "    pass\n",
    "def save_gdp_data():\n",
    "    pass\n",
    "def extract_gdp_data():\n",
    "    pass\n",
    "def transform_gdp_data():\n",
    "    pass\n",
    "def load_gdp_data():\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "def etl_process():\n",
    "    try:\n",
    "        log_started()\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    etl_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
