{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parser / Python's html.parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEVER - 국민의 아들\n",
      "SIGNAL - TWICE\n",
      "LONELY - 씨스타\n",
      "I LUV IT - PSY\n",
      "New Face - PSY\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "html = ''' \n",
    "<ol>\n",
    "    <li>NEVER - 국민의 아들</li>\n",
    "    <li>SIGNAL - TWICE</li>\n",
    "    <li>LONELY - 씨스타</li>\n",
    "    <li>I LUV IT - PSY</li>\n",
    "    <li>New Face - PSY</li>\n",
    "</ol>\n",
    "'''\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "for tag in soup.select('li'):\n",
    "    print(tag.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parser / lxml's HTML parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEVER - 국민의 아들\n",
      "SIGNAL - TWICE\n",
      "LONELY - 씨스타\n",
      "I LUV IT - PSY\n",
      "New Face - PSY\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "html = ''' \n",
    "<ol>\n",
    "    <li>NEVER - 국민의 아들</li>\n",
    "    <li>SIGNAL - TWICE</li>\n",
    "    <li>LONELY - 씨스타</li>\n",
    "    <li>I LUV IT - PSY</li>\n",
    "    <li>New Face - PSY</li>\n",
    "</ol>\n",
    "'''\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "for tag in soup.select('li'):\n",
    "    print(tag.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만들어야 하는 것 \n",
    "1. ~~국가별 GDP 확인 가능한 테이블 (GDP가 높은 국가들 순서로/ 단위는 1B USD로 소수점 2자리/ 갱신해도 재사용 가능하게)~~\n",
    "2. ~~로그 기록시 datetime Year-Monthname-Day-Hour-Minute-Second (각 단계의 시작과 끝을 로그에 기록(기족 파일에 append))~~\n",
    "3. ~~추출 (Extract)한 정보는 'Countries_by_GDP.json'라는 이름의 JSON 화일 포맷으로 저장~~\n",
    "\n",
    "\n",
    "지켜야 하는 것\n",
    "1. 주석 사용\n",
    "2. 함수 만들어 재사용성\n",
    "\n",
    "화면 출력\n",
    "1. ~~GDP가 100B USD이상이 되는 국가만을 구해서 화면에 출력~~\n",
    "2. ~~각 Region별로 top5 국가의 GDP 평균을 구해서 화면에 출력~~\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 준호님 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from tabulate import tabulate\n",
    "from datetime import datetime\n",
    "\n",
    "# 로그 기록 함수\n",
    "def log_message(message):\n",
    "    with open('etl_project_log.txt', 'a') as f:\n",
    "        current_time = datetime.now().strftime('%Y-%B-%d-%H-%M-%S')\n",
    "        f.write(f\"{current_time}, {message}\\n\")\n",
    "\n",
    "# 실행 구분선 추가 함수\n",
    "def log_separator():\n",
    "    with open('etl_project_log.txt', 'a') as f:\n",
    "        f.write(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "        current_time = datetime.now().strftime('%Y-%B-%d-%H-%M-%S')\n",
    "        f.write(f\"🚀 New Execution at {current_time}\\n\")\n",
    "        f.write(\"=\"*50 + \"\\n\\n\")\n",
    "\n",
    "# URL 설정\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)'\n",
    "\n",
    "# 웹 페이지 요청 및 파싱\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# gdp 테이블 추출\n",
    "def extract_gdp_table(soup):\n",
    "    log_message(\"extract_gdp_table 시작\")\n",
    "    # 테이블 추출 (지정된 class 사용)  \n",
    "    table = soup.find('table', {'class': 'wikitable'})\n",
    "\n",
    "    # 데이터 저장용 리스트 초기화\n",
    "    data = []\n",
    "\n",
    "    # 테이블에서 모든 <tr> 태그 추출\n",
    "    rows = table.find_all('tr')\n",
    "\n",
    "    # 각 <tr>에서 <td>를 추출해 데이터 리스트에 추가\n",
    "    for row in rows:\n",
    "        cols = row.find_all('td')\n",
    "        if len(cols) >= 3:  # 적어도 3개의 <td>가 있는 경우만 처리\n",
    "            country = cols[0].get_text(strip=True)\n",
    "            forecast = cols[1].get_text(strip=True)\n",
    "            year = cols[2].get_text(strip=True)\n",
    "\n",
    "            # [n 1]과 같은 태그 제거 (정규표현식 사용)\n",
    "            year = re.sub(r'\\[.*?\\]', '', year)\n",
    "\n",
    "            data.append([country, forecast, year])\n",
    "\n",
    "    # 데이터프레임 생성\n",
    "    df = pd.DataFrame(data, columns=['Country', 'GDP_USD_billion', 'Year'])\n",
    "    log_message(\"extract_gdp_table 완료\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def transform_gdp_data(df):\n",
    "    log_message(\"transform_gdp_data 시작\")\n",
    "    # 0번 인덱스 (World) 제거\n",
    "    df = df[df['Country'] != 'World']\n",
    "\n",
    "    # Forecast가 숫자가 아닌 경우(예: '—') 제거 (GDP 100B 이상 국가 중 쿠바가 제외되는 이슈가 있음)\n",
    "    df = df[df['GDP_USD_billion'] != '—']\n",
    "\n",
    "    # 쉼표 제거 후 숫자로 변환\n",
    "    df['GDP_USD_billion'] = df['GDP_USD_billion'].str.replace(',', '').astype(int)\n",
    "\n",
    "    # Forecast 값을 100으로 나누어 1B USD로 변환 (소수점 둘째 자리까지)\n",
    "    df['GDP_USD_billion'] = (df['GDP_USD_billion'] / 1000).round(2)\n",
    "\n",
    "    # country_region_table.json 파일로부터 데이터 로드\n",
    "    with open('country_region_table.json', 'r') as f:\n",
    "        region_mapping = json.load(f)\n",
    "\n",
    "    # Region 매핑 추가\n",
    "    df['Region'] = df['Country'].map(region_mapping)\n",
    "\n",
    "    log_message(\"transform_gdp_data 완료\")\n",
    "    return df\n",
    "\n",
    "def load_gdp_data(df):\n",
    "    log_message(\"load_gdp_data 시작\")\n",
    "    # Countries_by_GDP.json 파일로 저장\n",
    "    df.to_json('Countries_by_GDP.json', orient='records', indent=4)\n",
    "    log_message(\"load_gdp_data 완료\")\n",
    "\n",
    "def print_gdp_over_100b(df):\n",
    "    log_message(\"print_gdp_over_100b 시작\")\n",
    "    # GDP 100B USD 이상 국가만 필터링\n",
    "    gdp_over_100b = df[df['GDP_USD_billion'] >= 100]\n",
    "\n",
    "    # 인덱스 리셋 (1부터 시작)\n",
    "    gdp_over_100b.index = range(1, len(gdp_over_100b) + 1)\n",
    "\n",
    "    # GDP 100B 이상 국가 출력\n",
    "    print(\"🌍 GDP 100B USD 이상 국가 목록:\")\n",
    "    print(tabulate(gdp_over_100b, headers='keys', tablefmt='grid'))\n",
    "    log_message(\"print_gdp_over_100b 완료\")\n",
    "\n",
    "def print_region_avg_gdp(df):\n",
    "    log_message(\"print_region_avg_gdp 시작\")\n",
    "    # Region별로 그룹화 및 상위 5개 국가 추출\n",
    "    top_5_per_region = (\n",
    "        df.groupby('Region')\n",
    "        .apply(lambda x: x.nlargest(5, 'GDP_USD_billion'))  # 상위 5개 추출\n",
    "        .reset_index(drop=True)  # 인덱스 리셋\n",
    "    )\n",
    "    # Region별 상위 5개 국가의 GDP 평균 계산\n",
    "    region_avg_gdp = (\n",
    "        top_5_per_region.groupby('Region')['GDP_USD_billion']\n",
    "        .mean()\n",
    "        .round(2)\n",
    "        .reset_index()\n",
    "        .rename(columns={'GDP_USD_billion': 'Top 5 Avg GDP'})\n",
    "    )\n",
    "    # 내림차순 정렬\n",
    "    region_avg_gdp = region_avg_gdp.sort_values('Top 5 Avg GDP', ascending=False)\n",
    "\n",
    "    # 인덱스 리셋 (1부터 시작)\n",
    "    region_avg_gdp.index = range(1, len(region_avg_gdp) + 1)\n",
    "\n",
    "    # Region별 상위 5개 국가 평균 GDP 출력\n",
    "    print(\"\\n📊 Region별 상위 5개 국가의 GDP 평균:\")\n",
    "    print(tabulate(region_avg_gdp, headers='keys', tablefmt='grid'))\n",
    "    log_message(\"print_region_avg_gdp 완료\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    log_separator()  # 실행 구분선 추가\n",
    "\n",
    "    # gdp 테이블 추출\n",
    "    raw_df = extract_gdp_table(soup)\n",
    "\n",
    "    # 데이터 변환\n",
    "    transformed_df = transform_gdp_data(raw_df)\n",
    "\n",
    "    # 데이터 json 형태로 저장\n",
    "    load_gdp_data(transformed_df)\n",
    "\n",
    "    # 100B 이상 국가 출력\n",
    "    print_gdp_over_100b(transformed_df)\n",
    "\n",
    "    # Region별 상위 5개 국가의 GDP 평균 출력\n",
    "    print_region_avg_gdp(transformed_df)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 민재님 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\n",
    "TARGET_URL = 'https://en.wikipedia.org/wiki/List_of_countries_by_GDP_%28nominal%29'\n",
    "LOG_FILE_PATH = 'etl_project_log.txt'\n",
    "OUTPUT_FILE_PATH = 'Countries_by_GDP.json'\n",
    "COUNTRY_REGION_TABLE_PATH = 'country_region_table.json'\n",
    "\n",
    "class Logger:\n",
    "    '''\n",
    "    Logger class\n",
    "    '''\n",
    "    def __init__(self, log_file_path: str):\n",
    "        self.log_file_path = log_file_path\n",
    "\n",
    "    def info(self, message: str):\n",
    "        self.__log('INFO', message)\n",
    "\n",
    "    def error(self, message: str):\n",
    "        self.__log('ERROR', message)\n",
    "\n",
    "    def __log(self, type: str, message: str):\n",
    "        with open(self.log_file_path, 'a') as log_file:\n",
    "            timestamp = datetime.datetime.now()\n",
    "            log_data = f'{timestamp.strftime(\"%Y-%b-%d-%H-%M-%S\")}, {type}: {message}'\n",
    "            log_file.write(log_data+'\\n')\n",
    "            print(log_data)\n",
    "\n",
    "logger = Logger(LOG_FILE_PATH)\n",
    "\n",
    "def get_html(url: str) -> str:\n",
    "    '''\n",
    "    Fetch HTML from the given URL\n",
    "    '''\n",
    "    try: \n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        return response.text\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return None\n",
    "    \n",
    "def parse_html_to_table(html:str, target: str) -> list:\n",
    "    '''\n",
    "    Select HTML table by class name and parse to list\n",
    "    '''\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    table = soup.find('table', class_=target)\n",
    "    data = []\n",
    "    try:\n",
    "        if not table:\n",
    "            return data\n",
    "        rows = table.find_all('tr')\n",
    "        for row in rows[3:]:\n",
    "            columns = row.find_all('td')\n",
    "            country = columns[0].text.strip()\n",
    "            gdp = columns[1].text.strip()\n",
    "            if (not gdp or gdp == '—'):\n",
    "                continue\n",
    "            data.append({'Country': country, 'GDP': gdp})\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        logger.error(f'ERROR: Error parsing HTML: {e}')\n",
    "        return []\n",
    "\n",
    "def parse_json(file_path):\n",
    "    '''\n",
    "    Read JSON file\n",
    "    '''\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def parse_to_df(target):\n",
    "    '''\n",
    "    Convert list to dataframe\n",
    "    '''\n",
    "    df = pd.DataFrame(target)\n",
    "    return df\n",
    "\n",
    "def transfrom_df(df):\n",
    "    '''\n",
    "    Transformation function\n",
    "    '''\n",
    "    # Million -> Billion\n",
    "    df['GDP'] = df['GDP'].apply(lambda x: x.replace(',', ''))\n",
    "    df['GDP'] = df['GDP'].apply(lambda x: round(float(x) / 1000, 2))\n",
    "    \n",
    "    # Sort by GDP\n",
    "    df = df.sort_values(by='GDP', ascending=False)\n",
    "    \n",
    "    # Add region\n",
    "    country_region_table = parse_json(COUNTRY_REGION_TABLE_PATH)\n",
    "    df['Region'] = df['Country'].map(country_region_table)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def save_to_json(df, file_path):\n",
    "    '''\n",
    "    Save dataframe to JSON file\n",
    "    '''\n",
    "    df.to_json(file_path, orient='records', indent=2)\n",
    "    \n",
    "def main():\n",
    "    logger.info('-'*50)\n",
    "    logger.info('Starting the ETL process')\n",
    "    logger.info(f'Fetching HTML from {TARGET_URL}...')\n",
    "    html = get_html(TARGET_URL)\n",
    "    if not html:\n",
    "        logger.error(f'Failed to fetch HTML from {TARGET_URL}')\n",
    "        return\n",
    "    logger.info('Parsing HTML to table...')\n",
    "    data = parse_html_to_table(html, 'wikitable')\n",
    "    if not data:\n",
    "        logger.error('Table Parsing Failed')\n",
    "        return\n",
    "    logger.info('Transforming data to dataframe...')\n",
    "    df = parse_to_df(data)\n",
    "    df = transfrom_df(df)\n",
    "    \n",
    "    logger.info(f'Saving data to {OUTPUT_FILE_PATH}...')\n",
    "    save_to_json(df, OUTPUT_FILE_PATH)\n",
    "    \n",
    "    logger.info('ETL process completed successfully')\n",
    "    \n",
    "    # print output\n",
    "    print(f'Countries with GDP > 100B: \\n{df[df[\"GDP\"] > 100]}')\n",
    "    df_groupby_top5 = df.groupby('Region').head(5)\n",
    "    avg_gdp = df_groupby_top5.groupby('Region')['GDP'].mean()\n",
    "    print('Top 5 Average GDP by Region:')\n",
    "    print(avg_gdp)\n",
    "    \n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 내 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countries with a GDP of over 100B USD\n",
      "          Country  GDP (B USD)  Year         Region\n",
      "0           World    115494.31  2025            NaN\n",
      "1   United States     30337.16  2025  North America\n",
      "2           China     19534.89  2025           Asia\n",
      "3         Germany      4921.56  2025         Europe\n",
      "4           Japan      4389.33  2025           Asia\n",
      "..            ...          ...   ...            ...\n",
      "68     Uzbekistan       112.65  2024           Asia\n",
      "69      Guatemala       112.37  2024  North America\n",
      "70           Oman       109.99  2024           Asia\n",
      "71       Bulgaria       108.42  2024         Europe\n",
      "72      Venezuela       106.33  2024  South America\n",
      "\n",
      "[73 rows x 4 columns]\n",
      "Average GDP of top 5 countries by region\n",
      "          Region  Top 5 Avg GDP (B USD)\n",
      "0         Africa                238.182\n",
      "1           Asia               6255.970\n",
      "2         Europe               3318.112\n",
      "3  North America               6946.500\n",
      "4        Oceania                734.840\n",
      "5  South America                791.566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rd/d9knhb6x6nj7rd817gqlcsr00000gn/T/ipykernel_5638/3158481998.py:109: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df.groupby('Region')\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "# 로그 기록 함수\n",
    "def log_message(message):\n",
    "    timestamp = datetime.datetime.now().strftime('%Y-%b-%d-%H-%M-%S')\n",
    "    with open('etl_project_log.txt', 'a') as log_file:\n",
    "        log_file.write(f\"{timestamp}, {message}\\n\")\n",
    "\n",
    "# Extract\n",
    "def extract_gdp_data(url):\n",
    "    log_message(\"Starting Data Extraction\")\n",
    "    # HTTP 요청 후 파싱해서 데이터 추출\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    table = soup.find('table', {'class': 'wikitable'})\n",
    "    rows = table.find_all('tr')\n",
    "\n",
    "    data = []\n",
    "    for row in rows[1:]:  # 첫 번째 행은 헤더이므로 제외함\n",
    "        cols = row.find_all('td')\n",
    "        cleaned_cols = []\n",
    "        for col in cols:\n",
    "            # 'sup' 태그 제거 [n 1] 이런식으로 자꾸 떠서\n",
    "            for sup in col.find_all('sup'):\n",
    "                sup.decompose()\n",
    "            cleaned_cols.append(col.text.strip())  # 텍스트 정리\n",
    "        if cleaned_cols:  # 빈 행 제외\n",
    "            try:\n",
    "                country = cleaned_cols[0]  # 국가명\n",
    "                gdp_raw = cleaned_cols[1]  # GDP 값 (Nominal GDP)\n",
    "                gdp_year = cleaned_cols[2]\n",
    "                gdp_cleaned = ''.join(filter(str.isdigit, gdp_raw.split('.')[0]))\n",
    "                if gdp_cleaned:  # GDP 값이 유효한 경우만 추가\n",
    "                    gdp = int(gdp_cleaned) / 1e3  # 단위를 1B USD로 변환\n",
    "                    data.append({'Country': country, 'GDP (B USD)': round(gdp, 2), 'Year': gdp_year})\n",
    "            except IndexError:\n",
    "                # 예상치 못한 데이터 구조를 무시\n",
    "                continue\n",
    "    log_message(\"Data Extraction Completed\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Transform\n",
    "def transform_gdp_data(data):\n",
    "    log_message(\"Starting Data Transformation\")\n",
    "    # 데이터프레임 생성\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # GDP 순으로 정렬\n",
    "    df = df.sort_values(by='GDP (B USD)', ascending=False)\n",
    "    \n",
    "    # 국가별 Region 정보 매핑\n",
    "    with open('country_region_table.json', 'r', encoding='utf-8') as region_file:\n",
    "        region_data = json.load(region_file)\n",
    "    df['Region'] = df['Country'].map(region_data)\n",
    "    \n",
    "    log_message(\"Data Transformation Completed\")\n",
    "    return df\n",
    "\n",
    "# Load\n",
    "def load_gdp_data(df, output_csv_file='gdp_by_country.csv', output_json_file='Countries_by_GDP.json'):\n",
    "    log_message(\"Starting Data Loading\")\n",
    "    try:\n",
    "        # CSV 파일로 저장\n",
    "        df.to_csv(output_csv_file, index=False)\n",
    "        log_message(f\"CSV file saved as {output_csv_file}\")\n",
    "        \n",
    "        # JSON 파일로 저장\n",
    "        data_as_dict = df.to_dict(orient='records')  # DataFrame을 딕셔너리 리스트로 변환\n",
    "        with open(output_json_file, 'w', encoding='utf-8') as json_file:\n",
    "            json.dump(data_as_dict, json_file, ensure_ascii=False, indent=4)\n",
    "        log_message(f\"JSON file saved as {output_json_file}\")\n",
    "        \n",
    "        log_message(\"Data Loading Completed Successfully\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        log_message(f\"Data Loading Failed: {str(e)}\")\n",
    "        raise  # 예외를 다시 던져 ETL 프로세스에서 처리 가능\n",
    "\n",
    "\n",
    "# GDP가 100B USD 이상인 국가만 필터링\n",
    "def filtered_100USD(df):\n",
    "    filtered_100 = df[df['GDP (B USD)'] >= 100]\n",
    "    print(\"Countries with a GDP of over 100B USD\")\n",
    "    print(filtered_100)\n",
    "    \n",
    "    \n",
    " # Region별 상위 5개 국가의 GDP 평균 계산\n",
    "def region_top5_calculate(df):\n",
    "    region_top5_avg = (\n",
    "        df.groupby('Region')\n",
    "        .apply(lambda x: x.nlargest(5, 'GDP (B USD)')['GDP (B USD)'].mean())\n",
    "        .reset_index(name='Top 5 Avg GDP (B USD)')\n",
    "    )\n",
    "    print(\"Average GDP of top 5 countries by region\")\n",
    "    print(region_top5_avg)\n",
    "    \n",
    "\n",
    "# 메인 ETL 함수\n",
    "def etl_process():\n",
    "    url = \"https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)\"\n",
    "    try:\n",
    "        log_message(\"ETL Process Started\")\n",
    "        # Extract\n",
    "        data = extract_gdp_data(url)\n",
    "        # Transform\n",
    "        transformed_data = transform_gdp_data(data)\n",
    "        # Load\n",
    "        load_gdp_data(transformed_data)  \n",
    "        log_message(\"ETL Process End Successfully\")\n",
    "        \n",
    "        # GDP가 100B USD 이상인 국가만 필터링\n",
    "        filtered_100USD(transformed_data)\n",
    "        # Region별 상위 5개 국가의 GDP 평균 계산\n",
    "        region_top5_calculate(transformed_data)\n",
    "        \n",
    "    except Exception as e:\n",
    "        log_message(f\"ETL Process Failed: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    etl_process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load에 있던 저장 프로세스를 Transform으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countries with a GDP of over 100B USD\n",
      "          Country  GDP (B USD)  Year         Region\n",
      "0           World    115494.31  2025            NaN\n",
      "1   United States     30337.16  2025  North America\n",
      "2           China     19534.89  2025           Asia\n",
      "3         Germany      4921.56  2025         Europe\n",
      "4           Japan      4389.33  2025           Asia\n",
      "..            ...          ...   ...            ...\n",
      "68     Uzbekistan       112.65  2024           Asia\n",
      "69      Guatemala       112.37  2024  North America\n",
      "70           Oman       109.99  2024           Asia\n",
      "71       Bulgaria       108.42  2024         Europe\n",
      "72      Venezuela       106.33  2024  South America\n",
      "\n",
      "[73 rows x 4 columns]\n",
      "Average GDP of top 5 countries by region\n",
      "          Region  Top 5 Avg GDP (B USD)\n",
      "0         Africa                238.182\n",
      "1           Asia               6255.970\n",
      "2         Europe               3318.112\n",
      "3  North America               6946.500\n",
      "4        Oceania                734.840\n",
      "5  South America                791.566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rd/d9knhb6x6nj7rd817gqlcsr00000gn/T/ipykernel_5638/547960222.py:94: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df.groupby('Region')\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "# 로그 기록 함수\n",
    "def log_message(message):\n",
    "    timestamp = datetime.datetime.now().strftime('%Y-%b-%d-%H-%M-%S')\n",
    "    with open('etl_project_log.txt', 'a') as log_file:\n",
    "        log_file.write(f\"{timestamp}, {message}\\n\")\n",
    "\n",
    "# Extract\n",
    "def extract_gdp_data(url):\n",
    "    log_message(\"Starting Data Extraction\")\n",
    "    # HTTP 요청 후 파싱해서 데이터 추출\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    table = soup.find('table', {'class': 'wikitable'})\n",
    "    rows = table.find_all('tr')\n",
    "\n",
    "    data = []\n",
    "    for row in rows[1:]:  # 첫 번째 행은 헤더이므로 제외함\n",
    "        cols = row.find_all('td')\n",
    "        cleaned_cols = []\n",
    "        for col in cols:\n",
    "            # 'sup' 태그 제거 [n 1] 이런식으로 자꾸 떠서\n",
    "            for sup in col.find_all('sup'):\n",
    "                sup.decompose()\n",
    "            cleaned_cols.append(col.text.strip())  # 텍스트 정리\n",
    "        if cleaned_cols:  # 빈 행 제외\n",
    "            try:\n",
    "                country = cleaned_cols[0]  # 국가명\n",
    "                gdp_raw = cleaned_cols[1]  # GDP 값 (Nominal GDP)\n",
    "                gdp_year = cleaned_cols[2]\n",
    "                gdp_cleaned = ''.join(filter(str.isdigit, gdp_raw.split('.')[0]))\n",
    "                if gdp_cleaned:  # GDP 값이 유효한 경우만 추가\n",
    "                    gdp = int(gdp_cleaned) / 1e3  # 단위를 1B USD로 변환\n",
    "                    data.append({'Country': country, 'GDP (B USD)': round(gdp, 2), 'Year': gdp_year})\n",
    "            except IndexError:\n",
    "                # 예상치 못한 데이터 구조를 무시\n",
    "                continue\n",
    "    log_message(\"Data Extraction Completed\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "# Transform\n",
    "def transform_gdp_data(data, output_csv_file='gdp_by_country.csv', output_json_file='Countries_by_GDP.json'):\n",
    "    log_message(\"Starting Data Transformation\")\n",
    "    # 데이터프레임 생성\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # GDP 순으로 정렬\n",
    "    df = df.sort_values(by='GDP (B USD)', ascending=False)\n",
    "    \n",
    "    # 국가별 Region 정보 매핑\n",
    "    with open('country_region_table.json', 'r', encoding='utf-8') as region_file:\n",
    "        region_data = json.load(region_file)\n",
    "    df['Region'] = df['Country'].map(region_data)\n",
    "\n",
    "    # 데이터 저장 (CSV 및 JSON 파일)\n",
    "    try:\n",
    "        df.to_csv(output_csv_file, index=False)\n",
    "        log_message(f\"CSV file saved as {output_csv_file}\")\n",
    "        \n",
    "        data_as_dict = df.to_dict(orient='records')  # DataFrame을 딕셔너리 리스트로 변환\n",
    "        with open(output_json_file, 'w', encoding='utf-8') as json_file:\n",
    "            json.dump(data_as_dict, json_file, ensure_ascii=False, indent=4)\n",
    "        log_message(f\"JSON file saved as {output_json_file}\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"Data Transformation Failed during saving: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "    log_message(\"Data Transformation Completed\")\n",
    "    return df\n",
    "\n",
    "# Load\n",
    "def load_gdp_data(df):\n",
    "    log_message(\"Data Loading step is now minimal, performing any additional post-processing if required.\")\n",
    "    # 현재는 데이터 로드 관련 추가 작업이 없다면 빈 함수로 유지 가능\n",
    "    pass\n",
    "\n",
    "# GDP가 100B USD 이상인 국가만 필터링\n",
    "def filtered_100USD(df):\n",
    "    filtered_100 = df[df['GDP (B USD)'] >= 100]\n",
    "    print(\"Countries with a GDP of over 100B USD\")\n",
    "    print(filtered_100)\n",
    "    \n",
    "    \n",
    " # Region별 상위 5개 국가의 GDP 평균 계산\n",
    "def region_top5_calculate(df):\n",
    "    region_top5_avg = (\n",
    "        df.groupby('Region')\n",
    "        .apply(lambda x: x.nlargest(5, 'GDP (B USD)')['GDP (B USD)'].mean())\n",
    "        .reset_index(name='Top 5 Avg GDP (B USD)')\n",
    "    )\n",
    "    print(\"Average GDP of top 5 countries by region\")\n",
    "    print(region_top5_avg)\n",
    "\n",
    "# 메인 ETL 함수\n",
    "def etl_process():\n",
    "    url = \"https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)\"\n",
    "    try:\n",
    "        log_message(\"ETL Process Started\")\n",
    "        # Extract\n",
    "        data = extract_gdp_data(url)\n",
    "        # Transform (includes saving)\n",
    "        transformed_data = transform_gdp_data(data)\n",
    "        # Load\n",
    "        load_gdp_data(transformed_data)  \n",
    "        log_message(\"ETL Process End Successfully\")\n",
    "        \n",
    "        # GDP가 100B USD 이상인 국가만 필터링\n",
    "        filtered_100USD(transformed_data)\n",
    "        # Region별 상위 5개 국가의 GDP 평균 계산\n",
    "        region_top5_calculate(transformed_data)\n",
    "        \n",
    "    except Exception as e:\n",
    "        log_message(f\"ETL Process Failed: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    etl_process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추가 요구 사항\n",
    "\n",
    "\n",
    "#### 코드를 수정해서 아래 요구사항을 구현하세요.\n",
    "- 추출한 데이터를 데이터베이스에 저장하세요. 'Countries_by_GDP'라는 테이블명으로 'World_Economies.db'라는 데이터 베이스에 저장되어야 합니다. \n",
    "    - 해당 테이블은 'Country', 'GDP_USD_billion'라는 어트리뷰트를 반드시 가져야 합니다.\n",
    "\n",
    "데이터베이스는 sqlite3 라이브러리를 사용해서 만드세요.\n",
    "- 필요한 모든 작업을 수행하는 'etl_project_gdp_with_sql.py' 코드를 작성하세요.\n",
    "\n",
    "#### 화면 출력\n",
    "- SQL Query를 사용해야 합니다.\n",
    "    - GDP가 100B USD이상이 되는 국가만을 구해서 화면에 출력해야 합니다.\n",
    "    - 각 Region별로 top5 국가의 GDP 평균을 구해서 화면에 출력해야 합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countries with a GDP of over 100B USD:\n",
      "          Country  GDP_USD_billion\n",
      "0           World        115494.31\n",
      "1   United States         30337.16\n",
      "2           China         19534.89\n",
      "3         Germany          4921.56\n",
      "4           Japan          4389.33\n",
      "..            ...              ...\n",
      "68     Uzbekistan           112.65\n",
      "69      Guatemala           112.37\n",
      "70           Oman           109.99\n",
      "71       Bulgaria           108.42\n",
      "72      Venezuela           106.33\n",
      "\n",
      "[73 rows x 2 columns]\n",
      "Average GDP of top 5 countries by region:\n",
      "          Region  Top 5 Avg GDP (B USD)\n",
      "0         Africa                238.182\n",
      "1           Asia               6255.970\n",
      "2         Europe               3318.112\n",
      "3  North America               6946.500\n",
      "4        Oceania                734.840\n",
      "5  South America                791.566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rd/d9knhb6x6nj7rd817gqlcsr00000gn/T/ipykernel_5638/3186562559.py:112: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df.groupby('Region')\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import json\n",
    "import sqlite3\n",
    "\n",
    "# 로그 기록 함수\n",
    "def log_message(message):\n",
    "    timestamp = datetime.datetime.now().strftime('%Y-%b-%d-%H-%M-%S')\n",
    "    with open('etl_project_log.txt', 'a') as log_file:\n",
    "        log_file.write(f\"{timestamp}, {message}\\n\")\n",
    "\n",
    "# Extract\n",
    "def extract_gdp_data(url):\n",
    "    log_message(\"Starting Data Extraction\")\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    table = soup.find('table', {'class': 'wikitable'})\n",
    "    rows = table.find_all('tr')\n",
    "\n",
    "    data = []\n",
    "    for row in rows[1:]:\n",
    "        cols = row.find_all('td')\n",
    "        cleaned_cols = []\n",
    "        for col in cols:\n",
    "            for sup in col.find_all('sup'):\n",
    "                sup.decompose()\n",
    "            cleaned_cols.append(col.text.strip())\n",
    "        if cleaned_cols:\n",
    "            try:\n",
    "                country = cleaned_cols[0]\n",
    "                gdp_raw = cleaned_cols[1]\n",
    "                gdp_year = cleaned_cols[2]\n",
    "                gdp_cleaned = ''.join(filter(str.isdigit, gdp_raw.split('.')[0]))\n",
    "                if gdp_cleaned:\n",
    "                    gdp = int(gdp_cleaned) / 1e3  # 단위를 1B USD로 변환\n",
    "                    data.append({'Country': country, 'GDP (B USD)': round(gdp, 2), 'Year': gdp_year})\n",
    "            except IndexError:\n",
    "                continue\n",
    "    log_message(\"Data Extraction Completed\")\n",
    "    return data\n",
    "\n",
    "# Transform\n",
    "def transform_gdp_data(data, output_csv_file='gdp_by_country.csv', output_json_file='Countries_by_GDP.json'):\n",
    "    log_message(\"Starting Data Transformation\")\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.sort_values(by='GDP (B USD)', ascending=False)\n",
    "    with open('country_region_table.json', 'r', encoding='utf-8') as region_file:\n",
    "        region_data = json.load(region_file)\n",
    "    df['Region'] = df['Country'].map(region_data)\n",
    "\n",
    "    # 데이터 저장 (CSV 및 JSON 파일)\n",
    "    try:\n",
    "        df.to_csv(output_csv_file, index=False)\n",
    "        log_message(f\"CSV file saved as {output_csv_file}\")\n",
    "        \n",
    "        data_as_dict = df.to_dict(orient='records')\n",
    "        with open(output_json_file, 'w', encoding='utf-8') as json_file:\n",
    "            json.dump(data_as_dict, json_file, ensure_ascii=False, indent=4)\n",
    "        log_message(f\"JSON file saved as {output_json_file}\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"Data Transformation Failed during saving: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "    log_message(\"Data Transformation Completed\")\n",
    "    return df\n",
    "\n",
    "# Load to Database\n",
    "def load_gdp_to_database(df, db_name='World_Economies.db', table_name='Countries_by_GDP'):\n",
    "    log_message(\"Starting Data Loading to Database\")\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_name)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # 테이블 생성\n",
    "        cursor.execute(f\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "                Country TEXT PRIMARY KEY,\n",
    "                GDP_USD_billion REAL\n",
    "            )\n",
    "        \"\"\")\n",
    "        \n",
    "        # 데이터 삽입\n",
    "        for _, row in df.iterrows():\n",
    "            cursor.execute(f\"\"\"\n",
    "                INSERT OR REPLACE INTO {table_name} (Country, GDP_USD_billion)\n",
    "                VALUES (?, ?)\n",
    "            \"\"\", (row['Country'], row['GDP (B USD)']))\n",
    "        \n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "        log_message(\"Data Loading to Database Completed Successfully\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"Data Loading to Database Failed: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# SQL Query: GDP가 100B USD 이상인 국가 출력\n",
    "def query_gdp_over_100(db_name='World_Economies.db', table_name='Countries_by_GDP'):\n",
    "    log_message(\"Querying GDP over 100B USD\")\n",
    "    conn = sqlite3.connect(db_name)\n",
    "    query = f\"SELECT * FROM {table_name} WHERE GDP_USD_billion >= 100\"\n",
    "    result = pd.read_sql_query(query, conn)\n",
    "    conn.close()\n",
    "    print(\"Countries with a GDP of over 100B USD:\")\n",
    "    print(result)\n",
    "\n",
    "# SQL Query: Region별 Top 5 국가의 GDP 평균\n",
    "def query_region_top5_avg(df):\n",
    "    log_message(\"Calculating Region-wise Top 5 Average GDP\")\n",
    "    region_top5_avg = (\n",
    "        df.groupby('Region')\n",
    "        .apply(lambda x: x.nlargest(5, 'GDP (B USD)')['GDP (B USD)'].mean())\n",
    "        .reset_index(name='Top 5 Avg GDP (B USD)')\n",
    "    )\n",
    "    print(\"Average GDP of top 5 countries by region:\")\n",
    "    print(region_top5_avg)\n",
    "\n",
    "# 메인 ETL 함수\n",
    "def etl_process():\n",
    "    url = \"https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)\"\n",
    "    try:\n",
    "        log_message(\"ETL Process Started\")\n",
    "        # Extract\n",
    "        data = extract_gdp_data(url)\n",
    "        # Transform\n",
    "        transformed_data = transform_gdp_data(data)\n",
    "        # Load to Database\n",
    "        load_gdp_to_database(transformed_data)\n",
    "        log_message(\"ETL Process Completed Successfully\")\n",
    "\n",
    "        # SQL Query Outputs\n",
    "        query_gdp_over_100()\n",
    "        query_region_top5_avg(transformed_data)\n",
    "    except Exception as e:\n",
    "        log_message(f\"ETL Process Failed: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    etl_process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/Documents/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import sqlite3\n",
    "import datetime\n",
    "\n",
    "def log_started():\n",
    "    with open('etl_project_log.txt', 'a') as log_file:\n",
    "        log_file.write(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "        timestamp = datetime.datetime.now().strftime('%Y-%B-%d-%H-%M-%S')\n",
    "        log_file.write(f\"New execution at {timestamp}\\n\")\n",
    "        log_file.write(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "\n",
    "def log_message():\n",
    "    pass\n",
    "def save_gdp_data():\n",
    "    pass\n",
    "def extract_gdp_data():\n",
    "    pass\n",
    "def transform_gdp_data():\n",
    "    pass\n",
    "def load_gdp_data():\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "def etl_process():\n",
    "    try:\n",
    "        log_started()\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    etl_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
